{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Packages:\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "# Model Packeges import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "mydir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "sys.path.append(mydir)\n",
    "from DataGenerator import genTrainValidFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STDbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/STD/batchData/\"\n",
    "EDGbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/EDG/batchData/\"\n",
    "HOGp1batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp1/batchData/\"\n",
    "HOGp2batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp2/batchData/\"\n",
    "HOGp3batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp3/batchData/\"\n",
    "\n",
    "featureDIR = HOGp3batch_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def toOneHotVector():\n",
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "def reshape_data(dataset, labels, featureSize, numLabels, sample_size=None):\n",
    "    if sample_size:\n",
    "        dataset = dataset[:sample_size].reshape(sample_size, featureSize) # To reshape the  \n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    else:\n",
    "        dataset = dataset.reshape(len(dataset), featureSize) # To reshape the  \n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BuildNeuralNet():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        seed = 2316\n",
    "        self.featureSize = 900     # Note to change the featureSize when using a new Feature Set\n",
    "        self.numHidden1 = 1000\n",
    "        self.numHidden2 = 1000\n",
    "        self.numHidden3 = 1000\n",
    "        self.numLabels = 2\n",
    "        self.alpha = 0.06\n",
    "        self.momentum = 0.9\n",
    "        \n",
    "        self.weights = {\n",
    "            \"inp_to_hid1_wght\": tf.Variable(tf.random_normal([self.featureSize, self.numHidden1], seed=seed)),\n",
    "            \"hid1_to_hid2_wght\" : tf.Variable(tf.random_normal([self.numHidden1, self.numHidden2], seed=seed)),\n",
    "            \"hid2_to_hid3_wght\": tf.Variable(tf.random_normal([self.numHidden2, self.numHidden3], seed=seed)),\n",
    "            \"hid3_to_out_wght\": tf.Variable(tf.random_normal([self.numHidden3, self.numLabels], seed=seed))\n",
    "        }\n",
    "        \n",
    "        self.biases = {\n",
    "            \"hid1_bias\": tf.Variable(tf.random_normal([self.numHidden1], seed=seed)),\n",
    "            \"hid2_bias\": tf.Variable(tf.random_normal([self.numHidden2], seed=seed)),\n",
    "            \"hid3_bias\": tf.Variable(tf.random_normal([self.numHidden3], seed=seed)),\n",
    "            \"out_bias\": tf.Variable(tf.random_normal([self.numLabels], seed=seed))\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def trainNet(self):\n",
    "        trainData = tf.placeholder(tf.float32, [None, self.featureSize])\n",
    "        trainLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "        # 1st Hidden Layer State\n",
    "        inp_to_hid1 = tf.matmul(trainData, self.weights['inp_to_hid1_wght']) + self.biases['hid1_bias']\n",
    "        hid1State = tf.sigmoid(inp_to_hid1)\n",
    "        \n",
    "        # 2nd Hidden Layer State\n",
    "        hid1_to_hid2 = tf.matmul(hid1State, self.weights['hid1_to_hid2_wght']) + self.biases['hid2_bias']\n",
    "        hid2State = tf.sigmoid(hid1_to_hid2)\n",
    "        \n",
    "        # 3nd Hidden Layer State\n",
    "        hid2_to_hid3 = tf.matmul(hid2State, self.weights['hid2_to_hid3_wght']) + self.biases['hid3_bias']\n",
    "        hid3State = tf.sigmoid(hid2_to_hid3)\n",
    "        \n",
    "        # Output Layer State\n",
    "        hid3_to_out = tf.matmul(hid3State, self.weights['hid3_to_out_wght']) + self.biases['out_bias']\n",
    "        outState = tf.nn.softmax(hid3_to_out)\n",
    "        \n",
    "        # Loss Function and Optimization\n",
    "        lossCE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hid3_to_out, labels=trainLabels))\n",
    "#         optimizer = tf.train.AdamOptimizer(learning_rate=self.alpha).minimize(lossCE)\n",
    "        optimizer = tf.train.MomentumOptimizer(self.alpha, \n",
    "                                            self.momentum, \n",
    "                                            use_locking=False, \n",
    "                                            name='Momentum', \n",
    "                                            use_nesterov=True).minimize(lossCE)\n",
    "        \n",
    "        # Evaluate model\n",
    "#         trainPred = tf.equal(tf.argmax(outState, 1), tf.argmax(trainLabels, 1))\n",
    "#         trainAccuracy = tf.reduce_mean(tf.cast(trainPred, tf.float32))\n",
    "        \n",
    "        return dict(\n",
    "            trainData = trainData, \n",
    "            trainLabels = trainLabels,\n",
    "#             weightsLRND = self.weights,\n",
    "            trainPred = outState,\n",
    "            optimizer = optimizer,\n",
    "            lossCE = lossCE\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def crossValid(self):\n",
    "            validData = tf.placeholder(tf.float32, [None, self.featureSize])\n",
    "            validLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "            # 1st Hidden Layer State\n",
    "            valid_hid1State = tf.sigmoid(tf.matmul(validData, self.weights['inp_to_hid1_wght']) + self.biases['hid1_bias'])\n",
    "\n",
    "            # 2nd Hidden Layer State\n",
    "            valid_hid2State = tf.sigmoid(tf.matmul(valid_hid1State, self.weights['hid1_to_hid2_wght']) + self.biases['hid2_bias'])\n",
    "\n",
    "            # 3nd Hidden Layer State\n",
    "            valid_hid3State = tf.sigmoid(tf.matmul(valid_hid2State, self.weights['hid2_to_hid3_wght']) + self.biases['hid3_bias'])\n",
    "\n",
    "            # Output Layer State\n",
    "            validOutState = tf.nn.softmax(tf.matmul(valid_hid3State, self.weights['hid3_to_out_wght']) + self.biases['out_bias'])\n",
    "\n",
    "#             validPred = tf.equal(tf.argmax(validOutState, 1), tf.argmax(validLabels, 1))\n",
    "#             validAccuracy = tf.reduce_mean(tf.cast(validPred, tf.float32))\n",
    "            \n",
    "            return dict(\n",
    "                validData = validData,\n",
    "                validLabels = validLabels,\n",
    "                validPred = validOutState\n",
    "            )\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 1, Iter: 2, Loss= 29.794928, Training Accuracy= 50.00000\n",
      "Fold: 1, Iter: 4, Loss= 3.477992, Training Accuracy= 62.56667\n",
      "Fold: 1, Iter: 6, Loss= 21.262964, Training Accuracy= 50.01111\n",
      "Fold: 1, Iter: 8, Loss= 3.350467, Training Accuracy= 70.30000\n",
      "Fold: 1, Iter: 10, Loss= 10.159875, Training Accuracy= 56.44444\n",
      "Fold: 1, Iter: 12, Loss= 4.855434, Training Accuracy= 69.23333\n",
      "Fold: 1, Iter: 14, Loss= 3.215656, Training Accuracy= 75.82222\n",
      "Fold: 1, Iter: 16, Loss= 2.105411, Training Accuracy= 80.67778\n",
      "Fold: 1, Iter: 18, Loss= 1.780059, Training Accuracy= 82.10000\n",
      "Fold: 1, Iter: 20, Loss= 1.605361, Training Accuracy= 82.67778\n",
      "Fold: 1, Iter: 22, Loss= 1.449473, Training Accuracy= 83.18889\n",
      "Fold: 1, Iter: 24, Loss= 1.302992, Training Accuracy= 83.72222\n",
      "Fold: 1, Iter: 26, Loss= 1.173072, Training Accuracy= 83.81111\n",
      "Fold: 1, Iter: 28, Loss= 1.062898, Training Accuracy= 83.95556\n",
      "Fold: 1, Iter: 30, Loss= 0.990015, Training Accuracy= 84.22222\n",
      "Fold: 1, Cross Validation Accuracy= 81.60000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3631   551  4182\n",
      "1           869  3949  4818\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          426  110   536\n",
      "1           74  390   464\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 2, Iter: 2, Loss= 29.761728, Training Accuracy= 50.00000\n",
      "Fold: 2, Iter: 4, Loss= 3.344099, Training Accuracy= 63.21111\n",
      "Fold: 2, Iter: 6, Loss= 21.345490, Training Accuracy= 50.01111\n",
      "Fold: 2, Iter: 8, Loss= 3.159611, Training Accuracy= 71.22222\n",
      "Fold: 2, Iter: 10, Loss= 9.902699, Training Accuracy= 56.53333\n",
      "Fold: 2, Iter: 12, Loss= 5.159710, Training Accuracy= 68.35556\n",
      "Fold: 2, Iter: 14, Loss= 3.248562, Training Accuracy= 75.65556\n",
      "Fold: 2, Iter: 16, Loss= 2.064188, Training Accuracy= 80.94444\n",
      "Fold: 2, Iter: 18, Loss= 1.747361, Training Accuracy= 82.25556\n",
      "Fold: 2, Iter: 20, Loss= 1.579149, Training Accuracy= 83.05556\n",
      "Fold: 2, Iter: 22, Loss= 1.425578, Training Accuracy= 83.44444\n",
      "Fold: 2, Iter: 24, Loss= 1.286622, Training Accuracy= 83.85556\n",
      "Fold: 2, Iter: 26, Loss= 1.163536, Training Accuracy= 84.03333\n",
      "Fold: 2, Iter: 28, Loss= 1.059180, Training Accuracy= 84.31111\n",
      "Fold: 2, Iter: 30, Loss= 0.983192, Training Accuracy= 84.30000\n",
      "Fold: 2, Cross Validation Accuracy= 80.50000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3658   571  4229\n",
      "1           842  3929  4771\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          411  106   517\n",
      "1           89  394   483\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 3, Iter: 2, Loss= 29.778591, Training Accuracy= 50.00000\n",
      "Fold: 3, Iter: 4, Loss= 3.387916, Training Accuracy= 63.17778\n",
      "Fold: 3, Iter: 6, Loss= 21.333597, Training Accuracy= 50.01111\n",
      "Fold: 3, Iter: 8, Loss= 3.306032, Training Accuracy= 70.71111\n",
      "Fold: 3, Iter: 10, Loss= 10.023481, Training Accuracy= 56.60000\n",
      "Fold: 3, Iter: 12, Loss= 4.934330, Training Accuracy= 69.22222\n",
      "Fold: 3, Iter: 14, Loss= 3.152554, Training Accuracy= 76.13333\n",
      "Fold: 3, Iter: 16, Loss= 2.072825, Training Accuracy= 80.76667\n",
      "Fold: 3, Iter: 18, Loss= 1.762231, Training Accuracy= 82.08889\n",
      "Fold: 3, Iter: 20, Loss= 1.581709, Training Accuracy= 82.63333\n",
      "Fold: 3, Iter: 22, Loss= 1.425364, Training Accuracy= 83.21111\n",
      "Fold: 3, Iter: 24, Loss= 1.288720, Training Accuracy= 83.61111\n",
      "Fold: 3, Iter: 26, Loss= 1.170661, Training Accuracy= 84.02222\n",
      "Fold: 3, Iter: 28, Loss= 1.080917, Training Accuracy= 84.15556\n",
      "Fold: 3, Iter: 30, Loss= 1.057219, Training Accuracy= 83.67778\n",
      "Fold: 3, Cross Validation Accuracy= 80.50000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3500   469  3969\n",
      "1          1000  4031  5031\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          440  135   575\n",
      "1           60  365   425\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 4, Iter: 2, Loss= 29.962456, Training Accuracy= 50.00000\n",
      "Fold: 4, Iter: 4, Loss= 3.837773, Training Accuracy= 61.68889\n",
      "Fold: 4, Iter: 6, Loss= 18.996958, Training Accuracy= 50.04444\n",
      "Fold: 4, Iter: 8, Loss= 6.816133, Training Accuracy= 60.91111\n",
      "Fold: 4, Iter: 10, Loss= 8.082580, Training Accuracy= 61.17778\n",
      "Fold: 4, Iter: 12, Loss= 3.961122, Training Accuracy= 73.28889\n",
      "Fold: 4, Iter: 14, Loss= 2.448447, Training Accuracy= 79.34444\n",
      "Fold: 4, Iter: 16, Loss= 1.971969, Training Accuracy= 81.40000\n",
      "Fold: 4, Iter: 18, Loss= 1.761338, Training Accuracy= 81.92222\n",
      "Fold: 4, Iter: 20, Loss= 1.580016, Training Accuracy= 82.38889\n",
      "Fold: 4, Iter: 22, Loss= 1.411925, Training Accuracy= 82.66667\n",
      "Fold: 4, Iter: 24, Loss= 1.261409, Training Accuracy= 83.33333\n",
      "Fold: 4, Iter: 26, Loss= 1.134841, Training Accuracy= 83.67778\n",
      "Fold: 4, Iter: 28, Loss= 1.042300, Training Accuracy= 84.13333\n",
      "Fold: 4, Iter: 30, Loss= 1.081534, Training Accuracy= 83.08889\n",
      "Fold: 4, Cross Validation Accuracy= 78.70000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3355   377  3732\n",
      "1          1145  4123  5268\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          460  173   633\n",
      "1           40  327   367\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 5, Iter: 2, Loss= 29.594299, Training Accuracy= 50.00000\n",
      "Fold: 5, Iter: 4, Loss= 2.999032, Training Accuracy= 64.65556\n",
      "Fold: 5, Iter: 6, Loss= 18.879456, Training Accuracy= 50.02222\n",
      "Fold: 5, Iter: 8, Loss= 10.006996, Training Accuracy= 54.85556\n",
      "Fold: 5, Iter: 10, Loss= 7.805543, Training Accuracy= 61.26667\n",
      "Fold: 5, Iter: 12, Loss= 4.349229, Training Accuracy= 71.92222\n",
      "Fold: 5, Iter: 14, Loss= 2.569452, Training Accuracy= 78.71111\n",
      "Fold: 5, Iter: 16, Loss= 1.984734, Training Accuracy= 81.56667\n",
      "Fold: 5, Iter: 18, Loss= 1.773582, Training Accuracy= 82.24444\n",
      "Fold: 5, Iter: 20, Loss= 1.600809, Training Accuracy= 82.87778\n",
      "Fold: 5, Iter: 22, Loss= 1.435379, Training Accuracy= 83.22222\n",
      "Fold: 5, Iter: 24, Loss= 1.286545, Training Accuracy= 83.63333\n",
      "Fold: 5, Iter: 26, Loss= 1.160005, Training Accuracy= 83.98889\n",
      "Fold: 5, Iter: 28, Loss= 1.055415, Training Accuracy= 84.32222\n",
      "Fold: 5, Iter: 30, Loss= 0.975282, Training Accuracy= 84.51111\n",
      "Fold: 5, Cross Validation Accuracy= 78.40000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3707   601  4308\n",
      "1           793  3899  4692\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          414  130   544\n",
      "1           86  370   456\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 6, Iter: 2, Loss= 29.862722, Training Accuracy= 50.00000\n",
      "Fold: 6, Iter: 4, Loss= 3.542360, Training Accuracy= 62.63333\n",
      "Fold: 6, Iter: 6, Loss= 20.939266, Training Accuracy= 50.01111\n",
      "Fold: 6, Iter: 8, Loss= 3.718022, Training Accuracy= 69.45556\n",
      "Fold: 6, Iter: 10, Loss= 9.946972, Training Accuracy= 56.96667\n",
      "Fold: 6, Iter: 12, Loss= 4.680214, Training Accuracy= 70.07778\n",
      "Fold: 6, Iter: 14, Loss= 3.035179, Training Accuracy= 76.71111\n",
      "Fold: 6, Iter: 16, Loss= 2.051534, Training Accuracy= 80.63333\n",
      "Fold: 6, Iter: 18, Loss= 1.764683, Training Accuracy= 81.80000\n",
      "Fold: 6, Iter: 20, Loss= 1.582849, Training Accuracy= 82.43333\n",
      "Fold: 6, Iter: 22, Loss= 1.419047, Training Accuracy= 82.71111\n",
      "Fold: 6, Iter: 24, Loss= 1.270517, Training Accuracy= 83.18889\n",
      "Fold: 6, Iter: 26, Loss= 1.138647, Training Accuracy= 83.72222\n",
      "Fold: 6, Iter: 28, Loss= 1.031007, Training Accuracy= 83.76667\n",
      "Fold: 6, Iter: 30, Loss= 0.971598, Training Accuracy= 83.76667\n",
      "Fold: 6, Cross Validation Accuracy= 80.80000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3587   548  4135\n",
      "1           913  3952  4865\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          441  133   574\n",
      "1           59  367   426\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 7, Iter: 2, Loss= 29.890583, Training Accuracy= 50.00000\n",
      "Fold: 7, Iter: 4, Loss= 3.550127, Training Accuracy= 62.46667\n",
      "Fold: 7, Iter: 6, Loss= 20.790834, Training Accuracy= 50.01111\n",
      "Fold: 7, Iter: 8, Loss= 3.805298, Training Accuracy= 69.03333\n",
      "Fold: 7, Iter: 10, Loss= 9.790422, Training Accuracy= 57.06667\n",
      "Fold: 7, Iter: 12, Loss= 4.612145, Training Accuracy= 70.30000\n",
      "Fold: 7, Iter: 14, Loss= 3.000951, Training Accuracy= 76.65556\n",
      "Fold: 7, Iter: 16, Loss= 2.038143, Training Accuracy= 81.04444\n",
      "Fold: 7, Iter: 18, Loss= 1.753407, Training Accuracy= 81.94444\n",
      "Fold: 7, Iter: 20, Loss= 1.584059, Training Accuracy= 82.64444\n",
      "Fold: 7, Iter: 22, Loss= 1.429159, Training Accuracy= 83.32222\n",
      "Fold: 7, Iter: 24, Loss= 1.290236, Training Accuracy= 83.66667\n",
      "Fold: 7, Iter: 26, Loss= 1.170581, Training Accuracy= 83.91111\n",
      "Fold: 7, Iter: 28, Loss= 1.076655, Training Accuracy= 84.10000\n",
      "Fold: 7, Iter: 30, Loss= 1.052989, Training Accuracy= 83.77778\n",
      "Fold: 7, Cross Validation Accuracy= 80.60000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3500   460  3960\n",
      "1          1000  4040  5040\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          438  132   570\n",
      "1           62  368   430\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 8, Iter: 2, Loss= 29.766104, Training Accuracy= 50.00000\n",
      "Fold: 8, Iter: 4, Loss= 3.170152, Training Accuracy= 63.83333\n",
      "Fold: 8, Iter: 6, Loss= 20.990355, Training Accuracy= 50.01111\n",
      "Fold: 8, Iter: 8, Loss= 4.413929, Training Accuracy= 66.55556\n",
      "Fold: 8, Iter: 10, Loss= 9.240232, Training Accuracy= 58.03333\n",
      "Fold: 8, Iter: 12, Loss= 4.504093, Training Accuracy= 70.52222\n",
      "Fold: 8, Iter: 14, Loss= 2.880346, Training Accuracy= 77.26667\n",
      "Fold: 8, Iter: 16, Loss= 2.000747, Training Accuracy= 81.58889\n",
      "Fold: 8, Iter: 18, Loss= 1.739716, Training Accuracy= 82.13333\n",
      "Fold: 8, Iter: 20, Loss= 1.568927, Training Accuracy= 82.66667\n",
      "Fold: 8, Iter: 22, Loss= 1.411162, Training Accuracy= 83.02222\n",
      "Fold: 8, Iter: 24, Loss= 1.273013, Training Accuracy= 83.45556\n",
      "Fold: 8, Iter: 26, Loss= 1.154293, Training Accuracy= 83.75556\n",
      "Fold: 8, Iter: 28, Loss= 1.053314, Training Accuracy= 83.76667\n",
      "Fold: 8, Iter: 30, Loss= 0.996738, Training Accuracy= 83.97778\n",
      "Fold: 8, Cross Validation Accuracy= 78.40000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3587   529  4116\n",
      "1           913  3971  4884\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          415  131   546\n",
      "1           85  369   454\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 9, Iter: 2, Loss= 29.772549, Training Accuracy= 50.00000\n",
      "Fold: 9, Iter: 4, Loss= 3.433486, Training Accuracy= 63.03333\n",
      "Fold: 9, Iter: 6, Loss= 21.369152, Training Accuracy= 50.01111\n",
      "Fold: 9, Iter: 8, Loss= 3.209725, Training Accuracy= 71.25556\n",
      "Fold: 9, Iter: 10, Loss= 10.013232, Training Accuracy= 56.50000\n",
      "Fold: 9, Iter: 12, Loss= 5.178907, Training Accuracy= 68.38889\n",
      "Fold: 9, Iter: 14, Loss= 3.300403, Training Accuracy= 75.67778\n",
      "Fold: 9, Iter: 16, Loss= 2.128805, Training Accuracy= 80.64444\n",
      "Fold: 9, Iter: 18, Loss= 1.787744, Training Accuracy= 82.08889\n",
      "Fold: 9, Iter: 20, Loss= 1.606847, Training Accuracy= 82.66667\n",
      "Fold: 9, Iter: 22, Loss= 1.446712, Training Accuracy= 83.13333\n",
      "Fold: 9, Iter: 24, Loss= 1.298924, Training Accuracy= 83.50000\n",
      "Fold: 9, Iter: 26, Loss= 1.170408, Training Accuracy= 83.73333\n",
      "Fold: 9, Iter: 28, Loss= 1.063817, Training Accuracy= 83.96667\n",
      "Fold: 9, Iter: 30, Loss= 0.980641, Training Accuracy= 84.07778\n",
      "Fold: 9, Cross Validation Accuracy= 80.70000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3689   622  4311\n",
      "1           811  3878  4689\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          439  132   571\n",
      "1           61  368   429\n",
      "All        500  500  1000\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 450) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 450) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Fold: 10, Iter: 2, Loss= 29.822931, Training Accuracy= 50.00000\n",
      "Fold: 10, Iter: 4, Loss= 3.404434, Training Accuracy= 63.00000\n",
      "Fold: 10, Iter: 6, Loss= 21.398157, Training Accuracy= 50.01111\n",
      "Fold: 10, Iter: 8, Loss= 3.097092, Training Accuracy= 72.02222\n",
      "Fold: 10, Iter: 10, Loss= 9.879205, Training Accuracy= 56.78889\n",
      "Fold: 10, Iter: 12, Loss= 5.029111, Training Accuracy= 68.86667\n",
      "Fold: 10, Iter: 14, Loss= 3.166128, Training Accuracy= 76.16667\n",
      "Fold: 10, Iter: 16, Loss= 2.043483, Training Accuracy= 80.94444\n",
      "Fold: 10, Iter: 18, Loss= 1.747582, Training Accuracy= 82.23333\n",
      "Fold: 10, Iter: 20, Loss= 1.580231, Training Accuracy= 82.97778\n",
      "Fold: 10, Iter: 22, Loss= 1.422429, Training Accuracy= 83.54444\n",
      "Fold: 10, Iter: 24, Loss= 1.277421, Training Accuracy= 83.81111\n",
      "Fold: 10, Iter: 26, Loss= 1.152076, Training Accuracy= 83.96667\n",
      "Fold: 10, Iter: 28, Loss= 1.050616, Training Accuracy= 84.24444\n",
      "Fold: 10, Iter: 30, Loss= 0.992971, Training Accuracy= 84.30000\n",
      "Fold: 10, Cross Validation Accuracy= 80.30000\n",
      "\n",
      "\n",
      "Confusion Matrix Training Set\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3603   516  4119\n",
      "1           897  3984  4881\n",
      "All        4500  4500  9000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          439  136   575\n",
      "1           61  364   425\n",
      "All        500  500  1000\n",
      "\n",
      "The Mean crossValidation Accuracy is:  80.05\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])\n",
    "\n",
    "def confusionMatrix(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (pd.crosstab(np.argmax(labels, 1), np.argmax(predictions, 1), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "\n",
    "class SessionExec():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epochs = 30\n",
    "        \n",
    "    def model(self, trainDataIN, trainLabelsIN, validDataIN, validLabelsIN):\n",
    "#         print (self.trainGraphDict)\n",
    "#         print ('')\n",
    "#         print (self.validGraphDict)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "\n",
    "            for epoch in range(self.epochs): \n",
    "                feed_dict = {self.trainGraphDict['trainData']: trainDataIN,\n",
    "                             self.trainGraphDict['trainLabels']: trainLabelsIN\n",
    "                        }\n",
    "\n",
    "\n",
    "                _, loss, tpred = sess.run([self.trainGraphDict['optimizer'], \n",
    "                                                        self.trainGraphDict['lossCE'],\n",
    "                                                        self.trainGraphDict['trainPred']], feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "                if (epoch+1)%2 == 0:\n",
    "                    # Evaluate training set\n",
    "                    tacc = accuracy(tpred, trainLabelsIN)\n",
    "                    print (\"Fold: \" + str(self.foldNUM+1) + \", Iter: \" + str(epoch+1) + \", Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(tacc))\n",
    "\n",
    "                    \n",
    "            # After all epoch are over with, test the model with the cross validation set\n",
    "            feed_dict = {self.validGraphDict['validData']: validDataIN,\n",
    "                     self.validGraphDict['validLabels']: validLabelsIN\n",
    "                }\n",
    "\n",
    "            vpred = sess.run(self.validGraphDict['validPred'], feed_dict=feed_dict)\n",
    "            \n",
    "            # Evaluate corss-validation set\n",
    "            vacc = accuracy(vpred, validLabelsIN)\n",
    "            print (\"Fold: \" + str(self.foldNUM+1) + \", Cross Validation Accuracy= \" + \"{:.5f}\".format(vacc))\n",
    "\n",
    "            print ('')\n",
    "            print ('')\n",
    "            \n",
    "            return tpred, tacc, vpred, vacc \n",
    "\n",
    "\n",
    "\n",
    "    def execute(self):\n",
    "        meanValidAcc = 0\n",
    "        for foldNUM, (trainDataIN, trainLabelsIN, validDataIN, validLabelsIN, labelDict) in enumerate(genTrainValidFolds(featureDIR, oneHot=True)):\n",
    "            print ('')\n",
    "            print ('Validation Data and Labels shape: ', validDataIN.shape, validLabelsIN.shape)\n",
    "            print ('Training Data and Labels shape: ', trainDataIN.shape, trainLabelsIN.shape)\n",
    "            print ('The Label Dictionary is given as: ', labelDict)\n",
    "            self.foldNUM = foldNUM\n",
    "            \n",
    "            reset_graph()\n",
    "            objNNET = BuildNeuralNet()\n",
    "            self.trainGraphDict = objNNET.trainNet()\n",
    "            self.validGraphDict = objNNET.crossValid()\n",
    "            tpred, tacc, vpred, vacc = self.model(trainDataIN, trainLabelsIN, validDataIN, validLabelsIN)\n",
    "            \n",
    "            trainCM = confusionMatrix(trainLabelsIN,tpred)\n",
    "            validCM = confusionMatrix(validLabelsIN,vpred)\n",
    "\n",
    "            meanValidAcc += vacc\n",
    "            print ('Confusion Matrix Training Set')\n",
    "            print (trainCM)\n",
    "            print ('')\n",
    "            print ('Confusion Matrix CrossValid Set')\n",
    "            print (validCM) \n",
    "#             break\n",
    "        print ('')\n",
    "        print ('The Mean crossValidation Accuracy is: ', meanValidAcc/(foldNUM+1))\n",
    "            \n",
    "            \n",
    "SessionExec().execute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Running i is : 0\n",
    "# Validation Data and Labels shape:  (1000, 162) (1000, 2)\n",
    "# Training Data and Labels shape:  (9000, 162) (9000, 2)\n",
    "# The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
    "# Fold: 1, Iter: 10, Loss= 1.603019, Training Accuracy= 0.79000\n",
    "# Fold: 1, Cross Validation Accuracy= 0.79200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def accuracy(predictions, labels):\n",
    "#     return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "#           / predictions.shape[0])\n",
    "\n",
    "\n",
    "# epochs = 30\n",
    "# def model(trainGraphDict, validGraphDict):\n",
    "#     print (trainGraphDict)\n",
    "#     print ('')\n",
    "#     print (validGraphDict)\n",
    "    \n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "#         for foldNUM, (trainDataIN, trainLabelsIN, validDataIN, validLabelsIN, labelDict) in enumerate(genTrainValidFolds(featureDIR, oneHot=True)):\n",
    "#             print ('Validation Data and Labels shape: ', validDataIN.shape, validLabelsIN.shape)\n",
    "#             print ('Training Data and Labels shape: ', trainDataIN.shape, trainLabelsIN.shape)\n",
    "#             print ('The Label Dictionary is given as: ', labelDict)\n",
    "\n",
    "#             for epoch in range(epochs): \n",
    "#                 feed_dict = {trainGraphDict['trainData']: trainDataIN,\n",
    "#                              trainGraphDict['trainLabels']: trainLabelsIN\n",
    "#                         }\n",
    "                \n",
    "                \n",
    "#                 _, loss, tacc, twghts, tbiases = sess.run([trainGraphDict['optimizer'], \n",
    "#                                                         trainGraphDict['lossCE'], \n",
    "#                                                         trainGraphDict['accuracy'],\n",
    "#                                                         trainGraphDict['weightsLRND'],\n",
    "#                                                         trainGraphDict['biasesLRND']], feed_dict=feed_dict)\n",
    "\n",
    "#                 if (epoch+1)%10 == 0:\n",
    "#                     print (\"Fold: \" + str(foldNUM+1) + \", Iter: \" + str(epoch) + \", Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(tacc))\n",
    "\n",
    "#                 # During the Last iteration of the nth fold batch, we should calculate the model accuracy with Cross Validataion Data\n",
    "#                 if epoch==epochs-1:\n",
    "#                     print ('')\n",
    "\n",
    "#                     feed_dict = {validGraphDict['validData']: validDataIN,\n",
    "#                              validGraphDict['validLabels']: validLabelsIN\n",
    "#                         }\n",
    "                \n",
    "#                     vacc = sess.run(validGraphDict['validAccuracy'], feed_dict=feed_dict)\n",
    "#                     print (\"Fold: \" + str(foldNUM+1) + \", Cross Validation Accuracy= \" + \"{:.5f}\".format(vacc))\n",
    "                    \n",
    "#             print ('')\n",
    "#             print ('')\n",
    "\n",
    "# #             break\n",
    "# #             epoch += 1\n",
    "# #         print (\"Optimization Finished!\")\n",
    "# #     obj_SVM = Models()\n",
    "# #     batchEvalDict[foldNUM] = obj_SVM.classify(trainData, trainLabels, validData)\n",
    "\n",
    "# reset_graph()\n",
    "# objNNET = BuildNeuralNet()\n",
    "# trainGraphDict = objNNET.trainNet()\n",
    "# validGraphDict = objNNET.crossValid()\n",
    "# model(trainGraphDict, validGraphDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "a = [1,2,3,4]\n",
    "b = [4,5,6,7]\n",
    "\n",
    "c.append(a+b)\n",
    "# c.append(b)\n",
    "c\n",
    "\n",
    "(a,b,c,d) = (1,2,3,4)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
