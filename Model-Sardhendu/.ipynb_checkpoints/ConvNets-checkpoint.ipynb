{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Packages:\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "# Model Packeges import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "mydir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "sys.path.append(mydir)\n",
    "from DataGenerator import genTrainValidFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STDbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/STD/batchData/\"\n",
    "EDGbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/EDG/batchData/\"\n",
    "HOGp1batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp1/batchData/\"   # dim =162\n",
    "HOGp2batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp2/batchData/\"   # dim =576\n",
    "HOGp3batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp3/batchData/\"\n",
    "\n",
    "featureDIR = STDbatch_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "def reshape_data(dataset, labels=None, imageSize=32, numChannels=1, sample_size=None):\n",
    "    if sample_size:\n",
    "        dataset = dataset[:sample_size].reshape((-1,imageSize,imageSize,numChannels)) # To reshape the\n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        if labels:\n",
    "            numLabels = len(np.unique(labels))\n",
    "            labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    else:\n",
    "        dataset = dataset.reshape((-1,imageSize,imageSize,numChannels)) # To reshape the  \n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        if labels:\n",
    "            numLabels = len(np.unique(labels))\n",
    "            labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GlabalVariable():\n",
    "    def __init__():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BuildConvNet():\n",
    "    \n",
    "    def __init__(self):\n",
    "#         self.batchSize = 128\n",
    "        self.imageSize = 32\n",
    "        self.numLabels = 2\n",
    "        self.numChannel = 1              # numChannels -> For grayscale =1, for RGB =3\n",
    "        self.numHidden = 1000            # numHiddenUnits for the fully connected layerr\n",
    "#         self.numHidden2 = 1000            # numHiddenUnits for the fully connected layer\n",
    "\n",
    "        self.conv1Kernel = 5             # Size of kernel for the first convolution layer\n",
    "        self.conv2Kernel = 5             # Size of kernel for the second convolution layer\n",
    "        self.conv1Depth = 32             # Number of kernels for the first convolution layer\n",
    "        self.conv2Depth = 64             # Number of kernels for the second convolution layer\n",
    "        self.conv1Stride = 1             # Strides for the first convolution layer filter  \n",
    "        self.conv2Stride = 1             # Strides for the second convolution layer filter\n",
    "\n",
    "        self.pool1Kernel = 2             # Size of kernel for the first Pooling layer\n",
    "        self.pool2Kernel = 2             # Size of kernel for the second Pooling layer  \n",
    "        self.pool1Stride = 2             # Strides for the first Pooling layer filter\n",
    "        self.pool2Stride = 2             # Strides for the second Pooling layer filter\n",
    "        \n",
    "        self.alpha = 0.005               # The learning Rate, A high Learning Rate will would be inefficient. If using higher\n",
    "                                         # learning rate then use regularizer else, the model will overfitt\n",
    "        self.dropout = 0.75              # Drop out a weight with a probability of 0.5\n",
    "        \n",
    "        self.m = 0.9\n",
    "        \n",
    "        self.seed = 2316                 # Set the seeds for the random weights generator\n",
    "        \n",
    "        self.weights = {\n",
    "            'cv1_wght': tf.Variable(tf.random_normal([self.conv1Kernel, self.conv1Kernel, self.numChannel, self.conv1Depth], seed=self.seed)),\n",
    "            'cv2_wgth': tf.Variable(tf.random_normal([self.conv2Kernel, self.conv2Kernel, self.conv1Depth, self.conv2Depth], seed=self.seed)),\n",
    "            'out_wght': tf.Variable(tf.random_normal([self.numHidden, self.numLabels], seed=self.seed))\n",
    "        }\n",
    "\n",
    "        self.biases = {\n",
    "            'cv1_bias': tf.Variable(tf.random_normal([self.conv1Depth], seed=self.seed)),\n",
    "            'cv2_bias': tf.Variable(tf.random_normal([self.conv2Depth], seed=self.seed)),\n",
    "            'fc1_bias': tf.Variable(tf.random_normal([self.numHidden], seed=self.seed)),\n",
    "            'out_bias': tf.Variable(tf.random_normal([self.numLabels], seed=self.seed))\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def convLayer(self, x, w, b, s=1, nlModel='RELU'):\n",
    "        x = tf.nn.conv2d(x, w, [1,s,s,1], padding='SAME') # Same padding\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        if nlModel == 'RELU':\n",
    "            return tf.nn.relu(x)\n",
    "        elif nlModel == 'LOGIT':\n",
    "            return tf.sigmoid(x)\n",
    "\n",
    "\n",
    "    def poolLayer(self, x, k=2, s=2, poolType='MAX'):\n",
    "        if poolType=='MAX':\n",
    "            return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,s,s,1], padding='SAME')\n",
    "        elif poolType == 'AVG':\n",
    "            return tf.nn.avg_pool(data, ksize=[1,k,k,1], strides=[1,s,s,1], padding='SAME')\n",
    "\n",
    "        \n",
    "    def fcLayer(self, x, w, b, nModel='RELU'):\n",
    "        x = tf.matmul(x, w) + b\n",
    "        if nModel=='RELU':\n",
    "            return tf.nn.relu(x)\n",
    "        if nModel=='LOGIT':\n",
    "            return tf.sigmoid(x)\n",
    "        \n",
    "        \n",
    "    def outputLayer(self, x, w, b):\n",
    "        x = tf.matmul(x, w) + b\n",
    "        return x, tf.nn.softmax(x)\n",
    "            \n",
    "                         \n",
    "    # Create the entire Model\n",
    "    def trainGraph(self):\n",
    "        trainData = tf.placeholder(tf.float32, [None, self.imageSize, self.imageSize, self.numChannel])\n",
    "        trainLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "\n",
    "        # Convolution Layer 1\n",
    "        conv1 = self.convLayer(trainData, self.weights['cv1_wght'], self.biases['cv1_bias'], s=self.conv1Stride)\n",
    "        conv1 = self.poolLayer(conv1, k=self.pool1Kernel)\n",
    "\n",
    "        # Convolution Layer 2\n",
    "        conv2 = self.convLayer(conv1, self.weights['cv2_wgth'], self.biases['cv2_bias'], self.conv2Stride)\n",
    "        conv2 = self.poolLayer(conv2, k=self.pool2Kernel)\n",
    "        poolSize = conv2.get_shape().as_list()[1]\n",
    "\n",
    "        # Fully connected layer : Reshape conv2 output to fit fully connected layer input\n",
    "        flattenedPoolSize = poolSize*poolSize*self.conv2Depth\n",
    "        self.weights['fc1_wght'] =  tf.Variable(tf.random_normal([flattenedPoolSize, self.numHidden]))\n",
    "        fc1State = tf.reshape(conv2, [-1, flattenedPoolSize])\n",
    "        fc1State = self.fcLayer(fc1State, self.weights['fc1_wght'], self.biases['fc1_bias'])\n",
    "        \n",
    "        # Drop out regularizer\n",
    "        fc1State = tf.nn.dropout(fc1State, self.dropout)\n",
    "\n",
    "\n",
    "        # Output, class prediction\n",
    "        pred, outputState = self.outputLayer(fc1State, self.weights['out_wght'], self.biases['out_bias'])\n",
    "        lossCE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=trainLabels))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.alpha).minimize(lossCE)\n",
    "#         optimizer = tf.train.MomentumOptimizer(self.alpha, \n",
    "#                                             self.m, \n",
    "#                                             use_locking=False, \n",
    "#                                             name='Momentum', \n",
    "#                                             use_nesterov=False).minimize(lossCE)\n",
    "\n",
    "        # Evaluate model\n",
    "#         correct_pred = tf.equal(tf.argmax(outputState, 1), tf.argmax(trainLabels, 1))\n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        \n",
    "        return dict(\n",
    "            trainData=trainData, \n",
    "            trainLabels=trainLabels, \n",
    "            optimizer=optimizer, \n",
    "            lossCE=lossCE,\n",
    "            trainPred = outputState\n",
    "#             accuracy=accuracy\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def validGraph(self):\n",
    "\n",
    "        validData = tf.placeholder(tf.float32, [None, self.imageSize, self.imageSize, self.numChannel])\n",
    "        validLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "        # Convolution Layer 1\n",
    "        vConv1 = self.convLayer(validData, self.weights['cv1_wght'], self.biases['cv1_bias'], s=self.conv1Stride)\n",
    "        vConv1 = self.poolLayer(vConv1, k=self.pool1Kernel)\n",
    "\n",
    "        # Convolution Layer 2\n",
    "        vConv2 = self.convLayer(vConv1, self.weights['cv2_wgth'], self.biases['cv2_bias'], self.conv2Stride)\n",
    "        vConv2 = self.poolLayer(vConv2, k=self.pool2Kernel)\n",
    "        vPoolSize = vConv2.get_shape().as_list()[1]\n",
    "\n",
    "        # Fully connected layer : Reshape conv2 output to fit fully connected layer input\n",
    "        vflattenedPoolSize = vPoolSize*vPoolSize*self.conv2Depth\n",
    "        vFc1State = tf.reshape(vConv2, [-1, vflattenedPoolSize])\n",
    "        vFc1State = self.fcLayer(vFc1State, self.weights['fc1_wght'], self.biases['fc1_bias'])\n",
    "\n",
    "        # Using DropOut Regularizer\n",
    "#         fc1State = tf.nn.dropout(fc1State, self.dropout)\n",
    "\n",
    "        # Output, class prediction\n",
    "        vPred, vOutState = self.outputLayer(vFc1State, self.weights['out_wght'], self.biases['out_bias'])\n",
    "\n",
    "    #             validPred = tf.equal(tf.argmax(validOutState, 1), tf.argmax(validLabels, 1))\n",
    "    #             validAccuracy = tf.reduce_mean(tf.cast(validPred, tf.float32))\n",
    "\n",
    "        return dict(\n",
    "            validData = validData,\n",
    "            validLabels = validLabels,\n",
    "            validPred = vOutState\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################################################################\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 32, 32, 1) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 32, 32, 1) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "\n",
      "Fold: 1, Epoch: 1, Mini Batch: 5, Loss= 34088.933594, Training Accuracy= 55.20000\n",
      "Fold: 1, Epoch: 1, Mini Batch: 10, Loss= 17000.271484, Training Accuracy= 66.00000\n",
      "Fold: 1, Epoch: 1, Mini Batch: 15, Loss= 13483.639648, Training Accuracy= 68.80000\n",
      "Fold: 1, Epoch: 1, Mini Batch: 18, Loss= 12162.555664, Training Accuracy= 66.80000\n",
      "\n",
      "Fold: 1, Epoch: 1, Validation Accuracy= 64.40000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          151    7   158\n",
      "1          349  493   842\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 2, Mini Batch: 5, Loss= 5706.247559, Training Accuracy= 71.40000\n",
      "Fold: 1, Epoch: 2, Mini Batch: 10, Loss= 4824.378906, Training Accuracy= 68.60000\n",
      "Fold: 1, Epoch: 2, Mini Batch: 15, Loss= 5192.920410, Training Accuracy= 72.40000\n",
      "Fold: 1, Epoch: 2, Mini Batch: 18, Loss= 3975.469971, Training Accuracy= 71.40000\n",
      "\n",
      "Fold: 1, Epoch: 2, Validation Accuracy= 78.70000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          441  154   595\n",
      "1           59  346   405\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 3, Mini Batch: 5, Loss= 4429.664062, Training Accuracy= 71.80000\n",
      "Fold: 1, Epoch: 3, Mini Batch: 10, Loss= 3194.411621, Training Accuracy= 73.20000\n",
      "Fold: 1, Epoch: 3, Mini Batch: 15, Loss= 3272.489990, Training Accuracy= 72.40000\n",
      "Fold: 1, Epoch: 3, Mini Batch: 18, Loss= 2330.538330, Training Accuracy= 75.40000\n",
      "\n",
      "Fold: 1, Epoch: 3, Validation Accuracy= 82.60000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          420   94   514\n",
      "1           80  406   486\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 4, Mini Batch: 5, Loss= 3008.956299, Training Accuracy= 76.00000\n",
      "Fold: 1, Epoch: 4, Mini Batch: 10, Loss= 2078.231445, Training Accuracy= 76.60000\n",
      "Fold: 1, Epoch: 4, Mini Batch: 15, Loss= 2432.664307, Training Accuracy= 78.00000\n",
      "Fold: 1, Epoch: 4, Mini Batch: 18, Loss= 1846.393921, Training Accuracy= 77.40000\n",
      "\n",
      "Fold: 1, Epoch: 4, Validation Accuracy= 83.80000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          411   73   484\n",
      "1           89  427   516\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 5, Mini Batch: 5, Loss= 1690.156494, Training Accuracy= 78.80000\n",
      "Fold: 1, Epoch: 5, Mini Batch: 10, Loss= 1871.571045, Training Accuracy= 77.20000\n",
      "Fold: 1, Epoch: 5, Mini Batch: 15, Loss= 1607.639038, Training Accuracy= 78.00000\n",
      "Fold: 1, Epoch: 5, Mini Batch: 18, Loss= 1877.078491, Training Accuracy= 76.80000\n",
      "\n",
      "Fold: 1, Epoch: 5, Validation Accuracy= 84.10000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          395   54   449\n",
      "1          105  446   551\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 6, Mini Batch: 5, Loss= 1756.234741, Training Accuracy= 77.00000\n",
      "Fold: 1, Epoch: 6, Mini Batch: 10, Loss= 1078.093384, Training Accuracy= 83.60000\n",
      "Fold: 1, Epoch: 6, Mini Batch: 15, Loss= 1345.219238, Training Accuracy= 80.60000\n",
      "Fold: 1, Epoch: 6, Mini Batch: 18, Loss= 1202.127930, Training Accuracy= 82.40000\n",
      "\n",
      "Fold: 1, Epoch: 6, Validation Accuracy= 83.50000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          436  101   537\n",
      "1           64  399   463\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 7, Mini Batch: 5, Loss= 1357.308960, Training Accuracy= 76.80000\n",
      "Fold: 1, Epoch: 7, Mini Batch: 10, Loss= 1156.577515, Training Accuracy= 80.80000\n",
      "Fold: 1, Epoch: 7, Mini Batch: 15, Loss= 1142.795044, Training Accuracy= 80.20000\n",
      "Fold: 1, Epoch: 7, Mini Batch: 18, Loss= 859.079346, Training Accuracy= 81.00000\n",
      "\n",
      "Fold: 1, Epoch: 7, Validation Accuracy= 85.40000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          421   67   488\n",
      "1           79  433   512\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 8, Mini Batch: 5, Loss= 1077.852905, Training Accuracy= 82.80000\n",
      "Fold: 1, Epoch: 8, Mini Batch: 10, Loss= 845.558960, Training Accuracy= 83.00000\n",
      "Fold: 1, Epoch: 8, Mini Batch: 15, Loss= 749.227722, Training Accuracy= 85.00000\n",
      "Fold: 1, Epoch: 8, Mini Batch: 18, Loss= 739.321899, Training Accuracy= 84.20000\n",
      "\n",
      "Fold: 1, Epoch: 8, Validation Accuracy= 84.50000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          407   62   469\n",
      "1           93  438   531\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 9, Mini Batch: 5, Loss= 793.803650, Training Accuracy= 83.40000\n",
      "Fold: 1, Epoch: 9, Mini Batch: 10, Loss= 597.216858, Training Accuracy= 86.20000\n",
      "Fold: 1, Epoch: 9, Mini Batch: 15, Loss= 722.333252, Training Accuracy= 83.40000\n",
      "Fold: 1, Epoch: 9, Mini Batch: 18, Loss= 757.740479, Training Accuracy= 84.20000\n",
      "\n",
      "Fold: 1, Epoch: 9, Validation Accuracy= 85.30000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          426   73   499\n",
      "1           74  427   501\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 10, Mini Batch: 5, Loss= 707.527771, Training Accuracy= 82.40000\n",
      "Fold: 1, Epoch: 10, Mini Batch: 10, Loss= 476.743958, Training Accuracy= 87.60000\n",
      "Fold: 1, Epoch: 10, Mini Batch: 15, Loss= 612.767395, Training Accuracy= 85.20000\n",
      "Fold: 1, Epoch: 10, Mini Batch: 18, Loss= 569.516174, Training Accuracy= 85.80000\n",
      "\n",
      "Fold: 1, Epoch: 10, Validation Accuracy= 86.00000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          428   68   496\n",
      "1           72  432   504\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 11, Mini Batch: 5, Loss= 516.501465, Training Accuracy= 84.80000\n",
      "Fold: 1, Epoch: 11, Mini Batch: 10, Loss= 457.688751, Training Accuracy= 87.20000\n",
      "Fold: 1, Epoch: 11, Mini Batch: 15, Loss= 588.556946, Training Accuracy= 84.80000\n",
      "Fold: 1, Epoch: 11, Mini Batch: 18, Loss= 453.072632, Training Accuracy= 87.00000\n",
      "\n",
      "Fold: 1, Epoch: 11, Validation Accuracy= 87.00000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          430   60   490\n",
      "1           70  440   510\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 12, Mini Batch: 5, Loss= 425.794586, Training Accuracy= 86.00000\n",
      "Fold: 1, Epoch: 12, Mini Batch: 10, Loss= 430.599945, Training Accuracy= 86.20000\n",
      "Fold: 1, Epoch: 12, Mini Batch: 15, Loss= 334.890686, Training Accuracy= 88.40000\n",
      "Fold: 1, Epoch: 12, Mini Batch: 18, Loss= 312.538849, Training Accuracy= 87.00000\n",
      "\n",
      "Fold: 1, Epoch: 12, Validation Accuracy= 86.00000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          427   67   494\n",
      "1           73  433   506\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 13, Mini Batch: 5, Loss= 355.984497, Training Accuracy= 86.80000\n",
      "Fold: 1, Epoch: 13, Mini Batch: 10, Loss= 269.577271, Training Accuracy= 88.20000\n",
      "Fold: 1, Epoch: 13, Mini Batch: 15, Loss= 313.205414, Training Accuracy= 88.80000\n",
      "Fold: 1, Epoch: 13, Mini Batch: 18, Loss= 214.192612, Training Accuracy= 89.40000\n",
      "\n",
      "Fold: 1, Epoch: 13, Validation Accuracy= 86.90000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          416   47   463\n",
      "1           84  453   537\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 14, Mini Batch: 5, Loss= 344.289246, Training Accuracy= 85.80000\n",
      "Fold: 1, Epoch: 14, Mini Batch: 10, Loss= 324.448486, Training Accuracy= 88.20000\n",
      "Fold: 1, Epoch: 14, Mini Batch: 15, Loss= 353.899872, Training Accuracy= 89.20000\n",
      "Fold: 1, Epoch: 14, Mini Batch: 18, Loss= 288.148682, Training Accuracy= 88.40000\n",
      "\n",
      "Fold: 1, Epoch: 14, Validation Accuracy= 86.00000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          399   39   438\n",
      "1          101  461   562\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 15, Mini Batch: 5, Loss= 255.044907, Training Accuracy= 89.00000\n",
      "Fold: 1, Epoch: 15, Mini Batch: 10, Loss= 258.678772, Training Accuracy= 89.60000\n",
      "Fold: 1, Epoch: 15, Mini Batch: 15, Loss= 255.002380, Training Accuracy= 90.00000\n",
      "Fold: 1, Epoch: 15, Mini Batch: 18, Loss= 168.260147, Training Accuracy= 91.60000\n",
      "\n",
      "Fold: 1, Epoch: 15, Validation Accuracy= 86.30000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          410   47   457\n",
      "1           90  453   543\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 16, Mini Batch: 5, Loss= 219.904694, Training Accuracy= 90.00000\n",
      "Fold: 1, Epoch: 16, Mini Batch: 10, Loss= 214.537903, Training Accuracy= 90.00000\n",
      "Fold: 1, Epoch: 16, Mini Batch: 15, Loss= 175.842270, Training Accuracy= 91.60000\n",
      "Fold: 1, Epoch: 16, Mini Batch: 18, Loss= 146.352936, Training Accuracy= 91.00000\n",
      "\n",
      "Fold: 1, Epoch: 16, Validation Accuracy= 86.60000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          439   73   512\n",
      "1           61  427   488\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 17, Mini Batch: 5, Loss= 266.186005, Training Accuracy= 88.80000\n",
      "Fold: 1, Epoch: 17, Mini Batch: 10, Loss= 163.497116, Training Accuracy= 91.60000\n",
      "Fold: 1, Epoch: 17, Mini Batch: 15, Loss= 209.701172, Training Accuracy= 91.60000\n",
      "Fold: 1, Epoch: 17, Mini Batch: 18, Loss= 238.876358, Training Accuracy= 89.80000\n",
      "\n",
      "Fold: 1, Epoch: 17, Validation Accuracy= 86.10000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          459   98   557\n",
      "1           41  402   443\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 18, Mini Batch: 5, Loss= 223.989105, Training Accuracy= 91.00000\n",
      "Fold: 1, Epoch: 18, Mini Batch: 10, Loss= 148.627686, Training Accuracy= 92.40000\n",
      "Fold: 1, Epoch: 18, Mini Batch: 15, Loss= 173.554962, Training Accuracy= 90.20000\n",
      "Fold: 1, Epoch: 18, Mini Batch: 18, Loss= 102.788734, Training Accuracy= 94.00000\n",
      "\n",
      "Fold: 1, Epoch: 18, Validation Accuracy= 86.50000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          446   81   527\n",
      "1           54  419   473\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 19, Mini Batch: 5, Loss= 124.634071, Training Accuracy= 93.20000\n",
      "Fold: 1, Epoch: 19, Mini Batch: 10, Loss= 132.709641, Training Accuracy= 92.80000\n",
      "Fold: 1, Epoch: 19, Mini Batch: 15, Loss= 136.881119, Training Accuracy= 92.00000\n",
      "Fold: 1, Epoch: 19, Mini Batch: 18, Loss= 87.751274, Training Accuracy= 94.20000\n",
      "\n",
      "Fold: 1, Epoch: 19, Validation Accuracy= 85.90000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          442   83   525\n",
      "1           58  417   475\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 1, Epoch: 20, Mini Batch: 5, Loss= 176.151443, Training Accuracy= 89.80000\n",
      "Fold: 1, Epoch: 20, Mini Batch: 10, Loss= 158.294250, Training Accuracy= 91.80000\n",
      "Fold: 1, Epoch: 20, Mini Batch: 15, Loss= 79.210655, Training Accuracy= 94.60000\n",
      "Fold: 1, Epoch: 20, Mini Batch: 18, Loss= 94.426529, Training Accuracy= 95.80000\n",
      "\n",
      "Fold: 1, Epoch: 20, Validation Accuracy= 87.90000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          435   56   491\n",
      "1           65  444   509\n",
      "All        500  500  1000\n",
      "\n",
      "\n",
      "##########################################################################################\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 32, 32, 1) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 32, 32, 1) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "\n",
      "Fold: 2, Epoch: 1, Mini Batch: 5, Loss= 41305.777344, Training Accuracy= 52.60000\n",
      "Fold: 2, Epoch: 1, Mini Batch: 10, Loss= 26092.716797, Training Accuracy= 61.00000\n",
      "Fold: 2, Epoch: 1, Mini Batch: 15, Loss= 12845.963867, Training Accuracy= 64.00000\n",
      "Fold: 2, Epoch: 1, Mini Batch: 18, Loss= 6163.596680, Training Accuracy= 72.60000\n",
      "\n",
      "Fold: 2, Epoch: 1, Validation Accuracy= 74.80000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          413  165   578\n",
      "1           87  335   422\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 2, Mini Batch: 5, Loss= 4966.779785, Training Accuracy= 71.20000\n",
      "Fold: 2, Epoch: 2, Mini Batch: 10, Loss= 5432.704590, Training Accuracy= 70.60000\n",
      "Fold: 2, Epoch: 2, Mini Batch: 15, Loss= 5295.163086, Training Accuracy= 69.20000\n",
      "Fold: 2, Epoch: 2, Mini Batch: 18, Loss= 3280.506592, Training Accuracy= 76.20000\n",
      "\n",
      "Fold: 2, Epoch: 2, Validation Accuracy= 76.90000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          317   48   365\n",
      "1          183  452   635\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 3, Mini Batch: 5, Loss= 3648.657959, Training Accuracy= 72.40000\n",
      "Fold: 2, Epoch: 3, Mini Batch: 10, Loss= 3348.825439, Training Accuracy= 73.00000\n",
      "Fold: 2, Epoch: 3, Mini Batch: 15, Loss= 2198.284424, Training Accuracy= 76.80000\n",
      "Fold: 2, Epoch: 3, Mini Batch: 18, Loss= 2123.742920, Training Accuracy= 78.80000\n",
      "\n",
      "Fold: 2, Epoch: 3, Validation Accuracy= 79.60000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          420  124   544\n",
      "1           80  376   456\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 4, Mini Batch: 5, Loss= 2856.802979, Training Accuracy= 73.80000\n",
      "Fold: 2, Epoch: 4, Mini Batch: 10, Loss= 1829.603027, Training Accuracy= 79.00000\n",
      "Fold: 2, Epoch: 4, Mini Batch: 15, Loss= 1804.188721, Training Accuracy= 79.00000\n",
      "Fold: 2, Epoch: 4, Mini Batch: 18, Loss= 1366.953857, Training Accuracy= 82.60000\n",
      "\n",
      "Fold: 2, Epoch: 4, Validation Accuracy= 81.70000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          370   53   423\n",
      "1          130  447   577\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 5, Mini Batch: 5, Loss= 1867.454224, Training Accuracy= 77.60000\n",
      "Fold: 2, Epoch: 5, Mini Batch: 10, Loss= 1791.860107, Training Accuracy= 78.80000\n",
      "Fold: 2, Epoch: 5, Mini Batch: 15, Loss= 1392.524292, Training Accuracy= 79.40000\n",
      "Fold: 2, Epoch: 5, Mini Batch: 18, Loss= 1216.525024, Training Accuracy= 80.00000\n",
      "\n",
      "Fold: 2, Epoch: 5, Validation Accuracy= 83.20000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          373   41   414\n",
      "1          127  459   586\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 6, Mini Batch: 5, Loss= 1637.277954, Training Accuracy= 76.80000\n",
      "Fold: 2, Epoch: 6, Mini Batch: 10, Loss= 1127.569458, Training Accuracy= 82.60000\n",
      "Fold: 2, Epoch: 6, Mini Batch: 15, Loss= 846.047180, Training Accuracy= 85.40000\n",
      "Fold: 2, Epoch: 6, Mini Batch: 18, Loss= 843.256348, Training Accuracy= 82.80000\n",
      "\n",
      "Fold: 2, Epoch: 6, Validation Accuracy= 84.20000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          387   45   432\n",
      "1          113  455   568\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 7, Mini Batch: 5, Loss= 1223.993164, Training Accuracy= 81.20000\n",
      "Fold: 2, Epoch: 7, Mini Batch: 10, Loss= 948.506775, Training Accuracy= 82.00000\n",
      "Fold: 2, Epoch: 7, Mini Batch: 15, Loss= 832.615234, Training Accuracy= 85.40000\n",
      "Fold: 2, Epoch: 7, Mini Batch: 18, Loss= 541.227234, Training Accuracy= 88.20000\n",
      "\n",
      "Fold: 2, Epoch: 7, Validation Accuracy= 84.80000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          399   51   450\n",
      "1          101  449   550\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 8, Mini Batch: 5, Loss= 986.047241, Training Accuracy= 83.00000\n",
      "Fold: 2, Epoch: 8, Mini Batch: 10, Loss= 706.055481, Training Accuracy= 85.20000\n",
      "Fold: 2, Epoch: 8, Mini Batch: 15, Loss= 567.474609, Training Accuracy= 86.00000\n",
      "Fold: 2, Epoch: 8, Mini Batch: 18, Loss= 488.271057, Training Accuracy= 87.20000\n",
      "\n",
      "Fold: 2, Epoch: 8, Validation Accuracy= 84.10000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          421   80   501\n",
      "1           79  420   499\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 9, Mini Batch: 5, Loss= 761.753662, Training Accuracy= 82.60000\n",
      "Fold: 2, Epoch: 9, Mini Batch: 10, Loss= 580.816956, Training Accuracy= 84.40000\n",
      "Fold: 2, Epoch: 9, Mini Batch: 15, Loss= 504.238861, Training Accuracy= 86.60000\n",
      "Fold: 2, Epoch: 9, Mini Batch: 18, Loss= 402.663544, Training Accuracy= 88.60000\n",
      "\n",
      "Fold: 2, Epoch: 9, Validation Accuracy= 85.10000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          404   53   457\n",
      "1           96  447   543\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 10, Mini Batch: 5, Loss= 592.811768, Training Accuracy= 84.20000\n",
      "Fold: 2, Epoch: 10, Mini Batch: 10, Loss= 443.303741, Training Accuracy= 87.20000\n",
      "Fold: 2, Epoch: 10, Mini Batch: 15, Loss= 491.227386, Training Accuracy= 86.20000\n",
      "Fold: 2, Epoch: 10, Mini Batch: 18, Loss= 349.094513, Training Accuracy= 87.80000\n",
      "\n",
      "Fold: 2, Epoch: 10, Validation Accuracy= 84.70000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          403   56   459\n",
      "1           97  444   541\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 11, Mini Batch: 5, Loss= 647.540100, Training Accuracy= 81.40000\n",
      "Fold: 2, Epoch: 11, Mini Batch: 10, Loss= 272.328308, Training Accuracy= 90.20000\n",
      "Fold: 2, Epoch: 11, Mini Batch: 15, Loss= 368.730652, Training Accuracy= 88.00000\n",
      "Fold: 2, Epoch: 11, Mini Batch: 18, Loss= 293.323425, Training Accuracy= 89.00000\n",
      "\n",
      "Fold: 2, Epoch: 11, Validation Accuracy= 86.60000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          423   57   480\n",
      "1           77  443   520\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 12, Mini Batch: 5, Loss= 427.057068, Training Accuracy= 87.00000\n",
      "Fold: 2, Epoch: 12, Mini Batch: 10, Loss= 378.072144, Training Accuracy= 87.40000\n",
      "Fold: 2, Epoch: 12, Mini Batch: 15, Loss= 322.007660, Training Accuracy= 87.00000\n",
      "Fold: 2, Epoch: 12, Mini Batch: 18, Loss= 265.347076, Training Accuracy= 90.00000\n",
      "\n",
      "Fold: 2, Epoch: 12, Validation Accuracy= 85.40000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          406   52   458\n",
      "1           94  448   542\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 13, Mini Batch: 5, Loss= 299.862305, Training Accuracy= 87.60000\n",
      "Fold: 2, Epoch: 13, Mini Batch: 10, Loss= 229.096558, Training Accuracy= 89.00000\n",
      "Fold: 2, Epoch: 13, Mini Batch: 15, Loss= 270.154449, Training Accuracy= 88.00000\n",
      "Fold: 2, Epoch: 13, Mini Batch: 18, Loss= 207.734726, Training Accuracy= 93.00000\n",
      "\n",
      "Fold: 2, Epoch: 13, Validation Accuracy= 85.50000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          403   48   451\n",
      "1           97  452   549\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 14, Mini Batch: 5, Loss= 204.782715, Training Accuracy= 89.20000\n",
      "Fold: 2, Epoch: 14, Mini Batch: 10, Loss= 166.739578, Training Accuracy= 91.00000\n",
      "Fold: 2, Epoch: 14, Mini Batch: 15, Loss= 205.221313, Training Accuracy= 90.40000\n",
      "Fold: 2, Epoch: 14, Mini Batch: 18, Loss= 205.157150, Training Accuracy= 90.20000\n",
      "\n",
      "Fold: 2, Epoch: 14, Validation Accuracy= 85.90000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          429   70   499\n",
      "1           71  430   501\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 15, Mini Batch: 5, Loss= 206.474915, Training Accuracy= 88.60000\n",
      "Fold: 2, Epoch: 15, Mini Batch: 10, Loss= 139.719711, Training Accuracy= 92.20000\n",
      "Fold: 2, Epoch: 15, Mini Batch: 15, Loss= 143.113220, Training Accuracy= 91.60000\n",
      "Fold: 2, Epoch: 15, Mini Batch: 18, Loss= 213.275696, Training Accuracy= 90.40000\n",
      "\n",
      "Fold: 2, Epoch: 15, Validation Accuracy= 84.70000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          441   94   535\n",
      "1           59  406   465\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 16, Mini Batch: 5, Loss= 250.463226, Training Accuracy= 88.60000\n",
      "Fold: 2, Epoch: 16, Mini Batch: 10, Loss= 202.184357, Training Accuracy= 89.80000\n",
      "Fold: 2, Epoch: 16, Mini Batch: 15, Loss= 189.115845, Training Accuracy= 90.00000\n",
      "Fold: 2, Epoch: 16, Mini Batch: 18, Loss= 254.832184, Training Accuracy= 88.60000\n",
      "\n",
      "Fold: 2, Epoch: 16, Validation Accuracy= 82.40000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          464  140   604\n",
      "1           36  360   396\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 17, Mini Batch: 5, Loss= 264.092865, Training Accuracy= 86.00000\n",
      "Fold: 2, Epoch: 17, Mini Batch: 10, Loss= 227.156006, Training Accuracy= 88.40000\n",
      "Fold: 2, Epoch: 17, Mini Batch: 15, Loss= 226.405106, Training Accuracy= 87.20000\n",
      "Fold: 2, Epoch: 17, Mini Batch: 18, Loss= 101.367157, Training Accuracy= 93.60000\n",
      "\n",
      "Fold: 2, Epoch: 17, Validation Accuracy= 84.80000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          446   98   544\n",
      "1           54  402   456\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 18, Mini Batch: 5, Loss= 115.626305, Training Accuracy= 92.80000\n",
      "Fold: 2, Epoch: 18, Mini Batch: 10, Loss= 78.628815, Training Accuracy= 93.40000\n",
      "Fold: 2, Epoch: 18, Mini Batch: 15, Loss= 121.559662, Training Accuracy= 93.80000\n",
      "Fold: 2, Epoch: 18, Mini Batch: 18, Loss= 89.188110, Training Accuracy= 93.00000\n",
      "\n",
      "Fold: 2, Epoch: 18, Validation Accuracy= 85.40000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          408   54   462\n",
      "1           92  446   538\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 19, Mini Batch: 5, Loss= 105.328545, Training Accuracy= 92.80000\n",
      "Fold: 2, Epoch: 19, Mini Batch: 10, Loss= 79.318077, Training Accuracy= 93.60000\n",
      "Fold: 2, Epoch: 19, Mini Batch: 15, Loss= 95.616455, Training Accuracy= 93.60000\n",
      "Fold: 2, Epoch: 19, Mini Batch: 18, Loss= 65.651131, Training Accuracy= 94.00000\n",
      "\n",
      "Fold: 2, Epoch: 19, Validation Accuracy= 85.70000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          435   78   513\n",
      "1           65  422   487\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 2, Epoch: 20, Mini Batch: 5, Loss= 84.564079, Training Accuracy= 93.60000\n",
      "Fold: 2, Epoch: 20, Mini Batch: 10, Loss= 65.327866, Training Accuracy= 95.80000\n",
      "Fold: 2, Epoch: 20, Mini Batch: 15, Loss= 95.289635, Training Accuracy= 93.40000\n",
      "Fold: 2, Epoch: 20, Mini Batch: 18, Loss= 70.774780, Training Accuracy= 94.20000\n",
      "\n",
      "Fold: 2, Epoch: 20, Validation Accuracy= 86.90000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          446   77   523\n",
      "1           54  423   477\n",
      "All        500  500  1000\n",
      "\n",
      "\n",
      "##########################################################################################\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 32, 32, 1) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 32, 32, 1) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "\n",
      "Fold: 3, Epoch: 1, Mini Batch: 5, Loss= 22368.226562, Training Accuracy= 60.00000\n",
      "Fold: 3, Epoch: 1, Mini Batch: 10, Loss= 17635.572266, Training Accuracy= 65.20000\n",
      "Fold: 3, Epoch: 1, Mini Batch: 15, Loss= 15116.022461, Training Accuracy= 65.80000\n",
      "Fold: 3, Epoch: 1, Mini Batch: 18, Loss= 11286.663086, Training Accuracy= 67.00000\n",
      "\n",
      "Fold: 3, Epoch: 1, Validation Accuracy= 63.20000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          145   13   158\n",
      "1          355  487   842\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 3, Epoch: 2, Mini Batch: 5, Loss= 5999.812988, Training Accuracy= 69.20000\n",
      "Fold: 3, Epoch: 2, Mini Batch: 10, Loss= 5264.881348, Training Accuracy= 72.00000\n",
      "Fold: 3, Epoch: 2, Mini Batch: 15, Loss= 4683.982910, Training Accuracy= 72.20000\n",
      "Fold: 3, Epoch: 2, Mini Batch: 18, Loss= 3631.151611, Training Accuracy= 76.20000\n",
      "\n",
      "Fold: 3, Epoch: 2, Validation Accuracy= 81.20000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          423  111   534\n",
      "1           77  389   466\n",
      "All        500  500  1000\n",
      "\n",
      "Fold: 3, Epoch: 3, Mini Batch: 5, Loss= 3309.820557, Training Accuracy= 71.60000\n",
      "Fold: 3, Epoch: 3, Mini Batch: 10, Loss= 3437.596436, Training Accuracy= 74.80000\n",
      "Fold: 3, Epoch: 3, Mini Batch: 15, Loss= 2734.927002, Training Accuracy= 76.40000\n",
      "Fold: 3, Epoch: 3, Mini Batch: 18, Loss= 2450.500000, Training Accuracy= 78.00000\n",
      "\n",
      "Fold: 3, Epoch: 3, Validation Accuracy= 80.40000\n",
      "\n",
      "Confusion Matrix CrossValid Set\n",
      "Predicted    0    1   All\n",
      "True                     \n",
      "0          429  125   554\n",
      "1           71  375   446\n",
      "All        500  500  1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])\n",
    "\n",
    "def confusionMatrix(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (pd.crosstab(np.argmax(labels, 1), np.argmax(predictions, 1), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "\n",
    "class SessionExec():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epochs = 20\n",
    "        self.imageSize = 32\n",
    "        self.batchSize = 500\n",
    "        \n",
    "        \n",
    "    def trainModel(self, trainDataIN, trainLabelsIN, sess):    \n",
    "        numBatches = int(trainDataIN.shape[0]/self.batchSize)\n",
    "        for numBatch in np.arange(numBatches):\n",
    "#                     print ('Batch no: ', numBatch)\n",
    "#                     print (numBatch*self.batchSize,  (numBatch+1)*self.batchSize)\n",
    "            batchData = trainDataIN[numBatch*self.batchSize : (numBatch+1)*self.batchSize]\n",
    "            batchLabels = trainLabelsIN[numBatch*self.batchSize : (numBatch+1)*self.batchSize]\n",
    "\n",
    "            feed_dict = {self.trainGraphDict['trainData']: batchData,\n",
    "                         self.trainGraphDict['trainLabels']: batchLabels\n",
    "#                              self.trainGraphDict['keep_prob']: 0.7\n",
    "                    }\n",
    "\n",
    "            _, loss, tpred = sess.run([self.trainGraphDict['optimizer'],\n",
    "                                        self.trainGraphDict['lossCE'],\n",
    "                                        self.trainGraphDict['trainPred']], feed_dict=feed_dict)\n",
    "            \n",
    "            if ((numBatch+1)%5 == 0) or ((numBatch+1) == numBatches): \n",
    "                tacc = accuracy(tpred, batchLabels)\n",
    "                print (\"Fold: \" + str(self.foldNUM+1) + \n",
    "                       \", Epoch: \" + str(self.epoch+1)+ \n",
    "                       \", Mini Batch: \" + str(numBatch+1) + \n",
    "                       \", Loss= \" + \"{:.6f}\".format(loss) + \n",
    "                       \", Training Accuracy= \" + \"{:.5f}\".format(tacc))\n",
    "    \n",
    "\n",
    "    \n",
    "    def validModel(self, validDataIN, validLabelsIN, sess):\n",
    "        feed_dict = {self.validGraphDict['validData']: validDataIN,\n",
    "                     self.validGraphDict['validLabels']: validLabelsIN\n",
    "#                              self.trainGraphDict['keep_prob']: 0.7\n",
    "                }\n",
    "\n",
    "        vpred = sess.run(self.validGraphDict['validPred'], feed_dict=feed_dict)\n",
    "        \n",
    "        vacc = accuracy(vpred, validLabelsIN)\n",
    "        print (\"Fold: \" + str(self.foldNUM+1) + \n",
    "                \", Epoch: \" + str(self.epoch+1)+ \n",
    "                \", Validation Accuracy= \" + \"{:.5f}\".format(vacc))\n",
    "        \n",
    "        return vpred \n",
    "        \n",
    "        \n",
    "    def execute(self, updWghtBias=False):\n",
    "        numLabels = 2\n",
    "        numFolds = 10\n",
    "        meanValidAcc = 0\n",
    "        self.wLRND = {}\n",
    "        self.bLRND = {}\n",
    "        \n",
    "        for foldNUM, (trainDataIN, trainLabelsIN, validDataIN, validLabelsIN, labelDict) in enumerate(genTrainValidFolds(featureDIR, oneHot=True)):   \n",
    "            print ('')\n",
    "            print ('##########################################################################################')\n",
    "            trainDataIN, _ = reshape_data(trainDataIN, imageSize=self.imageSize, numChannels=1)                                       \n",
    "            validDataIN, _ = reshape_data(validDataIN, imageSize=self.imageSize, numChannels=1)\n",
    "            \n",
    "            print ('')\n",
    "            print ('Validation Data and Labels shape: ', validDataIN.shape, validLabelsIN.shape)\n",
    "            print ('Training Data and Labels shape: ', trainDataIN.shape, trainLabelsIN.shape)\n",
    "            print ('The Label Dictionary is given as: ', labelDict)\n",
    "            print ('')\n",
    "            \n",
    "            self.foldNUM = foldNUM\n",
    "\n",
    "            reset_graph()\n",
    "\n",
    "            # Create a object encapsulating the graph lineage\n",
    "            objCNN = BuildConvNet()\n",
    "            self.trainGraphDict = objCNN.trainGraph()\n",
    "            self.validGraphDict = objCNN.validGraph()\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.initialize_all_variables())\n",
    "\n",
    "                for epoch in range(self.epochs): \n",
    "                    self.epoch = epoch\n",
    "                    \n",
    "                    # Train The model for Epochs\n",
    "                    self.trainModel(trainDataIN, trainLabelsIN, sess)\n",
    "                    print ('')\n",
    "                    \n",
    "                    # Validate the model for Epochs\n",
    "                    vpred = self.validModel(validDataIN, validLabelsIN, sess)\n",
    "                    print ('')\n",
    "\n",
    "                    validCM = confusionMatrix(validLabelsIN,vpred)\n",
    "                    print ('Confusion Matrix CrossValid Set')\n",
    "                    print (validCM)\n",
    "                    print ('')\n",
    "                    \n",
    "            if foldNUM == 2:\n",
    "                break\n",
    "\n",
    "SessionExec().execute(updWghtBias=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
