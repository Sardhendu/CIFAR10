{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rough Analysis Code:\n",
    "\n",
    "\n",
    "\n",
    "# class SessionExec():\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.epochs = 30\n",
    "        \n",
    "#     def trainModel(self, trainDataIN, trainLabelsIN):\n",
    "#         with tf.Session() as sess:\n",
    "#             sess.run(tf.initialize_all_variables())\n",
    "\n",
    "#             for epoch in range(self.epochs): \n",
    "#                 feed_dict = {self.trainGraphDict['trainData']: trainDataIN,\n",
    "#                              self.trainGraphDict['trainLabels']: trainLabelsIN,\n",
    "#                              self.trainGraphDict['keep_prob']: 0.7\n",
    "#                         }\n",
    "\n",
    "#                 if epoch == self.epochs-1:  # Capture the weights for the last iteration.\n",
    "#                     print ('ENtering the last iteration.....', epoch)\n",
    "#                     wLRND, bLRND, _, loss, tpred = sess.run([self.trainGraphDict['weightsLRND'],\n",
    "#                                                 self.trainGraphDict['biasesLRND'],\n",
    "#                                                 self.trainGraphDict['optimizer'],\n",
    "#                                                 self.trainGraphDict['lossCE'],\n",
    "#                                                 self.trainGraphDict['trainPred']], feed_dict=feed_dict)\n",
    "#                 else:\n",
    "#                     _, loss, tpred = sess.run([self.trainGraphDict['optimizer'], \n",
    "#                                                 self.trainGraphDict['lossCE'],\n",
    "#                                                 self.trainGraphDict['trainPred']], feed_dict=feed_dict)\n",
    "\n",
    "#                 if (epoch+1)%2 == 0 or epoch==self.epochs-1:\n",
    "#                     # Evaluate training set\n",
    "#                     tacc = accuracy(tpred, trainLabelsIN)\n",
    "#                     print (\"Fold: \" + str(self.foldNUM+1) + \", Iter: \" + str(epoch+1) + \", Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(tacc))\n",
    "    \n",
    "# #             print (wLRND)\n",
    "# #             print ('')\n",
    "# #             print (bLRND)\n",
    "#             return tpred, tacc, wLRND, bLRND\n",
    "\n",
    "                \n",
    "#     # After all epoch are over with, test the model with the cross validation set    \n",
    "#     def validateModel(self, validDataIN, validLabelsIN):\n",
    "#         with tf.Session() as sess:\n",
    "#             sess.run(tf.initialize_all_variables())\n",
    "            \n",
    "#             feed_dict = {self.validGraphDict['validData']: validDataIN,\n",
    "#                      self.validGraphDict['validLabels']: validLabelsIN\n",
    "#                 }\n",
    "\n",
    "#             vpred = sess.run(self.validGraphDict['validPred'], feed_dict=feed_dict)\n",
    "            \n",
    "#             # Evaluate corss-validation set\n",
    "#             vacc = accuracy(vpred, validLabelsIN)\n",
    "#             print (\"Fold: \" + str(self.foldNUM+1) + \", Cross Validation Accuracy= \" + \"{:.5f}\".format(vacc))\n",
    "\n",
    "#             print ('')\n",
    "#             print ('')\n",
    "            \n",
    "#             return vpred, vacc \n",
    "        \n",
    "    \n",
    "    \n",
    "#     def sumWghtBias(self, cmnDictIN, newDictIN):\n",
    "#         for param, val_aray in newDictIN.items():\n",
    "#             cmnDictIN[param] = np.add(val_aray, cmnDictIN[param])    \n",
    "#         return cmnDictIN\n",
    "            \n",
    "        \n",
    "#     def execute(self, updWghtBias=False):\n",
    "#         meanValidAcc = 0\n",
    "#         self.wLRND = {}\n",
    "#         self.bLRND = {}\n",
    "#         for foldNUM, (trainDataIN, trainLabelsIN, validDataIN, validLabelsIN, labelDict) in enumerate(genTrainValidFolds(featureDIR, oneHot=True)):\n",
    "#             print ('')\n",
    "#             print ('Validation Data and Labels shape: ', validDataIN.shape, validLabelsIN.shape)\n",
    "#             print ('Training Data and Labels shape: ', trainDataIN.shape, trainLabelsIN.shape)\n",
    "#             print ('The Label Dictionary is given as: ', labelDict)\n",
    "#             self.foldNUM = foldNUM\n",
    "            \n",
    "#             reset_graph()\n",
    "            \n",
    "#             # Build a class Object\n",
    "#             objNNET = BuildNeuralNet()\n",
    "            \n",
    "#             # Build the training Graph\n",
    "#             self.trainGraphDict = objNNET.trainNet(regularization=False)\n",
    "#             tpred, tacc, wLRND, bLRND = self.trainModel(trainDataIN, trainLabelsIN)\n",
    "            \n",
    "            \n",
    "#             reset_graph()\n",
    "            \n",
    "#             # Add all the weights and biases received from each training fold\n",
    "#             if updWghtBias:\n",
    "#                 if not (self.wLRND and self.bLRND):\n",
    "#                     self.wLRND = wLRND\n",
    "#                     self.bLRND = bLRND\n",
    "#                 else:\n",
    "#                     self.wLRND = self.sumWghtBias(self.wLRND, wLRND)\n",
    "#                     self.bLRND = self.sumWghtBias(self.bLRND, bLRND)\n",
    "\n",
    "                    \n",
    "#             self.validGraphDict = objNNET.crossValid(wLRND, bLRND)\n",
    "#             vpred, vacc = self.validateModel(validDataIN, validLabelsIN)\n",
    "            \n",
    "#             trainCM = confusionMatrix(trainLabelsIN,tpred)\n",
    "#             validCM = confusionMatrix(validLabelsIN,vpred)\n",
    "\n",
    "#             meanValidAcc += vacc\n",
    "#             print ('Confusion Matrix Training Set')\n",
    "#             print (trainCM)\n",
    "#             print ('')\n",
    "#             print ('Confusion Matrix CrossValid Set')\n",
    "#             print (validCM)\n",
    "            \n",
    "# #             if foldNUM ==2:\n",
    "# #                 break\n",
    "        \n",
    "#         # Test the cross validation accuracy for the nth-fold when the weights are averaged \n",
    "#         # Find the average of all the weights and biases from the training folds and take their average\n",
    "#         if updWghtBias:\n",
    "#             wLRND = {k: v/(foldNUM+1) for k, v in self.wLRND.items()} \n",
    "#             bLRND = {k: v/(foldNUM+1) for k, v in self.bLRND.items()} \n",
    "#             self.validGraphDict = objNNET.crossValid(wLRND, bLRND)\n",
    "#             vpred, vacc = self.validateModel(validDataIN, validLabelsIN)\n",
    "#             print (\"Fold: \" + str(self.foldNUM+1) + \", Aveaged Weight Cross Validation Accuracy= \" + \"{:.5f}\".format(vacc))\n",
    "        \n",
    "#         print ('')\n",
    "#         print ('The Mean crossValidation Accuracy is: ', meanValidAcc/(foldNUM+1))\n",
    "            \n",
    "            \n",
    "# SessionExec().execute(updWghtBias=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Running i is : 0\n",
    "# # Validation Data and Labels shape:  (1000, 162) (1000, 2)\n",
    "# # Training Data and Labels shape:  (9000, 162) (9000, 2)\n",
    "# # The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
    "# # Fold: 1, Iter: 10, Loss= 1.603019, Training Accuracy= 0.79000\n",
    "# # Fold: 1, Cross Validation Accuracy= 0.79200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "m = {}\n",
    "n = {} \n",
    "newDict = defaultdict(list)\n",
    "m['a'] = np.array([[1,2,3],[-1,3,-4]], dtype=float)\n",
    "n['a'] = np.array([[3,4,3],[-1,3,-4]], dtype=float)\n",
    "\n",
    "\n",
    "# print (np.abs(a-b))\n",
    "# print (np.sum(np.abs(a-b)))\n",
    "\n",
    "m['b'] = np.array([[5,4,1],[7,8,9]], dtype=float)\n",
    "n['b'] = np.array([[9,9,5],[-2,1,2]], dtype=float)\n",
    "\n",
    "for layer,val in n.items():\n",
    "    print (layer)\n",
    "    print (np.abs(val-m[layer]))\n",
    "    print (np.sum(np.abs(val-m[layer])))\n",
    "    print ('')\n",
    "    newDict[layer].append(np.sum(np.abs(val-m[layer])))\n",
    "    \n",
    "print (newDict)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
