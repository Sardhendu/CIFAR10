{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Packages:\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Model Packages import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "mydir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "sys.path.append(mydir)\n",
    "from DataGenerator import genTrainValidFolds\n",
    "\n",
    "\n",
    "# Packages for plot:\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "def reshape_data(dataset, labels=None, imageSize=32, numChannels=1, sample_size=None):\n",
    "    if sample_size:\n",
    "        dataset = dataset[:sample_size].reshape((-1,imageSize,imageSize,numChannels)) # To reshape the\n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        if labels:\n",
    "            numLabels = len(np.unique(labels))\n",
    "            labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    else:\n",
    "        dataset = dataset.reshape((-1,imageSize,imageSize,numChannels)) # To reshape the  \n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        if labels:\n",
    "            numLabels = len(np.unique(labels))\n",
    "            labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])\n",
    "\n",
    "\n",
    "def confusionMatrix(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (pd.crosstab(np.argmax(labels, 1), np.argmax(predictions, 1), rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Train, CrossValid and Test Graph:\n",
    "\n",
    "The below modules build a simple convolutional neural network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BuildConvNet():\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.imageSize = params['imageSize'],\n",
    "\n",
    "        self.numFolds = params['imageSize'],\n",
    "        \n",
    "        # Network Parameters\n",
    "        self.numLabels = params['imageSize'],\n",
    "        self.numChannels = params['imageSize'],               # numChannels -> For grayscale =1, for RGB =3\n",
    "                \n",
    "        # Convolution filter params\n",
    "        self.conv11_Kernel = params['imageSize'],             # Size of kernel for the first convolution layer\n",
    "        self.conv11_Stride = params['imageSize'],             # Strides for the first convolution layer filter \n",
    "        self.conv11_Depth = params['imageSize'],              # Number of kernels for the first convolution layer\n",
    "        self.conv12_Kernel = params['imageSize'],             # Size of kernel for the first convolution layer\n",
    "        self.conv12_Stride = params['imageSize'],             # Strides for the first convolution layer filter \n",
    "        self.conv12_Depth = params['imageSize'],              # Number of kernels for the first convolution layer\n",
    "        self.pool1_Kernel = params['imageSize'],              # Size of kernel for the first Pooling layer\n",
    "        self.pool1_Stride = params['imageSize'],              # Strides for the first Pooling layer filter\n",
    "        \n",
    "        self.conv21_Kernel = params['imageSize'],             # Size of kernel for the first convolution layer\n",
    "        self.conv21_Stride = params['imageSize'],             # Strides for the first convolution layer filter \n",
    "        self.conv21_Depth = params['imageSize'],              # Number of kernels for the first convolution layer\n",
    "        self.conv22_Kernel = params['imageSize'],             # Size of kernel for the first convolution layer\n",
    "        self.conv22_Stride = params['imageSize'],             # Strides for the first convolution layer filter \n",
    "        self.conv22_Depth = params['imageSize'],              # Number of kernels for the first convolution layer\n",
    "        self.pool2_Kernel = params['imageSize'],              # Size of kernel for the first Pooling layer\n",
    "        self.pool2_Stride = params['imageSize'],              # Strides for the second Pooling layer filte\n",
    "        \n",
    "        # Fully connected layer params\n",
    "        self.numHidden1 = params['imageSize'],                # numHiddenUnits for the fully connected layerr\n",
    "        self.numHidden2 = params['imageSize'],                # numHiddenUnits for the fully connected layer\n",
    "        \n",
    "        # Batch and Learning Variables     \n",
    "        self.epochs = params['imageSize'],\n",
    "        self.batchSize = params['imageSize'],\n",
    "        self.keepProb = params['imageSize'],\n",
    "        self.optimizerParam = params['imageSize'] \n",
    "\n",
    "\n",
    "        \n",
    "        # WEIGHTS AND BIASES\n",
    "        self.weights = {\n",
    "            'cv11_wght': tf.Variable(tf.random_normal([self.conv11_Kernel, self.conv11_Kernel, self.numChannels, self.conv11_Depth], seed=8753)),\n",
    "            'cv12_wght': tf.Variable(tf.random_normal([self.conv12_Kernel, self.conv12_Kernel, self.conv11_Depth, self.conv12_Depth], seed=231)),\n",
    "            'cv21_wght': tf.Variable(tf.random_normal([self.conv21_Kernel, self.conv21_Kernel, self.conv12_Depth, self.conv21_Depth], seed=4221)),\n",
    "            'cv22_wght': tf.Variable(tf.random_normal([self.conv22_Kernel, self.conv22_Kernel, self.conv21_Depth, self.conv22_1Depth], seed=680)),\n",
    "            'fc2_wght': tf.Variable(tf.random_normal([self.numHidden1, self.numHidden2], seed=598)),\n",
    "            'out_wght': tf.Variable(tf.random_normal([self.numHidden2, self.numLabels], seed=332))\n",
    "        }\n",
    "\n",
    "        self.biases = {\n",
    "            'cv11_bias': tf.Variable(tf.random_normal([self.conv11_Depth], seed=8767)),\n",
    "            'cv12_bias': tf.Variable(tf.random_normal([self.conv12_Depth], seed=9887)),\n",
    "            'cv21_bias': tf.Variable(tf.random_normal([self.conv21_Depth], seed=8767)),\n",
    "            'cv22_bias': tf.Variable(tf.random_normal([self.conv22_Depth], seed=9887)),\n",
    "            'fc1_bias': tf.Variable(tf.random_normal([self.numHidden1], seed=4323)),\n",
    "            'fc2_bias': tf.Variable(tf.random_normal([self.numHidden2], seed=4348)),\n",
    "            'out_bias': tf.Variable(tf.random_normal([self.numLabels], seed=9878))\n",
    "        }\n",
    "\n",
    "\n",
    "    def convLayer(self, x, w, b, s=1, nlModel='RELU'):\n",
    "        x = tf.nn.conv2d(x, w, [1,s,s,1], padding='SAME') # Same padding\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        if nlModel == 'RELU':\n",
    "            return tf.nn.relu(x)\n",
    "        elif nlModel == 'LOGIT':\n",
    "            return tf.sigmoid(x)\n",
    "\n",
    "\n",
    "    def poolLayer(self, x, k=2, s=2, poolType='MAX'):\n",
    "        if poolType=='MAX':\n",
    "            return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,s,s,1], padding='SAME')\n",
    "        elif poolType == 'AVG':\n",
    "            return tf.nn.avg_pool(data, ksize=[1,k,k,1], strides=[1,s,s,1], padding='SAME')\n",
    "\n",
    "        \n",
    "    def fcLayer(self, x, w, b, keepProb=None, nModel='RELU'):\n",
    "        x = tf.matmul(x, w) + b\n",
    "        if nModel=='RELU':\n",
    "            x = tf.nn.relu(x)\n",
    "        if nModel=='LOGIT':\n",
    "            x = tf.sigmoid(x)\n",
    "        if keepProb:\n",
    "            return tf.nn.dropout(x, keepProb, seed=6162)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "    def outputLayer(self, x, w, b):\n",
    "        x = tf.matmul(x, w) + b\n",
    "        return x, tf.nn.softmax(x)\n",
    "    \n",
    "            \n",
    "    # Convolutional Layer (Includes the convLayer and the max pool layer)\n",
    "    def convFeatureExtractor(self, x):\n",
    "        # Convolution and Pooling Layer 1\n",
    "        conv1 = self.convLayer(x, self.weights['cv11_wght'], self.biases['cv11_bias'], s=self.conv11_Stride)\n",
    "        conv1 = self.convLayer(conv1, self.weights['cv12_wght'], self.biases['cv12_bias'], s=self.conv12_Stride)\n",
    "        conv1 = self.poolLayer(conv1, k=self.pool1_Kernel, s=self.pool1_Stride)\n",
    "\n",
    "        # Convolution and Pooling Layer 2\n",
    "        conv2 = self.convLayer(conv2, self.weights['cv21_wgth'], self.biases['cv21_bias'], self.conv21_Stride)\n",
    "        conv2 = self.convLayer(conv2, self.weights['cv22_wgth'], self.biases['cv22_bias'], self.conv22_Stride)\n",
    "        conv2 = self.poolLayer(conv2, k=self.pool2_Kernel, s=self.pool2_Stride)\n",
    "        \n",
    "        # Get the features in flattened fashion\n",
    "        poolShape = conv2.get_shape().as_list()[1]\n",
    "        numConvFeatures = poolShape*poolShape*self.conv2Depth\n",
    "        convFeatures = tf.reshape(conv2, [-1, numConvFeatures])\n",
    "        \n",
    "        return convFeatures, numConvFeatures\n",
    "        \n",
    "        \n",
    "    # Create the training Graph Lineage\n",
    "    def trainGraph(self):\n",
    "        trainData = tf.placeholder(tf.float32, [None, self.imageSize, self.imageSize, self.numChannels])\n",
    "        trainLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "        # Convolutional Layer\n",
    "        convFeatures, numConvFeatures = self.convFeatureExtractor(trainData)\n",
    "        \n",
    "        # Fully connected layer : Reshape conv2 output to fit fully connected layer input\n",
    "        self.weights['fc1_wght'] =  tf.Variable(tf.random_normal([numConvFeatures, self.numHidden1], seed=6663))\n",
    "        fc1State = self.fcLayer(convFeatures, self.weights['fc1_wght'], self.biases['fc1_bias'], keepProb=self.keepProb['fc1'], nModel='RELU')  # = 0.5\n",
    "        \n",
    "        # Fully connected layer : Layer 2\n",
    "        fc2State = self.fcLayer(fc1State, self.weights['fc2_wght'], self.biases['fc2_bias'], keepProb=self.keepProb['fc2'], nModel='RELU')  # 0.75\n",
    "\n",
    "        # Output, or the Softmax layer\n",
    "        pred, outputState = self.outputLayer(fc2State, self.weights['out_wght'], self.biases['out_bias'])\n",
    "        \n",
    "        # Loss function and Optimization\n",
    "        lossCE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=trainLabels))\n",
    "        \n",
    "        if self.optimizerParam['optimizer'] == 'ADAM':\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.optimizerParam['learning_rate']).minimize(lossCE)\n",
    "        elif self.optimizerParam['optimizer'] == 'RMSPROP':\n",
    "            optimizer = tf.train.RMSPropOptimizer(learning_rate=self.optimizerParam['learning_rate'], \n",
    "                                                  momentum=self.optimizerParam['momentum']).minimize(lossCE)  # 0.0006  # 0.8\n",
    "        else:\n",
    "            print (\"Your provided optimizers do not match with any of the initialized optimizers: .........\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        return dict(\n",
    "            trainData=trainData, \n",
    "            trainLabels=trainLabels, \n",
    "            optimizer=optimizer, \n",
    "            lossCE=lossCE,\n",
    "            trainPred = outputState,\n",
    "            wghtNew = self.weights\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Create the Validation Graph Lineage\n",
    "    def validGraph(self):\n",
    "\n",
    "        validData = tf.placeholder(tf.float32, [None, self.imageSize, self.imageSize, self.numChannels])\n",
    "        validLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "        # Convolution and Pooling Layer 1\n",
    "        vconvFeatures, numConvFeatures = self.convFeatureExtractor(validData)\n",
    "        # Convolution and Pooling Layer 1\n",
    "#         vconv1 = self.convLayer(validData, self.weights['cv1_wght'], self.biases['cv1_bias'], s=self.conv1Stride)\n",
    "#         vconv1 = self.poolLayer(vconv1, k=self.pool1Kernel)\n",
    "\n",
    "#         # Convolution and Pooling Layer 2\n",
    "#         vconv2 = self.convLayer(vconv1, self.weights['cv2_wgth'], self.biases['cv2_bias'], self.conv2Stride)\n",
    "#         vconv2 = self.poolLayer(vconv2, k=self.pool2Kernel)\n",
    "        \n",
    "#         # Get the features in flattened fashion\n",
    "#         vpoolShape = vconv2.get_shape().as_list()[1]\n",
    "#         vnumConvFeatures = vpoolShape*vpoolShape*self.conv2Depth\n",
    "#         vconvFeatures = tf.reshape(vconv2, [-1, vnumConvFeatures])\n",
    "        \n",
    "        \n",
    "        # Fully connected layer/Hidden Layer 2 : Reshape conv2 output to fit fully connected layer input\n",
    "        vFc1State = self.fcLayer(vconvFeatures, self.weights['fc1_wght'], self.biases['fc1_bias'], nModel='RELU')\n",
    "        \n",
    "        # Fully connected layer/Hidden layer 2\n",
    "        vFc2State = self.fcLayer(vFc1State, self.weights['fc2_wght'], self.biases['fc2_bias'], nModel='RELU')\n",
    "\n",
    "\n",
    "        # Output Layer or the softmax layer\n",
    "        vPred, vOutState = self.outputLayer(vFc2State, self.weights['out_wght'], self.biases['out_bias'])\n",
    "\n",
    "\n",
    "        return dict(\n",
    "            validData = validData,\n",
    "            validLabels = validLabels,\n",
    "            validPred = vOutState\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Train, CrossValid and Test graph and evaluate Models:\n",
    "\n",
    "The below modules executes the graph given the input parameters and provides the training accuracy, validation accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SessionExec():\n",
    "    \n",
    "    def __init__(self, featureDIR, params):\n",
    "        self.featureDIR = featureDIR\n",
    "        \n",
    "        self.numFolds = params['numFolds']\n",
    "        self.epochs = params['epochs']\n",
    "        self.batchSize = params['batchSize']\n",
    "        self.imageSize = params['imageSize']\n",
    "        self.numChannels = params['numChannels']\n",
    "        \n",
    "        self.prevWghtDict = {}\n",
    "        self.wghtChngDict = defaultdict(list)\n",
    "        self.meanValidAcc = 0\n",
    "        self.loss_PerEpoch_PerFold = defaultdict(list)\n",
    "        self.trainacc_PerEpoch_PerFold = defaultdict(list)\n",
    "        self.validacc_PerEpoch_PerFold = defaultdict(list)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def captureWghtChange(self, wghtDict):   \n",
    "        for layer, wght_arr in wghtDict.items():\n",
    "#             print (layer)\n",
    "#             print (np.sum(np.abs(wght_arr-self.prevWghtDict[layer])))\n",
    "#             print ('********************')\n",
    "            self.wghtChngDict[layer].append(np.sum(np.abs(wght_arr-self.prevWghtDict[layer])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def trainModel(self, trainDataIN, trainLabelsIN, sess):    \n",
    "        numBatches = int(trainDataIN.shape[0]/self.batchSize)\n",
    "        for numBatch in np.arange(numBatches):\n",
    "#                     print ('Batch no: ', numBatch)\n",
    "#                     print (numBatch*self.batchSize,  (numBatch+1)*self.batchSize)\n",
    "            batchData = trainDataIN[numBatch*self.batchSize : (numBatch+1)*self.batchSize]\n",
    "            batchLabels = trainLabelsIN[numBatch*self.batchSize : (numBatch+1)*self.batchSize]\n",
    "\n",
    "            feed_dict = {self.trainGraphDict['trainData']: batchData,\n",
    "                         self.trainGraphDict['trainLabels']: batchLabels\n",
    "#                              self.trainGraphDict['keep_prob']: 0.7\n",
    "                    }\n",
    "\n",
    "            _, loss, tpred, wght = sess.run([self.trainGraphDict['optimizer'],\n",
    "                                        self.trainGraphDict['lossCE'],\n",
    "                                        self.trainGraphDict['trainPred'],\n",
    "                                        self.trainGraphDict['wghtNew']], feed_dict=feed_dict)\n",
    "            \n",
    "            if any(self.prevWghtDict):\n",
    "                self.captureWghtChange(wght)\n",
    "                self.prevWghtDict = wght\n",
    "            else:\n",
    "                self.prevWghtDict = wght\n",
    "                \n",
    "                \n",
    "            if ((numBatch+1)%10 == 0) or ((numBatch+1) == numBatches): \n",
    "                tacc = accuracy(tpred, batchLabels)\n",
    "                print (\"Fold: \" + str(self.foldNUM+1) + \n",
    "                       \", Epoch: \" + str(self.epoch+1)+ \n",
    "                       \", Mini Batch: \" + str(numBatch+1) + \n",
    "                       \", Loss= \" + \"{:.6f}\".format(loss) + \n",
    "                       \", Training Accuracy= \" + \"{:.5f}\".format(tacc))\n",
    "    \n",
    "        return loss, tacc\n",
    "    \n",
    "    \n",
    "    def validModel(self, validDataIN, validLabelsIN, sess):\n",
    "        feed_dict = {self.validGraphDict['validData']: validDataIN,\n",
    "                     self.validGraphDict['validLabels']: validLabelsIN\n",
    "#                              self.trainGraphDict['keep_prob']: 0.7\n",
    "                }\n",
    "\n",
    "        vpred = sess.run(self.validGraphDict['validPred'], feed_dict=feed_dict)\n",
    "        \n",
    "        vacc = accuracy(vpred, validLabelsIN)\n",
    "        print (\"Fold: \" + str(self.foldNUM+1) + \n",
    "                \", Epoch: \" + str(self.epoch+1)+ \n",
    "                \", Validation Accuracy= \" + \"{:.5f}\".format(vacc))\n",
    "        \n",
    "        return vpred, vacc \n",
    "        \n",
    "        \n",
    "    def execute(self):\n",
    "        meanValidAcc = 0\n",
    "        \n",
    "        for foldNUM, (trainDataIN, trainLabelsIN, validDataIN, validLabelsIN, labelDict) in enumerate(genTrainValidFolds(self.featureDIR, oneHot=True)):   \n",
    "            print ('')\n",
    "            print ('##########################################################################################')\n",
    "            trainDataIN, _ = reshape_data(trainDataIN, imageSize=self.imageSize, numChannels=self.numChannels)                                       \n",
    "            validDataIN, _ = reshape_data(validDataIN, imageSize=self.imageSize, numChannels=self.numChannels)\n",
    "            \n",
    "            print ('')\n",
    "            print ('Validation Data and Labels shape: ', validDataIN.shape, validLabelsIN.shape)\n",
    "            print ('Training Data and Labels shape: ', trainDataIN.shape, trainLabelsIN.shape)\n",
    "            print ('The Label Dictionary is given as: ', labelDict)\n",
    "            print ('')\n",
    "            \n",
    "            self.foldNUM = foldNUM\n",
    "\n",
    "            reset_graph()\n",
    "\n",
    "            # Create a object encapsulating the graph lineage\n",
    "            objCNN = BuildConvNet(params)\n",
    "            self.trainGraphDict = objCNN.trainGraph()\n",
    "            self.validGraphDict = objCNN.validGraph()\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.initialize_all_variables())\n",
    "\n",
    "                for epoch in range(self.epochs): \n",
    "                    self.epoch = epoch\n",
    "                    \n",
    "                    # Train The model for Epochs\n",
    "                    loss, tacc = self.trainModel(trainDataIN, trainLabelsIN, sess)\n",
    "                    print ('')\n",
    "                    \n",
    "                    # Validate the model for Epochs\n",
    "                    vpred, vacc = self.validModel(validDataIN, validLabelsIN, sess)\n",
    "                    print ('')\n",
    "                    \n",
    "                    self.loss_PerEpoch_PerFold[foldNUM+1].append(loss)\n",
    "                    self.trainacc_PerEpoch_PerFold[foldNUM+1].append(tacc)\n",
    "                    self.validacc_PerEpoch_PerFold[foldNUM+1].append(vacc)\n",
    "                    \n",
    "                    if (epoch+1)%10 ==0 or ((epoch+1) == self.epochs):\n",
    "                        validCM = confusionMatrix(validLabelsIN,vpred)\n",
    "                        print ('Confusion Matrix CrossValid Set')\n",
    "                        print (validCM)\n",
    "                        print ('')\n",
    "            \n",
    "            self.meanValidAcc += vpred\n",
    "            \n",
    "            if foldNUM == self.numFolds-1:\n",
    "                break\n",
    "                \n",
    "        return (self.wghtChngDict, \n",
    "                self.meanValidAcc/self.numFolds, \n",
    "                self.loss_PerEpoch_PerFold, \n",
    "                self.trainacc_PerEpoch_PerFold, \n",
    "                self.validacc_PerEpoch_PerFold)\n",
    "                \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1: Standarized Feature Set (ADAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################################################################\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 32, 32, 1) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 32, 32, 1) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "\n",
      "Fold: 1, Epoch: 1, Mini Batch: 10, Loss= 482034.500000, Training Accuracy= 64.45312\n",
      "Fold: 1, Epoch: 1, Mini Batch: 20, Loss= 166031.250000, Training Accuracy= 73.43750\n",
      "Fold: 1, Epoch: 1, Mini Batch: 30, Loss= 120033.960938, Training Accuracy= 67.96875\n",
      "Fold: 1, Epoch: 1, Mini Batch: 35, Loss= 106169.234375, Training Accuracy= 73.04688\n",
      "\n",
      "Fold: 1, Epoch: 1, Validation Accuracy= 79.10000\n",
      "\n",
      "Fold: 1, Epoch: 2, Mini Batch: 10, Loss= 69455.203125, Training Accuracy= 71.87500\n",
      "Fold: 1, Epoch: 2, Mini Batch: 20, Loss= 57183.703125, Training Accuracy= 73.43750\n",
      "Fold: 1, Epoch: 2, Mini Batch: 30, Loss= 57612.492188, Training Accuracy= 75.39062\n",
      "Fold: 1, Epoch: 2, Mini Batch: 35, Loss= 43618.523438, Training Accuracy= 74.21875\n",
      "\n",
      "Fold: 1, Epoch: 2, Validation Accuracy= 82.50000\n",
      "\n",
      "Fold: 1, Epoch: 3, Mini Batch: 10, Loss= 47333.812500, Training Accuracy= 73.04688\n",
      "Fold: 1, Epoch: 3, Mini Batch: 20, Loss= 37558.164062, Training Accuracy= 76.17188\n",
      "Fold: 1, Epoch: 3, Mini Batch: 30, Loss= 33404.691406, Training Accuracy= 77.34375\n",
      "Fold: 1, Epoch: 3, Mini Batch: 35, Loss= 32612.085938, Training Accuracy= 73.43750\n",
      "\n",
      "Fold: 1, Epoch: 3, Validation Accuracy= 83.40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STDbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/STD/batchData/\"\n",
    "EDGbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/EDG/batchData/\"\n",
    "HOGp1batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp1/batchData/\"   # dim =162\n",
    "HOGp2batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp2/batchData/\"   # dim =576\n",
    "HOGp3batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp3/batchData/\"\n",
    "\n",
    "featureDIR = STDbatch_dir\n",
    "\n",
    "params = dict(imageSize = 32,\n",
    "              seed = 2316,                 # Set the seeds for the random weights generator\n",
    "              numFolds = 1,\n",
    "              \n",
    "              # Network Parameters\n",
    "              numLabels = 2,\n",
    "              numChannels = 1,             # numChannels -> For grayscale =1, for RGB =3\n",
    "              \n",
    "              # Convolution filter params\n",
    "              conv11_Kernel = 5,             # Size of kernel for the first convolution layer\n",
    "              conv11_Stride = 2,             # Strides for the first convolution layer filter \n",
    "              conv11_Depth = 16,             # Number of kernels for the first convolution layer\n",
    "              conv12_Kernel = 3,             # Size of kernel for the first convolution layer\n",
    "              conv12_Stride = 2,             # Strides for the first convolution layer filter \n",
    "              conv12_Depth = 32,             # Number of kernels for the first convolution layer\n",
    "              pool1_Kernel = 2,             # Size of kernel for the first Pooling layer\n",
    "              pool1_Stride = 2,             # Strides for the first Pooling layer filter\n",
    "              \n",
    "              conv21_Kernel = 5,             # Size of kernel for the first convolution layer\n",
    "              conv21_Stride = 2,             # Strides for the first convolution layer filter \n",
    "              conv21_Depth = 16,             # Number of kernels for the first convolution layer\n",
    "              conv22_Kernel = 3,             # Size of kernel for the first convolution layer\n",
    "              conv22_Stride = 2,             # Strides for the first convolution layer filter \n",
    "              conv22_Depth = 32,             # Number of kernels for the first convolution layer\n",
    "              pool2_Kernel = 2,             # Size of kernel for the first Pooling layer\n",
    "              pool2_Stride = 2,             # Strides for the second Pooling layer filter\n",
    "\n",
    "              \n",
    "              numHidden1 = 1024,           # numHiddenUnits for the fully connected layerr\n",
    "              numHidden2 = 1024,            # numHiddenUnits for the fully connected layer\n",
    "              \n",
    "              # Learning Variables     \n",
    "              epochs = 20,\n",
    "              batchSize = 256,\n",
    "        \n",
    "              keepProb = dict(fc1=0.5, fc2=0.7),\n",
    "#               optimizerParam = dict(optimizer='RMSPROP', learning_rate=0.0008, momentum=0.8)\n",
    "              optimizerParam = dict(optimizer='ADAM', learning_rate=0.004)  # at 0.003 descents slowely, \n",
    "        )\n",
    "\n",
    "# print (params)\n",
    "\n",
    "(out, meanValidAcc, lossPerEpochPerFold, taccPerEpochPerFold, vaccPerEpochPerFold) = SessionExec(featureDIR, params).execute() \n",
    "\n",
    "print ('The mean Valid Accuracy is : ', meanValidAcc)\n",
    "# print ('The mean Valid Accuracy is : ', )\n",
    "# print ('The mean Valid Accuracy is : ', )\n",
    "# print ('The mean Valid Accuracy is : ', )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
