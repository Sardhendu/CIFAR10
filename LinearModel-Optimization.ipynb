{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display, Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import Tools\n",
    "\n",
    "from DataGenerator import genTrainValidFolds\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FunModel():\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.trainX = x\n",
    "        self.trainY = y\n",
    "        self.batchSize = self.trainX.shape[0]\n",
    "        \n",
    "    def lm(self, W, x=np.array([])):\n",
    "        # Not inclucing bias for now.\n",
    "        if x.size:\n",
    "            zt = np.dot(x,np.transpose(W))\n",
    "        else:\n",
    "            zt = np.dot(self.trainX, np.transpose(W))\n",
    "        return zt\n",
    "    \n",
    "    def logitSoftmax(self, W, x=np.array([])):\n",
    "        if x.size:\n",
    "            zt = self.lm(W,x)\n",
    "        else:\n",
    "            zt = self.lm(W)\n",
    "            \n",
    "        out_h = np.exp(zt)\n",
    "        return out_h / np.sum(out_h, axis=0)\n",
    "\n",
    "    def lossCrossEntropy(self, W, x=np.array([]), y=np.array([])):\n",
    "        noise = 1e-4\n",
    "        if x.size:\n",
    "#             print ('NOT EMPTY')\n",
    "            out_h = self.logitSoftmax(W,x)\n",
    "            avg_loss = np.sum(np.sum(-1 * y * np.log2(out_h + noise)))/x.shape[0]\n",
    "        else:\n",
    "#             print ('EMPTY')\n",
    "            out_h = self.logitSoftmax(W)\n",
    "            avg_loss = np.sum(np.sum(-1 * self.trainY * np.log2(out_h + noise)))/self.batchSize\n",
    "            \n",
    "        return avg_loss\n",
    "#         print (avg_loss)\n",
    "        \n",
    "    def calNumericalGradient(self, W):\n",
    "        \"\"\"\n",
    "            Esentially here we change each weight one after another and calculate the loss (each weight indicated to each cell in the weight \n",
    "            matrix of shape [10, 32*32]. Note after the loss for the a particular weight change is calculated, the weight is \n",
    "            put back to its oriinal value)\n",
    "        \n",
    "        \"\"\"\n",
    "        avg_loss = self.lossCrossEntropy(W)\n",
    "        grad = np.zeros(W.shape)\n",
    "        delta_h = 0.00001\n",
    "        \n",
    "        it = np.nditer(W, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        i = 0\n",
    "        while not it.finished:\n",
    "#             print ('pwpwpwpwpwpwpwp ', it.multi_index)\n",
    "#             print ('asasasasasasasasasasa')\n",
    "            i+=1\n",
    "            ix = it.multi_index\n",
    "            old_wght = W[ix]      # Get the Weight at Index 0,1 for first iteration\n",
    "            W[ix] = old_wght + delta_h\n",
    "            new_loss = self.lossCrossEntropy(W)   # Calculate the loss using the changed weight\n",
    "            W[ix] = old_wght                # Put the weight back to its original value\n",
    "#             print ('klklklkklkkkllklk', old_value)\n",
    "            \n",
    "            grad[ix] = (new_loss - avg_loss) / delta_h  # Compute the partial derivative\n",
    "            it.iternext()\n",
    "        print (i)\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running i is : 0\n",
      "Validation Data and Labels shape:  (5000, 1024) (5000, 10)\n",
      "Training Data and Labels shape:  (45000, 1024) (45000, 10)\n",
      "(10, 1024)\n",
      "(45000, 1024)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    for trainData, trainLabels, validData, validLabels in genTrainValidFolds():\n",
    "        print ('Validation Data and Labels shape: ', validData.shape, validLabels.shape)\n",
    "        print ('Training Data and Labels shape: ', trainData.shape, trainLabels.shape)\n",
    "        \n",
    "        # Generate a random W matrix\n",
    "        W = np.random.rand(10, 32*32) * 0.001\n",
    "        print (W.shape)\n",
    "        print (trainData.shape)\n",
    "        # create an object for the class KNN class\n",
    "        obj_LMO = FunModel(trainData, trainLabels)\n",
    "        # Calculate the loss using cross Entropy\n",
    "#         obj_LMO.lossCrossEntropy(W, x=trainData, y=trainLabels)\n",
    "        # Calculate the numerical gradient\n",
    "        print (obj_LMO.calNumericalGradient(W))\n",
    "\n",
    "\n",
    "        break\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4) [[1 2 3 4]\n",
      " [5 6 4 5]]\n",
      "\n",
      "(4,) [6 8 7 9]\n",
      "[[ 0.16666667  0.25        0.42857143  0.44444444]\n",
      " [ 0.83333333  0.75        0.57142857  0.55555556]]\n",
      "[[ 2  4  6 16]\n",
      " [25 36  8  5]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2,3, 4],[5,6,4,5]])\n",
    "b = sum(a)\n",
    "print (a.shape, a)\n",
    "print ()\n",
    "print (b.shape,b)\n",
    "c = np.array([[2, 2,2, 4],[5,6,2,1]])\n",
    "print (a/b)\n",
    "print (a*c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
