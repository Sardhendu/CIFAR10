{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Extraction: \n",
    "---------\n",
    "a> Mean Normalized image: For an object recongnition task or for other preprocessing task such as PCA to work well, We require that (i) The features have to be approximately zero mean, and (ii) The different features have similar variances to each other. With natural images like CIFAR-10, (ii) is already satisfied even without variance normalization, and so we won’t perform any variance normalization. However we would do mean normalization. The function that does it is: \"featureaMeanNorm\".\n",
    "   \n",
    "b> PCA: Principal component analysis a.k.a PCA is a dimensional reduction technique that uses concepts from singular value decomposition for rectangular matrices. It attempts to find the eigen vectors (basis of the original matrix) that captures the highest variation in each dimension. The resultant eigen vector matrix (U) is a orthogonal matrix with where the column vectors are orthogonal to each other. The new transformed matrix (\"x_rot\") can be obtained by doing (U_transpose.x). Dimensionality reduction can be obtained by taking the first few dimension from the new matrix \"x_rot\". For an image recognition task we, according to heuristics, it is wise to collect eigen vectors that explains 99% of the variance. This can be done using the eigen values.\n",
    "\n",
    "c> Whitening with PCA: Whitening is a smoothing concept. Adjecent pixels in an image are highly correlated. For a image recognition task providing the raw image as an input to the learning model is redundant because adjecent pixels are correlated. The goal of whitening is to make the input less redundant. It has two motive 1) The features are less co-reallated and 2) All the features have the same variance.\n",
    "\n",
    "   1. The input features are made uncorrelated using PCA.\n",
    "   2. The features are made to have unit variance by rescalling the features by divinding each element in the feature by the squareroot of the corresponding eigen value. This can be thought of as : The larger the eigen value (the more variance is captured by that feature vetor or eigen vector) the larger is the denominator the more the penalty.\n",
    "   \n",
    "   The formula looks like : x_PCAwhite(i) = x_rot(i) / square_root(λ(i)), where λ(i) is the eigen value for the ith vector in the new matrix (x_rot)\n",
    "   \n",
    "\n",
    "d> ZCA whitening: Unlike PCA_whitening, here we try keeping all the n dimension of the data, we dont reduce the dimension. ZCA transformation sometimes also called as \"Mahalanobis transformation\" is that it results in whitened data (x_ZCAwhite) that is as close as possible to the original data. The steps included here are.\n",
    "\n",
    "   1. Get the new transformed matrix:  x_rot =  U_transpose.x, where U is the eigen vector matrix.\n",
    "   2. Get the PCA whitened matrix: x_PCAwhite(i) = x_rot(i) / square_root(λ(i) + e), where e is epsilon, a small smoothing factor to identify edges.\n",
    "   1. Get the ZCA whitened matrix by retransforming the x_PCAwhite(i) as : x_ZCAwhite = U.x_PCAwhite where U is the same eigen vector matrix.\n",
    " \n",
    "e> Image Blurr and Edges:\n",
    "\n",
    "f> HOG: Histogram of oriented gradient captures the gradient magnitude and their orientation. Given a filter size, the filter slides throught the image and stores the magnitude of the gradients for the image (mostly edges in the image will have a high gradient shift) into respective bins of provided orientation. The sum of magnitude for each orientation per filter are the new HOG feature space. Here we use several filters with shape (2,2), (4,4), (5,5), (6,6) and stack them on top on one another and build a redundant feature space.\n",
    "\n",
    "g> RGB: Used for convolutional features (Implemented using Tensorflow)\n",
    "\n",
    "source: http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epsilon_noise = 0.1\n",
    "\n",
    "\n",
    "def featureStandarize(image_pxlvals):  # Preferable more for non-natural image like ()\n",
    "    return(image_pxlvals - 255.0/2)/255.0\n",
    "\n",
    "def featureaMeanNorm(image):           # A Preferable option for object recognition for CIFAR-10\n",
    "    '''\n",
    "        In object recognition task, the brightness or contrast of the pixels dont matter when trying to identify an object. \n",
    "        More formally, we are not interested in the mean intensity value of an image patch. Thus given a grayscale image we subtract\n",
    "        out this mean intensity of each feature (column) of the image from all the feature pixels as part of mean normalization.\n",
    "        np.mean(image, axis=0) --> The mean intensity vector corresponding to each feature column.\n",
    "    '''\n",
    "    return (image - np.mean(image, axis=0))\n",
    "\n",
    "\n",
    "\n",
    "def ZCA_whiteness(img):\n",
    "    img = featureaMeanNorm(img)\n",
    "    sigma_mat = np.dot(img,np.transpose(img))/img.shape[1]\n",
    "    u,s,_ = np.linalg.svd(sigma_mat)\n",
    "    img_rot = np.dot(np.transpose(u), img)\n",
    "#         x_reduced = np.dot(np.transpose(u[:,0:2]), x)#x_rot[:,0:2]\n",
    "    denominator = np.diag(1/pow(s+epsilon_noise,0.5))\n",
    "    PCA_whitening = np.dot(denominator, img_rot)\n",
    "    ZCA_whitening = np.dot(u, PCA_whitening)\n",
    "    return ZCA_whitening\n",
    "\n",
    "\n",
    "# We choose 18 orientation for the object recognition task\n",
    "class HOG:\n",
    "    def __init__(self, featureParams): \n",
    "        self.orienations = featureParams['orientations']\n",
    "        self.pixelsPerCell = featureParams['pixelsPerCell']\n",
    "        self.cellsPerBlock = featureParams['cellsPerBlock']\n",
    "        self.block_norm = featureParams['block_norm']\n",
    "        self.visualise = featureParams['visualise']\n",
    "        self.transform_sqrt = featureParams['transform_sqrt']\n",
    "\n",
    "    def describe(self, image):\n",
    "        # Use transform_sqrt for Power law Compression before processing the image to increase the accuracy\n",
    "        # Use visualise to return the image of the histogram\n",
    "        if self.visualise:\n",
    "            hist, hog_image = hog(image,\n",
    "                                orientations = self.orienations,\n",
    "                                pixels_per_cell = self.pixelsPerCell,\n",
    "                                cells_per_block = self.cellsPerBlock,\n",
    "                                visualise= self.visualise,\n",
    "                                transform_sqrt = self.transform_sqrt)\n",
    "            return hist, hog_image\n",
    "        else:\n",
    "            hog_image = hog(image,\n",
    "                                orientations = self.orienations,\n",
    "                                pixels_per_cell = self.pixelsPerCell,\n",
    "                                cells_per_block = self.cellsPerBlock,\n",
    "                                transform_sqrt = self.transform_sqrt)\n",
    "            return hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction():\n",
    "    \n",
    "    def __init__(self, augmentBY=None):        \n",
    "        featureParams1 = dict(orientations = 18, pixelsPerCell = (6, 6), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams2 = dict(orientations = 9, pixelsPerCell = (4, 4), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "\n",
    "        featureParams3_1 = dict(orientations = 9, pixelsPerCell = (2, 2), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams3_2 = dict(orientations = 9, pixelsPerCell = (4, 4), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams3_3 = dict(orientations = 9, pixelsPerCell = (6, 6), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams3_4 = dict(orientations = 9, pixelsPerCell = (8, 8), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "\n",
    "\n",
    "        self.obj_HOG_p1 = HOG(featureParams1)\n",
    "        self.obj_HOG_p2 = HOG(featureParams2)\n",
    "        self.obj_HOG_p3_1 = HOG(featureParams3_1)\n",
    "        self.obj_HOG_p3_2 = HOG(featureParams3_2)\n",
    "        self.obj_HOG_p3_3 = HOG(featureParams3_3)\n",
    "        self.obj_HOG_p3_4 = HOG(featureParams3_4)\n",
    "        \n",
    "        self.augmentBY = augmentBY\n",
    "        \n",
    "#         if self.augmentBY:\n",
    "#             seed = 462\n",
    "# #             randNumbers = random.sample(range(0, 4999), int(np.ceil(5000*(augmentBY/100))))\n",
    "#             randNumbers = np.random.randint(0,5000, int(np.ceil(5000*(augmentBY/100))))    # generate 3000 random numbers between 0 and 4900\n",
    "#             print ('Augmenting the data -> randNumber statistics: ' + \n",
    "#                    'min = %s ,'%np.min(randNumbers) + \n",
    "#                    'max = %s ,'%np.max(randNumbers) +\n",
    "#                    'Augmenting by = %s ,'%len(np.unique(randNumbers)))\n",
    "    \n",
    "    \n",
    "    def featureExtractor (self, imagePath, flip=None):\n",
    "        # Fetch the image into matrix form\n",
    "        img = cv2.imread(imagePath)\n",
    "        \n",
    "        # whether you want to flip the image horizontally or not:\n",
    "        if flip:\n",
    "#             print ('You have requested to flip the image, hence expect the outcome of all feature extractor to be flipped Horizontally')\n",
    "            img = cv2.flip(img,1)\n",
    "        \n",
    "        # Note tensor flow Fetches image in BGR format, hence converting it into RGB\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert the Image into Gray Scale\n",
    "        imgGRAY = cv2.cvtColor(imgRGB, cv2.COLOR_RGB2GRAY) \n",
    "\n",
    "        # Get the ZCA whitened feature set:\n",
    "        imgZCA = ZCA_whiteness(imgGRAY)\n",
    "\n",
    "        # Get normalized image\n",
    "        imgSTD = featureStandarize(imgGRAY)\n",
    "\n",
    "        # Blurr the Gray Scale Image using a Gaussian Blurr\n",
    "        imgBLR = cv2.GaussianBlur(imgGRAY, (3,3), 0)                 # The filer size is chosen to be 3 and the standard deviation for the distribution is 0\n",
    "\n",
    "        # Detect Edges using Canny Filter\n",
    "        imgEDG = cv2.Canny(imgBLR, 30, 150)                        # The minimum threshold value chosen is 60 and the maximum threshold chosen is 150\n",
    "\n",
    "        # Find the HOG features corresponding the parameter setting 1\n",
    "        imgHOGp1 = self.obj_HOG_p1.describe(imgGRAY)                 # We collect the HOG image pertaining to the first parameter settings\n",
    "\n",
    "        # Find the HOG features corresponding the parameter setting 2\n",
    "        imgHOGp2 = self.obj_HOG_p2.describe(imgGRAY)                 # We collect the HOG image pertaining to the first parameter settings\n",
    "\n",
    "        # MultiHOG kernels stack together, the HOG features corresponding the parameter setting 3\n",
    "        imgHOGp3_1 = self.obj_HOG_p3_1.describe(imgGRAY)             # We collect the HOG image pertaining to the first parameter settings\n",
    "        imgHOGp3_2 = self.obj_HOG_p3_2.describe(imgGRAY)\n",
    "        imgHOGp3_3 = self.obj_HOG_p3_3.describe(imgGRAY)\n",
    "        imgHOGp3_4 = self.obj_HOG_p3_4.describe(imgGRAY)\n",
    "\n",
    "        return (imgRGB, imgGRAY, imgZCA, imgSTD, imgBLR, imgEDG, imgHOGp1, imgHOGp2, imgHOGp3_1, imgHOGp3_2, imgHOGp3_3, imgHOGp3_4)\n",
    "\n",
    "\n",
    "\n",
    "    # This features Extraction is performed on augmented DataSet\n",
    "    def featureMatrixBuilder(self, pathTo_images, filenameArr, imageSize=32, mimNumImage=None, numChannels=3):\n",
    "        \n",
    "        datasetRGB = np.ndarray(shape=(len(filenameArr), imageSize, imageSize, numChannels), dtype='uint8')\n",
    "        datasetZCA = []\n",
    "        datasetSTD = []\n",
    "        datasetGRAY = []\n",
    "        datasetEDG = []\n",
    "        datasetHOGp1 = []\n",
    "        datasetHOGp2 = []\n",
    "        datasetHOGp3 = []\n",
    "        datasetHOGp4 = []\n",
    "\n",
    "        i = 0\n",
    "        for numImage, image in enumerate(filenameArr):\n",
    "            imagePath = os.path.join(pathTo_images, image)\n",
    "\n",
    "    #         print (numImage)\n",
    "            try:\n",
    "            \n",
    "                (imgRGB, imgGRAY, imgZCA, imgSTD, imgBLR, imgEDG, imgHOGp1, \n",
    "                 imgHOGp2, imgHOGp3_1, imgHOGp3_2, imgHOGp3_3, imgHOGp3_4) = self.featureExtractor(imagePath)\n",
    "                \n",
    "                datasetRGB[numImage,:] = imgRGB\n",
    "                datasetZCA.append(imgZCA.reshape((imageSize*imageSize)))\n",
    "                datasetSTD.append(imgSTD.reshape((imageSize*imageSize)))\n",
    "                datasetGRAY.append(imgGRAY.reshape((imageSize*imageSize)))\n",
    "                datasetEDG.append(imgEDG.reshape((imageSize*imageSize)))\n",
    "                datasetHOGp1.append(imgHOGp1)\n",
    "                datasetHOGp2.append(imgHOGp2)\n",
    "                datasetHOGp3.append(np.hstack((imgHOGp3_1,imgHOGp3_2,imgHOGp3_3)))\n",
    "                datasetHOGp4.append(np.hstack((imgHOGp3_1,imgHOGp3_2,imgHOGp3_3,imgHOGp3_4)))\n",
    "\n",
    "                if self.augmentBY:\n",
    "#                     if numImage in randNumbers:\n",
    "                    i += 1\n",
    "                    (imgRGB, imgGRAY, imgZCA, imgSTD, imgBLR, imgEDG, imgHOGp1, imgHOGp2, \n",
    "                     imgHOGp3_1, imgHOGp3_2, imgHOGp3_3, imgHOGp3_4) = self.featureExtractor(imagePath, flip=True)\n",
    "\n",
    "                    datasetZCA.append(imgZCA.reshape((imageSize*imageSize)))\n",
    "                    datasetSTD.append(imgSTD.reshape((imageSize*imageSize)))\n",
    "                    datasetGRAY.append(imgGRAY.reshape((imageSize*imageSize)))\n",
    "                    datasetEDG.append(imgEDG.reshape((imageSize*imageSize)))\n",
    "                    datasetHOGp1.append(imgHOGp1)\n",
    "                    datasetHOGp2.append(imgHOGp2)\n",
    "                    datasetHOGp3.append(np.hstack((imgHOGp3_1,imgHOGp3_2,imgHOGp3_3)))\n",
    "                    datasetHOGp4.append(np.hstack((imgHOGp3_1,imgHOGp3_2,imgHOGp3_3,imgHOGp3_4)))\n",
    "\n",
    "\n",
    "            except IOError as e:\n",
    "                print('Could not read:', image, ':', e, '- hence skipping.')\n",
    "                \n",
    "        print ('Augmented the datase by %s flipped images ', i)\n",
    "        return (datasetRGB.reshape((-1,imageSize*imageSize*numChannels)),\n",
    "                np.array(datasetZCA),\n",
    "                np.array(datasetSTD), \n",
    "                np.array(datasetGRAY),\n",
    "                np.array(datasetEDG), \n",
    "                np.array(datasetHOGp1), \n",
    "                np.array(datasetHOGp2), \n",
    "                np.array(datasetHOGp3),\n",
    "                np.array(datasetHOGp4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Matrix Generator:\n",
    "-------\n",
    "\n",
    "1. Loop through all the images, augments the data if needed.\n",
    "2. Calls class \"FeatureExtraction\", generates feature matrix\n",
    "3. Dumps the feature matrix as compressed pickle files in the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Capture the dimensions of the features\n",
    "\n",
    "def main(ImageDir, DataDir, augmentBY=None, forceDump=None, reduceDimension=None):\n",
    "    \n",
    "    obj_FeatureExtraction = FeatureExtraction(augmentBY=augmentBY)\n",
    "    \n",
    "    for image_dir in ImageDir:\n",
    "        objectName = os.path.basename(os.path.normpath(image_dir))\n",
    "        filenameArr =  os.listdir(image_dir)\n",
    "        print ('')\n",
    "        print ('The current image directory is: ', image_dir)\n",
    "        print ('The count of images in the directory is: ', len(filenameArr))\n",
    "        \n",
    "        (datasetRGB, datasetZCA, \n",
    "         datasetSTD, datasetGRAY,\n",
    "         datasetEDG, datasetHOGp1, \n",
    "         datasetHOGp2, datasetHOGp3, datasetHOGp4) = obj_FeatureExtraction.featureMatrixBuilder(image_dir, filenameArr)\n",
    "        \n",
    "        if reduceDimension:\n",
    "            decompose = PCA(n_components=reduceDimension)\n",
    "            datasetHOGp4 = decompose.fit_transform(datasetHOGp4)\n",
    "#             print(decompose.explained_variance_ratio_) \n",
    "\n",
    "        print ('RGB Feature DataSet: shape = ', datasetRGB.shape)\n",
    "        print ('ZCA whitened Feature DataSet: shape = ', datasetZCA.shape)\n",
    "        print ('Standarized Feature DataSet: shape = ', datasetSTD.shape)\n",
    "        print ('GrayScale Feature DataSet: shape = ', datasetGRAY.shape)\n",
    "        print ('Edge Feature DataSet: shape = ', datasetEDG.shape)\n",
    "        print ('HOG param1 Feature DataSet: shape = ', datasetHOGp1.shape)\n",
    "        print ('HOG param2 Feature DataSet: shape = ', datasetHOGp2.shape)\n",
    "        print ('HOG param3 Feature DataSet: shape = ', datasetHOGp3.shape)\n",
    "        print ('HOG param3 Feature DataSet: shape = ', datasetHOGp4.shape)\n",
    "        \n",
    "        \n",
    "        # Store feature diensions\n",
    "        rgbFeatureDim = datasetRGB.shape[1]\n",
    "        zcaFeatureDim = datasetZCA.shape[1]\n",
    "        stdFeatureDim = datasetSTD.shape[1]\n",
    "        grayFeatureDim = datasetGRAY.shape[1]\n",
    "        edgFeatureDim = datasetEDG.shape[1]\n",
    "        hogp1FeatureDim = datasetHOGp1.shape[1]\n",
    "        hogp2FeatureDim = datasetHOGp2.shape[1]\n",
    "        hogp3FeatureDim = datasetHOGp3.shape[1]\n",
    "        hogp4FeatureDim = datasetHOGp4.shape[1]\n",
    "\n",
    "        for data_dir in DataDir:        \n",
    "            if not os.path.exists(data_dir):\n",
    "                os.makedirs(data_dir)\n",
    "                \n",
    "            featureType = os.path.basename(os.path.normpath(data_dir))    \n",
    "            fileName = data_dir+objectName+\".pickle\"\n",
    "            # DUMP PICKLE FILES\n",
    "            if os.path.exists(fileName) and not forceDump:\n",
    "                print ('The path already exists, you should force the dump')\n",
    "            else:\n",
    "                try:\n",
    "                    with open(fileName, 'wb') as f:\n",
    "                        if featureType=='RGB':\n",
    "                            print ('Storing data for RGB Feature set')\n",
    "                            pickle.dump(datasetRGB, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        if featureType=='ZCA':\n",
    "                            print ('Storing data for ZCA Feature set')\n",
    "                            pickle.dump(datasetZCA, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        if featureType=='STD':\n",
    "                            print ('Storing data for STD Feature set')\n",
    "                            pickle.dump(datasetSTD, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        if featureType=='GRAY':\n",
    "                            print ('Storing data for GRAY Feature set')\n",
    "                            pickle.dump(datasetGRAY, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        elif featureType=='EDG':\n",
    "                            print ('Storing data for EDGE Feature set')\n",
    "                            pickle.dump(datasetEDG, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        elif featureType=='HOGp1':\n",
    "                            print ('Storing data for HOG p1 Feature set')\n",
    "                            pickle.dump(datasetHOGp1, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        elif featureType=='HOGp2':\n",
    "                            print ('Storing data for HOG p2 Feature set')\n",
    "                            pickle.dump(datasetHOGp2, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        elif featureType=='HOGp3':\n",
    "                            print ('Storing data for HOG p3 Feature set')\n",
    "                            pickle.dump(datasetHOGp3, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        elif featureType=='HOGp4':\n",
    "                            print ('Storing data for HOG p4 Feature set')\n",
    "                            pickle.dump(datasetHOGp4, f, pickle.HIGHEST_PROTOCOL)\n",
    "                except Exception as e:\n",
    "                    print('Unable to save data to', fileName1, ':', e)\n",
    "    return (rgbFeatureDim, zcaFeatureDim, stdFeatureDim, grayFeatureDim, \n",
    "            edgFeatureDim, hogp1FeatureDim, hogp2FeatureDim, hogp3FeatureDim, hogp4FeatureDim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN - Choose your Features (2-Class or 10-Class)\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClasses = 3\n",
    "augmentBY = False\n",
    "base_path = '/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/'\n",
    "\n",
    "airplaneDatapath = base_path + \"trainDataAirplane/\"\n",
    "autoDatapath = base_path + \"trainDataAuto/\"\n",
    "birdDatapath = base_path + \"trainDataBird/\"\n",
    "# catDatapath = base_path + \"trainDataCat/\"\n",
    "# deerDatapath = base_path + \"trainDataDeer/\"\n",
    "# dogDatapath = base_path + \"trainDataDog/\"\n",
    "# frogDatapath = base_path + \"trainDataFrog/\"\n",
    "# horseDatapath = base_path + \"trainDataHorse/\"\n",
    "# shipDatapath = base_path + \"trainDataShip/\"\n",
    "# truckDatapath = base_path + \"trainDataTruck/\"\n",
    "\n",
    "if numClasses == 10:\n",
    "    ImageDir = [airplaneDatapath, autoDatapath, birdDatapath, catDatapath, deerDatapath, dogDatapath, frogDatapath, horseDatapath, shipDatapath, truckDatapath]\n",
    "else:\n",
    "    ImageDir = [airplaneDatapath, autoDatapath, birdDatapath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The current image directory is:  /Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataAirplane/\n",
      "The count of images in the directory is:  5000\n",
      "Augmented the datase by %s flipped images  0\n",
      "RGB Feature DataSet: shape =  (5000, 3072)\n",
      "ZCA whitened Feature DataSet: shape =  (5000, 1024)\n",
      "Standarized Feature DataSet: shape =  (5000, 1024)\n",
      "GrayScale Feature DataSet: shape =  (5000, 1024)\n",
      "Edge Feature DataSet: shape =  (5000, 1024)\n",
      "HOG param1 Feature DataSet: shape =  (5000, 450)\n",
      "HOG param2 Feature DataSet: shape =  (5000, 576)\n",
      "HOG param3 Feature DataSet: shape =  (5000, 3105)\n",
      "HOG param3 Feature DataSet: shape =  (5000, 3249)\n",
      "Storing data for RGB Feature set\n",
      "Storing data for ZCA Feature set\n",
      "Storing data for GRAY Feature set\n",
      "Storing data for STD Feature set\n",
      "Storing data for EDGE Feature set\n",
      "Storing data for HOG p1 Feature set\n",
      "Storing data for HOG p2 Feature set\n",
      "Storing data for HOG p3 Feature set\n",
      "Storing data for HOG p4 Feature set\n",
      "\n",
      "The current image directory is:  /Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataAuto/\n",
      "The count of images in the directory is:  5000\n",
      "Augmented the datase by %s flipped images  0\n",
      "RGB Feature DataSet: shape =  (5000, 3072)\n",
      "ZCA whitened Feature DataSet: shape =  (5000, 1024)\n",
      "Standarized Feature DataSet: shape =  (5000, 1024)\n",
      "GrayScale Feature DataSet: shape =  (5000, 1024)\n",
      "Edge Feature DataSet: shape =  (5000, 1024)\n",
      "HOG param1 Feature DataSet: shape =  (5000, 450)\n",
      "HOG param2 Feature DataSet: shape =  (5000, 576)\n",
      "HOG param3 Feature DataSet: shape =  (5000, 3105)\n",
      "HOG param3 Feature DataSet: shape =  (5000, 3249)\n",
      "Storing data for RGB Feature set\n",
      "Storing data for ZCA Feature set\n",
      "Storing data for GRAY Feature set\n",
      "Storing data for STD Feature set\n",
      "Storing data for EDGE Feature set\n",
      "Storing data for HOG p1 Feature set\n",
      "Storing data for HOG p2 Feature set\n",
      "Storing data for HOG p3 Feature set\n",
      "Storing data for HOG p4 Feature set\n",
      "\n",
      "The current image directory is:  /Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataBird/\n",
      "The count of images in the directory is:  5000\n",
      "Augmented the datase by %s flipped images  0\n",
      "RGB Feature DataSet: shape =  (5000, 3072)\n",
      "ZCA whitened Feature DataSet: shape =  (5000, 1024)\n",
      "Standarized Feature DataSet: shape =  (5000, 1024)\n",
      "GrayScale Feature DataSet: shape =  (5000, 1024)\n",
      "Edge Feature DataSet: shape =  (5000, 1024)\n",
      "HOG param1 Feature DataSet: shape =  (5000, 450)\n",
      "HOG param2 Feature DataSet: shape =  (5000, 576)\n",
      "HOG param3 Feature DataSet: shape =  (5000, 3105)\n",
      "HOG param3 Feature DataSet: shape =  (5000, 3249)\n",
      "Storing data for RGB Feature set\n",
      "Storing data for ZCA Feature set\n",
      "Storing data for GRAY Feature set\n",
      "Storing data for STD Feature set\n",
      "Storing data for EDGE Feature set\n",
      "Storing data for HOG p1 Feature set\n",
      "Storing data for HOG p2 Feature set\n",
      "Storing data for HOG p3 Feature set\n",
      "Storing data for HOG p4 Feature set\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['RGB', 'ZCA', 'GRAY', 'STD', 'EDG', 'HOGp1', 'HOGp2', 'HOGp3', 'HOGp4']\n",
    "feature_paths = {}\n",
    "feature_batch_paths = {}\n",
    "\n",
    "if augmentBY==False:\n",
    "    maxNumImage = 5000    \n",
    "    for feature_name in feature_names:\n",
    "        if numClasses == 2:\n",
    "            feature_paths[feature_name] = base_path + \"featureModels/2-Class/regularFeatures/\" + feature_name + '/'\n",
    "            feature_batch_paths[feature_name] = base_path + \"featureModels/2-Class/regularFeatures/\" + feature_name + '/batch_data/'\n",
    "        else:\n",
    "            feature_paths[feature_name] = base_path + \"featureModels/10-Class/regularFeatures/\" + feature_name + '/'\n",
    "            feature_batch_paths[feature_name] = base_path + \"featureModels/10-Class/regularFeatures/\" + feature_name + '/batch_data/'\n",
    "elif augmentBY==True:\n",
    "    maxNumImage = 10000   # When all the images are augmented\n",
    "    for feature_name in feature_names:\n",
    "        if numClasses == 2:\n",
    "            feature_paths[feature_name] = base_path + \"featureModels/2-Class/augmentedFeatures/\" + feature_name + '/'\n",
    "            feature_batch_paths[feature_name] = base_path + \"featureModels/2-Class/augmentedFeatures/\" + feature_name + '/batch_data/'\n",
    "        else:\n",
    "            feature_paths[feature_name] = base_path + \"featureModels/10-Class/augmentedFeatures/\" + feature_name + '/'\n",
    "            feature_batch_paths[feature_name] = base_path + \"featureModels/10-Class/augmentedFeatures/\" + feature_name + '/batch_data/' \n",
    "else:\n",
    "    raise ValueError('None type provided for dataset required for Feature Extraction--> Augment or Not')\n",
    "\n",
    "    \n",
    "    \n",
    "DataDir = [feature_paths[feature_name] for feature_name in feature_names]\n",
    "\n",
    "\n",
    "(rgbFeatureDim, zcaFeatureDim, stdFeatureDim, grayFeatureDim,\n",
    " edgFeatureDim, hogp1FeatureDim, hogp2FeatureDim, hogp3FeatureDim, \n",
    " hogp4FeatureDim) = main(ImageDir, DataDir=DataDir, augmentBY=augmentBY, forceDump=True, reduceDimension=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-Fold Batch Generator: \n",
    "---------\n",
    "### The Below code calls the class CreateBatches \n",
    "\n",
    "1. Gets the pickled feature data from the directory, \n",
    "2. ranandomizes the data\n",
    "3. Divides the into train and test dataset. (In this case we dont code for test data as we have the test data as a different test file)\n",
    "4. Finally, the training data is converted into 10 folds and stored into the respective directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "# Get the current working directory\n",
    "# cwd = os.getcwd()\n",
    "# mydir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "# sys.path.append(mydir)\n",
    "\n",
    "from DataPreparation import CreateBatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Feature :\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 3072)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 3072)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 3072)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# RGB Feature Set\n",
    "#########################\n",
    "\n",
    "if augmentBY == False:\n",
    "    # Create 10 Batches and stores in into the provided Batch Directory for the Strandarized Feature set of Images\n",
    "    featureDim = rgbFeatureDim\n",
    "    numBatches =10\n",
    "    test_percntg = 0\n",
    "\n",
    "    obj_RGB = CreateBatches(dimensions=featureDim)\n",
    "    trainData, trainLabels, _, _, labelDict = obj_RGB.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['RGB'], test_percntg=test_percntg)\n",
    "\n",
    "    # print (labelDict)\n",
    "    for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_RGB.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "        obj_RGB.dumpBatches(feature_batch_paths['RGB'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCA Whitened Feature:\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 1024)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 1024)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# ZCA whitened Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the Strandarized Feature set of Images\n",
    "featureDim = zcaFeatureDim\n",
    "numBatches =10\n",
    "test_percntg = 0\n",
    "\n",
    "obj_ZCA = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_ZCA.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['ZCA'], test_percntg=test_percntg)\n",
    "\n",
    "# print (labelDict)\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_ZCA.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_ZCA.dumpBatches(feature_batch_paths['ZCA'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAY SCALE:\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 1024)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 1024)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# GRAY SCALE Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the GRAY SCALE Feature set of Images\n",
    "featureDim = 1024\n",
    "numBatches =10\n",
    "test_percntg = 0\n",
    "\n",
    "obj_GRAY = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_GRAY.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['GRAY'], test_percntg=test_percntg)\n",
    "\n",
    "# print (labelDict)\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_GRAY.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_GRAY.dumpBatches(feature_batch_paths['GRAY'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STD - Standarized Feature:\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 1024)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 1024)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Standarized Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the Strandarized Feature set of Images\n",
    "featureDim = stdFeatureDim\n",
    "numBatches =10\n",
    "test_percntg = 0\n",
    "\n",
    "obj_STD = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_STD.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['STD'], test_percntg=test_percntg)\n",
    "\n",
    "# print (labelDict)\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_STD.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_STD.dumpBatches(feature_batch_paths['STD'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDGE Feature:\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 1024)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 1024)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 1024)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Edge Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the Edge Feature set of Images\n",
    "featureDim = edgFeatureDim\n",
    "numBatches =10\n",
    "test_percntg=0\n",
    "\n",
    "obj_EDG = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_EDG.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['EDG'], test_percntg=test_percntg)\n",
    "\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_EDG.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_EDG.dumpBatches(feature_batch_paths['EDG'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG Feature :- One Kernel (6,6)  --> 18 Bins\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 450)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 450)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 450)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# HOG p1 Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the Hog Feature with first parameter settings for the set of Images\n",
    "featureDim=hogp1FeatureDim\n",
    "numBatches =10\n",
    "test_percntg=0\n",
    "\n",
    "obj_HOGp1 = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_HOGp1.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['HOGp1'], test_percntg=test_percntg)\n",
    "\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_HOGp1.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_HOGp1.dumpBatches(feature_batch_paths['HOGp1'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG Feature :- One Window (4,4) --> 18 Bins\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 576)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 576)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 576)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# HOG p2 Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the Hog Feature with first parameter settings for the set of Images\n",
    "featureDim=hogp2FeatureDim\n",
    "numBatches =10\n",
    "test_percntg=0\n",
    "\n",
    "obj_HOGp2 = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_HOGp2.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['HOGp2'], test_percntg=test_percntg)\n",
    "\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_HOGp2.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_HOGp2.dumpBatches(feature_batch_paths['HOGp2'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG Feature :- Three kernels (2,2),(4,4),(6,6) --> 9 Bins\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 3105)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 3105)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 3105)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# HOG p3 Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the Hog Feature with first parameter settings for the set of Images\n",
    "featureDim=hogp3FeatureDim\n",
    "numBatches =10\n",
    "test_percntg=0\n",
    "\n",
    "obj_HOGp3 = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_HOGp3.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['HOGp3'], test_percntg=test_percntg)\n",
    "\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_HOGp3.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_HOGp3.dumpBatches(feature_batch_paths['HOGp3'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG Feature :- Four Kernels (2,2),(4,4),(6,6)(8,8) -> {9 bins}\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed use for randomness is :  8653\n",
      "The training Data set size is :  (15000, 3249)\n",
      "The training Labels size is :  (15000,)\n",
      "The test Data set size is :  (0, 3249)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1500,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1500, 3249)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1500,)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# HOG p4 Feature Set\n",
    "#########################\n",
    "\n",
    "# Create 10 Batches and stores in into the provided Batch Directory for the Hog Feature with first parameter settings for the set of Images\n",
    "featureDim=hogp4FeatureDim\n",
    "numBatches =10\n",
    "test_percntg=0\n",
    "\n",
    "obj_HOGp4 = CreateBatches(dimensions=featureDim)\n",
    "trainData, trainLabels, _, _, labelDict = obj_HOGp4.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=feature_paths['HOGp4'], test_percntg=test_percntg)\n",
    "\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_HOGp4.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_HOGp4.dumpBatches(feature_batch_paths['HOGp4'], trnBatchData, trnBatchLabel, batchNum=batchNum, labelDict=labelDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}