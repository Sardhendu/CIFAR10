{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airplane_datapath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataAirplane/\"\n",
    "cat_datapath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataCat/\"\n",
    "\n",
    "featureSTDPath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/STD/\"\n",
    "featureEDGPath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/EDG/\"\n",
    "featureHOGPath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/HOG/\"\n",
    "\n",
    "featureSTDbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/STD/batchData/\"\n",
    "featureEDGbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/EDG/batchData/\"\n",
    "featureHOGbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/HOG/batchData/\"\n",
    "\n",
    "ImageDir = [airplane_datapath, cat_datapath]\n",
    "\n",
    "DataDir = [featureSTDPath, featureEDGPath]#, featureHOGPath]\n",
    "\n",
    "BatchDir = [featureSTDbatch_dir, featureEDGbatch_dir, featureHOGbatch_dir]\n",
    "\n",
    "# parentPath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We choose 18 orientation for the object recognition task\n",
    "class HOG:\n",
    "    def __init__(self, orientations = 18, pixelsPerCell = (8, 8),cellsPerBlock = (1, 1), block_norm='L1', visualise=False, transform_sqrt = False): \n",
    "        self.orienations = orientations\n",
    "        self.pixelsPerCell = pixelsPerCell\n",
    "        self.cellsPerBlock = cellsPerBlock\n",
    "        self.block_norm = block_norm\n",
    "        self.visualise = visualise\n",
    "        self.transform_sqrt = transform_sqrt\n",
    "\n",
    "    def describe(self, image):\n",
    "        # Use transform_sqrt for Power law Compression before processing the image to increase the accuracy\n",
    "        # Use visualise to return the image of the histogram\n",
    "        hist , hog_image= hog(image,\n",
    "                            orientations = self.orienations,\n",
    "                            pixels_per_cell = self.pixelsPerCell,\n",
    "                            cells_per_block = self.cellsPerBlock,\n",
    "                            visualise= self.visualise,\n",
    "                            transform_sqrt = transform_sqrt)\n",
    "#                             normalise = self.normalize)        # normalise is deprecated from the API\n",
    "\n",
    "        return hist, hog_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Below Process successfully creates the data set for the features:\n",
    "\n",
    "1. Standarized (Normalized) Image\n",
    "2. Image with Edge activation pixel\n",
    "3. Image with HOG Features (One Filter Type)\n",
    "4. To do ..... (HOG with multple filters)\n",
    "    \n",
    "The below code is generalized to store the features as ndarrays where,\n",
    "\n",
    "--> The number of rows are the number of images,\n",
    "--> The number of columns are the flattened feature set.\n",
    "\n",
    "The dataset is compressed into pickle files and stored in their respective directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image directory is:  /Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataAirplane/\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  95\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  142\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  139\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  125\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  269\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  82\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  208\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  120\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  65\n",
      "Count of Non Zero pixels entries in img are:  3067\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  169\n",
      "Count of Non Zero pixels entries in img are:  3072\n",
      "Count of Non Zero pixels entries in imgGS are:  1024\n",
      "Count of Non Zero pixels entries in imgBLR are:  1024\n",
      "Count of Non Zero pixels entries in imgEDG are:  202\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-6410f2915b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#         break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforceDump\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-6410f2915b49>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(forceDump)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'The image directory is: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdatasetSTD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetEDG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenameArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Standarized Feature DataSet '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetSTD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Edge Feature DataSet '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetEDG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-6410f2915b49>\u001b[0m in \u001b[0;36mfeatureExtraction\u001b[0;34m(pathTo_images, filenameArr, imageSize, mimNumImage, numChannels, HOG)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not read:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'- hence skipping.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatasetSTD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnumChannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetEDG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimageSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "def featureStandarize(image_pxlvals):\n",
    "    return(image_pxlvals - 255.0/2)/255.0\n",
    "\n",
    "\n",
    "def featureExtraction(pathTo_images, filenameArr, imageSize=32, mimNumImage=None, numChannels=3, HOG=None):\n",
    "    datasetSTD = np.ndarray(shape=(len(filenameArr), imageSize, imageSize), dtype=np.float32)\n",
    "    datasetEDG = np.ndarray(shape=(len(filenameArr), imageSize, imageSize), dtype=np.float32)\n",
    "    \n",
    "    for numImage, image in enumerate(filenameArr):\n",
    "        imagePath = os.path.join(pathTo_images, image)\n",
    "#         print (numImage)\n",
    "        try:\n",
    "            # Get the Image\n",
    "#             print ('The input image path is ', imagePath)\n",
    "            img = cv2.imread(imagePath)\n",
    "            print ('Count of Non Zero pixels entries in img are: ', len(np.where(np.reshape(img, 32*32*3)!=0)[0]))\n",
    "\n",
    "            \n",
    "            # Convert the Image into Gray Scale\n",
    "            imgGS = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "            print ('Count of Non Zero pixels entries in imgGS are: ', len(np.where(np.reshape(imgGS, 32*32)!=0)[0]))\n",
    "#             print (imgGS)\n",
    "            \n",
    "            # Get normalized image\n",
    "            imgSTD = featureStandarize(imgGS)\n",
    "            \n",
    "            # Blurr the Gray Scale Image using a Gaussian Blurr\n",
    "            imgBLR = cv2.GaussianBlur(imgGS, (3,3), 0)                # The filer size is chosen to be 3 and the standard deviation for the distribution is 0\n",
    "            print ('Count of Non Zero pixels entries in imgBLR are: ', len(np.where(np.reshape(imgBLR, 32*32)!=0)[0]))            \n",
    "            \n",
    "            # Detect Edges using Canny Filter\n",
    "            imgEDG = cv2.Canny(imgBLR, 30, 150)                        # The minimum threshold value chosen is 60 and the maximum threshold chosen is 150\n",
    "            print ('Count of Non Zero pixels entries in imgEDG are: ', len(np.where(np.reshape(imgEDG, 32*32)!=0)[0])) \n",
    "\n",
    "            datasetSTD[numImage, :] = imgSTD\n",
    "            datasetEDG[numImage, :] = imgEDG\n",
    "            \n",
    "            if numImage ==10:\n",
    "                break\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image, ':', e, '- hence skipping.')\n",
    "            \n",
    "    return datasetSTD.reshape((-1,imageSize*imageSize*numChannels)), datasetEDG.reshape((-1,imageSize*imageSize))\n",
    "           \n",
    "    \n",
    "def main(forceDump=None):\n",
    "    for image_dir in ImageDir:\n",
    "        objectName = os.path.basename(os.path.normpath(image_dir))\n",
    "        filenameArr =  os.listdir(image_dir)\n",
    "        \n",
    "        print ('The image directory is: ', image_dir)\n",
    "        datasetSTD, datasetEDG = featureExtraction(image_dir, filenameArr)\n",
    "        print ('Standarized Feature DataSet ', datasetSTD.shape)\n",
    "        print ('Edge Feature DataSet ', datasetEDG.shape)\n",
    "        \n",
    "#         for num, i in enumerate(datasetEDG):\n",
    "#             for j in i:\n",
    "#                 print (j)\n",
    "#             if num==10:\n",
    "#                 break\n",
    "                \n",
    "\n",
    "        for data_dir in DataDir:        \n",
    "            if not os.path.exists(data_dir):\n",
    "                os.makedirs(data_dir)\n",
    "                \n",
    "            featureType = os.path.basename(os.path.normpath(data_dir))    \n",
    "            fileName = data_dir+objectName+\".pickle\"\n",
    "\n",
    "            # DUMP PICKLE FILES\n",
    "            if os.path.exists(fileName) and not forceDump:\n",
    "                print ('The path already exists, you should force the dump')\n",
    "            else:\n",
    "                try:\n",
    "                    with open(fileName, 'wb') as f:\n",
    "                        if featureType=='STD':\n",
    "                            pickle.dump(datasetSTD, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        elif featureType=='EDG':\n",
    "                            pickle.dump(datasetEDG, f, pickle.HIGHEST_PROTOCOL)\n",
    "                except Exception as e:\n",
    "                    print('Unable to save data to', fileName1, ':', e)\n",
    "                    \n",
    "#         break\n",
    "    \n",
    "main(forceDump=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> The Below code calls the class CreateBatches. Class CreateBatches \n",
    "\n",
    "1. Gets the pickled feature data from the directory, \n",
    "2. ranandomize the data\n",
    "3. Divides the into train and test dataset. (In this case we dont code for test data as we have the test data as a different test file)\n",
    "4. Finally, the training data is converted into 10 folds and stored into the respective directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "mydir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "sys.path.append(mydir)\n",
    "\n",
    "from DataPreparation import CreateBatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training Data set size is :  (10000, 3072)\n",
      "The training Labels size is :  (10000,)\n",
      "The test Data set size is :  (0, 3072)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1000, 3072)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Create 10 Batches and stores in into the provided Batch Directory for the Strandarized Feature set of Images\n",
    "imageDim = 32*32*3\n",
    "numBatches =10\n",
    "maxNumImage = 5000\n",
    "test_percntg = 0\n",
    "\n",
    "root_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/STD/\"\n",
    "batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/STD/batchData/\"\n",
    "\n",
    "obj_STD = CreateBatches(dimensions=imageDim)\n",
    "trainData, trainLabels, testLabels, _, _ = obj_STD.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=root_dir, test_percntg=test_percntg)\n",
    "\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_STD.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_STD.dumpBatches(trnBatchData, trnBatchLabel, batch_dir, batchNum=batchNum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training Data set size is :  (10000, 1024)\n",
      "The training Labels size is :  (10000,)\n",
      "The test Data set size is :  (0, 1024)\n",
      "The test Labels size is :  (0,)\n",
      "Batch No:  0  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  0  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  1  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  1  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  2  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  2  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  3  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  3  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  4  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  4  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  5  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  5  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  6  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  6  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  7  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  7  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  8  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  8  : Training Batch Labels Shape : (1000,)\n",
      "Batch No:  9  : Training Batch Data Shape: (1000, 1024)\n",
      "Batch No:  9  : Training Batch Labels Shape : (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Create 10 Batches and stores in into the provided Batch Directory for the Edge Feature set of Images\n",
    "imageDim=32*32\n",
    "numBatches =10\n",
    "maxNumImage = 5000\n",
    "test_percntg=0\n",
    "\n",
    "root_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/EDG/\"\n",
    "batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Classification-1/EDG/batchData/\"\n",
    "\n",
    "obj_EDG = CreateBatches(dimensions=imageDim)\n",
    "trainData, trainLabels, testLabels, _, _ = obj_EDG.gen_TrainTestData(max_num_images=maxNumImage, dir_to_pickle_files=root_dir, test_percntg=test_percntg)\n",
    "\n",
    "for batchNum, (trnBatchData, trnBatchLabel) in enumerate(obj_EDG.generateBatches(dataset=trainData, labels=trainLabels, numBatches=numBatches)):\n",
    "    obj_EDG.dumpBatches(trnBatchData, trnBatchLabel, batch_dir, batchNum=batchNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
