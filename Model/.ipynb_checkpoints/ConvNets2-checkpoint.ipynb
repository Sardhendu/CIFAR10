{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Packages:\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Model Packages import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "mydir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "sys.path.append(mydir)\n",
    "from DataGenerator import genTrainValidFolds\n",
    "\n",
    "\n",
    "# Packages for plot:\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    \n",
    "def reshape_data(dataset, labels=None, imageSize=32, numChannels=1, sample_size=None):\n",
    "    if sample_size:\n",
    "        dataset = dataset[:sample_size].reshape((-1,imageSize,imageSize,numChannels)) # To reshape the\n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        if labels:\n",
    "            numLabels = len(np.unique(labels))\n",
    "            labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    else:\n",
    "        dataset = dataset.reshape((-1,imageSize,imageSize,numChannels)) # To reshape the  \n",
    "        # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "        if labels:\n",
    "            numLabels = len(np.unique(labels))\n",
    "            labels = (np.arange(numLabels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])\n",
    "\n",
    "\n",
    "def confusionMatrix(predictions, labels):\n",
    "    # Both the predictions and the labels should be in One-Hot vector format.\n",
    "    return (pd.crosstab(np.argmax(labels, 1), np.argmax(predictions, 1), rownames=['True'], colnames=['Predicted'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build the Graph : (Train, CrossValid and Test):\n",
    "---------\n",
    "The below modules builds a simple convolutional neural network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BuildConvNet():\n",
    "\n",
    "    def __init__(self, params):\n",
    "        self.imageSize = params['imageSize']\n",
    "\n",
    "        self.numFolds = params['numFolds']\n",
    "        \n",
    "        # Network Parameters\n",
    "        self.numLabels = params['numLabels']\n",
    "        self.numChannels = params['numChannels']                 # numChannels -> For grayscale =1, for RGB =3\n",
    "                \n",
    "        # Convolution filter params\n",
    "        self.conv11_Kernel = params['conv11_Kernel']             # Size of kernel for the first convolution layer\n",
    "        self.conv11_Stride = params['conv11_Stride']             # Strides for the first convolution layer filter \n",
    "        self.conv11_Depth = params['conv11_Depth']               # Number of kernels for the first convolution layer\n",
    "        self.conv12_Kernel = params['conv12_Kernel']             # Size of kernel for the first convolution layer\n",
    "        self.conv12_Stride = params['conv12_Stride']             # Strides for the first convolution layer filter \n",
    "        self.conv12_Depth = params['conv12_Depth']               # Number of kernels for the first convolution layer\n",
    "        self.pool1_Kernel = params['pool1_Kernel']               # Size of kernel for the first Pooling layer\n",
    "        self.pool1_Stride = params['pool1_Stride']               # Strides for the first Pooling layer filter\n",
    "        \n",
    "        self.conv21_Kernel = params['conv21_Kernel']             # Size of kernel for the first convolution layer\n",
    "        self.conv21_Stride = params['conv21_Stride']             # Strides for the first convolution layer filter \n",
    "        self.conv21_Depth = params['conv21_Depth']               # Number of kernels for the first convolution layer\n",
    "        self.conv22_Kernel = params['conv22_Kernel']             # Size of kernel for the first convolution layer\n",
    "        self.conv22_Stride = params['conv22_Stride']             # Strides for the first convolution layer filter \n",
    "        self.conv22_Depth = params['conv22_Depth']               # Number of kernels for the first convolution layer\n",
    "        self.pool2_Kernel = params['pool2_Kernel']               # Size of kernel for the first Pooling layer\n",
    "        self.pool2_Stride = params['pool2_Stride']               # Strides for the second Pooling layer filte\n",
    "        \n",
    "        # Fully connected layer params\n",
    "        self.numHidden1 = params['numHidden1']                   # numHiddenUnits for the fully connected layerr\n",
    "        self.numHidden2 = params['numHidden2']                   # numHiddenUnits for the fully connected layer\n",
    "        \n",
    "        # Batch and Learning Variables     \n",
    "        self.epochs = params['epochs']\n",
    "        self.batchSize = params['batchSize']\n",
    "        self.keepProb = params['keepProb']\n",
    "        self.optimizerParam = params['optimizerParam'] \n",
    "\n",
    "\n",
    "        \n",
    "        # WEIGHTS AND BIASES\n",
    "        self.weights = {\n",
    "            'cv11_wght': tf.Variable(tf.random_normal([self.conv11_Kernel, self.conv11_Kernel, self.numChannels, self.conv11_Depth], seed=8753)),\n",
    "            'cv12_wght': tf.Variable(tf.random_normal([self.conv12_Kernel, self.conv12_Kernel, self.conv11_Depth, self.conv12_Depth], seed=231)),\n",
    "            'cv21_wght': tf.Variable(tf.random_normal([self.conv21_Kernel, self.conv21_Kernel, self.conv12_Depth, self.conv21_Depth], seed=4221)),\n",
    "            'cv22_wght': tf.Variable(tf.random_normal([self.conv22_Kernel, self.conv22_Kernel, self.conv21_Depth, self.conv22_Depth], seed=680)),\n",
    "            'fc2_wght': tf.Variable(tf.random_normal([self.numHidden1, self.numHidden2], seed=598)),\n",
    "            'out_wght': tf.Variable(tf.random_normal([self.numHidden2, self.numLabels], seed=332))\n",
    "        }\n",
    "\n",
    "        self.biases = {\n",
    "            'cv11_bias': tf.Variable(tf.random_normal([self.conv11_Depth], seed=8767)),\n",
    "            'cv12_bias': tf.Variable(tf.random_normal([self.conv12_Depth], seed=9887)),\n",
    "            'cv21_bias': tf.Variable(tf.random_normal([self.conv21_Depth], seed=8767)),\n",
    "            'cv22_bias': tf.Variable(tf.random_normal([self.conv22_Depth], seed=9887)),\n",
    "            'fc1_bias': tf.Variable(tf.random_normal([self.numHidden1], seed=4323)),\n",
    "            'fc2_bias': tf.Variable(tf.random_normal([self.numHidden2], seed=4348)),\n",
    "            'out_bias': tf.Variable(tf.random_normal([self.numLabels], seed=9878))\n",
    "        }\n",
    "\n",
    "\n",
    "    def convLayer(self, x, w, b, s=1, nlModel='RELU'):\n",
    "        x = tf.nn.conv2d(x, w, [1,s,s,1], padding='SAME') # Same padding\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        if nlModel == 'RELU':\n",
    "            return tf.nn.relu(x)\n",
    "        elif nlModel == 'LOGIT':\n",
    "            return tf.sigmoid(x)\n",
    "\n",
    "\n",
    "    def poolLayer(self, x, k=2, s=2, poolType='MAX'):\n",
    "        if poolType=='MAX':\n",
    "            return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,s,s,1], padding='SAME')\n",
    "        elif poolType == 'AVG':\n",
    "            return tf.nn.avg_pool(data, ksize=[1,k,k,1], strides=[1,s,s,1], padding='SAME')\n",
    "\n",
    "        \n",
    "    def fcLayer(self, x, w, b, keepProb=None, nModel='RELU'):\n",
    "        x = tf.matmul(x, w) + b\n",
    "        if nModel=='RELU':\n",
    "            x = tf.nn.relu(x)\n",
    "        if nModel=='LOGIT':\n",
    "            x = tf.sigmoid(x)\n",
    "        if keepProb:\n",
    "            return tf.nn.dropout(x, keepProb, seed=6162)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "    def outputLayer(self, x, w, b):\n",
    "        x = tf.matmul(x, w) + b\n",
    "        return x, tf.nn.softmax(x)\n",
    "    \n",
    "            \n",
    "    # Convolutional Layer (Includes the convLayer and the max pool layer)\n",
    "    def convFeatureExtractor(self, x):\n",
    "        # Convolution and Pooling Layer 1\n",
    "        conv1 = self.convLayer(x, self.weights['cv11_wght'], self.biases['cv11_bias'], s=self.conv11_Stride)\n",
    "        # Add print here\n",
    "        conv1 = self.convLayer(conv1, self.weights['cv12_wght'], self.biases['cv12_bias'], s=self.conv12_Stride)\n",
    "        conv1 = self.poolLayer(conv1, k=self.pool1_Kernel, s=self.pool1_Stride)\n",
    "        # Add print here\n",
    "        # Convolution and Pooling Layer 2\n",
    "        conv2 = self.convLayer(conv1, self.weights['cv21_wght'], self.biases['cv21_bias'], self.conv21_Stride)\n",
    "        conv2 = self.convLayer(conv2, self.weights['cv22_wght'], self.biases['cv22_bias'], self.conv22_Stride)\n",
    "        conv2 = self.poolLayer(conv2, k=self.pool2_Kernel, s=self.pool2_Stride)\n",
    "        \n",
    "        # Get the features in flattened fashion\n",
    "        poolShape = conv2.get_shape().as_list()[1]\n",
    "        numConvFeatures = poolShape*poolShape*self.conv22_Depth\n",
    "        convFeatures = tf.reshape(conv2, [-1, numConvFeatures])\n",
    "        \n",
    "        return convFeatures, numConvFeatures\n",
    "        \n",
    "        \n",
    "    # Create the training Graph Lineage\n",
    "    def trainGraph(self):\n",
    "        trainData = tf.placeholder(tf.float32, [None, self.imageSize, self.imageSize, self.numChannels])\n",
    "        trainLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "        # Convolutional Layer\n",
    "        convFeatures, numConvFeatures = self.convFeatureExtractor(trainData)\n",
    "        \n",
    "        # Fully connected layer : Reshape conv2 output to fit fully connected layer input\n",
    "        self.weights['fc1_wght'] =  tf.Variable(tf.random_normal([numConvFeatures, self.numHidden1], seed=6663))\n",
    "        fc1State = self.fcLayer(convFeatures, self.weights['fc1_wght'], self.biases['fc1_bias'], keepProb=self.keepProb['fc1'], nModel='RELU')  # = 0.5\n",
    "        \n",
    "        # Fully connected layer : Layer 2\n",
    "        fc2State = self.fcLayer(fc1State, self.weights['fc2_wght'], self.biases['fc2_bias'], keepProb=self.keepProb['fc2'], nModel='RELU')  # 0.75\n",
    "\n",
    "        # Output, or the Softmax layer\n",
    "        pred, outputState = self.outputLayer(fc2State, self.weights['out_wght'], self.biases['out_bias'])\n",
    "        \n",
    "        # Loss function and Optimization\n",
    "        lossCE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=trainLabels))\n",
    "        \n",
    "        if self.optimizerParam['optimizer'] == 'ADAM':\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.optimizerParam['learning_rate']).minimize(lossCE)\n",
    "        elif self.optimizerParam['optimizer'] == 'RMSPROP':\n",
    "            optimizer = tf.train.RMSPropOptimizer(learning_rate=self.optimizerParam['learning_rate'], \n",
    "                                                  momentum=self.optimizerParam['momentum']).minimize(lossCE)  # 0.0006  # 0.8\n",
    "        else:\n",
    "            print (\"Your provided optimizers do not match with any of the initialized optimizers: .........\")\n",
    "            return None\n",
    "\n",
    "        \n",
    "        return dict(\n",
    "            trainData=trainData, \n",
    "            trainLabels=trainLabels, \n",
    "            optimizer=optimizer, \n",
    "            lossCE=lossCE,\n",
    "            trainPred = outputState,\n",
    "            wghtNew = self.weights\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Create the Validation Graph Lineage\n",
    "    def validGraph(self):\n",
    "\n",
    "        validData = tf.placeholder(tf.float32, [None, self.imageSize, self.imageSize, self.numChannels])\n",
    "        validLabels = tf.placeholder(tf.float32, [None, self.numLabels])\n",
    "\n",
    "        # Convolution and Pooling Layer 1\n",
    "        vconvFeatures, numConvFeatures = self.convFeatureExtractor(validData)\n",
    "        \n",
    "        # Fully connected layer/Hidden Layer 2 : Reshape conv2 output to fit fully connected layer input\n",
    "        vFc1State = self.fcLayer(vconvFeatures, self.weights['fc1_wght'], self.biases['fc1_bias'], nModel='RELU')\n",
    "        \n",
    "        # Fully connected layer/Hidden layer 2\n",
    "        vFc2State = self.fcLayer(vFc1State, self.weights['fc2_wght'], self.biases['fc2_bias'], nModel='RELU')\n",
    "\n",
    "\n",
    "        # Output Layer or the softmax layer\n",
    "        vPred, vOutState = self.outputLayer(vFc2State, self.weights['out_wght'], self.biases['out_bias'])\n",
    "\n",
    "\n",
    "        return dict(\n",
    "            validData = validData,\n",
    "            validLabels = validLabels,\n",
    "            validPred = vOutState\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Execute the Train, CrossValid and Test graph and evaluate Models:\n",
    "\n",
    "The below modules executes the graph given the input parameters and provides the training accuracy, validation accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SessionExec():\n",
    "    \n",
    "    def __init__(self, featureDIR, params):\n",
    "        self.featureDIR = featureDIR\n",
    "        \n",
    "        self.numFolds = params['numFolds']\n",
    "        self.epochs = params['epochs']\n",
    "        self.batchSize = params['batchSize']\n",
    "        self.imageSize = params['imageSize']\n",
    "        self.numChannels = params['numChannels']\n",
    "        \n",
    "        self.prevWghtDict = {}\n",
    "        self.wghtChngDict = defaultdict(list)\n",
    "        self.meanValidAcc = 0\n",
    "        self.loss_PerEpoch_PerFold = defaultdict(list)\n",
    "        self.trainacc_PerEpoch_PerFold = defaultdict(list)\n",
    "        self.validacc_PerEpoch_PerFold = defaultdict(list)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def captureWghtChange(self, wghtDict):   \n",
    "        for layer, wght_arr in wghtDict.items():\n",
    "#             print (layer)\n",
    "#             print (np.sum(np.abs(wght_arr-self.prevWghtDict[layer])))\n",
    "#             print ('********************')\n",
    "            self.wghtChngDict[layer].append(np.sum(np.abs(wght_arr-self.prevWghtDict[layer])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def trainModel(self, trainDataIN, trainLabelsIN, sess):    \n",
    "        numBatches = int(trainDataIN.shape[0]/self.batchSize)\n",
    "        for numBatch in np.arange(numBatches):\n",
    "#                     print ('Batch no: ', numBatch)\n",
    "#                     print (numBatch*self.batchSize,  (numBatch+1)*self.batchSize)\n",
    "            batchData = trainDataIN[numBatch*self.batchSize : (numBatch+1)*self.batchSize]\n",
    "            batchLabels = trainLabelsIN[numBatch*self.batchSize : (numBatch+1)*self.batchSize]\n",
    "\n",
    "            feed_dict = {self.trainGraphDict['trainData']: batchData,\n",
    "                         self.trainGraphDict['trainLabels']: batchLabels\n",
    "#                              self.trainGraphDict['keep_prob']: 0.7\n",
    "                    }\n",
    "\n",
    "            _, loss, tpred, wght = sess.run([self.trainGraphDict['optimizer'],\n",
    "                                        self.trainGraphDict['lossCE'],\n",
    "                                        self.trainGraphDict['trainPred'],\n",
    "                                        self.trainGraphDict['wghtNew']], feed_dict=feed_dict)\n",
    "            \n",
    "            if any(self.prevWghtDict):\n",
    "                self.captureWghtChange(wght)\n",
    "                self.prevWghtDict = wght\n",
    "            else:\n",
    "                self.prevWghtDict = wght\n",
    "                \n",
    "                \n",
    "            if ((numBatch+1)%10 == 0) or ((numBatch+1) == numBatches): \n",
    "                tacc = accuracy(tpred, batchLabels)\n",
    "                print (\"Fold: \" + str(self.foldNUM+1) + \n",
    "                       \", Epoch: \" + str(self.epoch+1)+ \n",
    "                       \", Mini Batch: \" + str(numBatch+1) + \n",
    "                       \", Loss= \" + \"{:.6f}\".format(loss) + \n",
    "                       \", Training Accuracy= \" + \"{:.5f}\".format(tacc))\n",
    "    \n",
    "        return loss, tacc\n",
    "    \n",
    "    \n",
    "    def validModel(self, validDataIN, validLabelsIN, sess):\n",
    "        feed_dict = {self.validGraphDict['validData']: validDataIN,\n",
    "                     self.validGraphDict['validLabels']: validLabelsIN\n",
    "#                              self.trainGraphDict['keep_prob']: 0.7\n",
    "                }\n",
    "\n",
    "        vpred = sess.run(self.validGraphDict['validPred'], feed_dict=feed_dict)\n",
    "        \n",
    "        vacc = accuracy(vpred, validLabelsIN)\n",
    "        print (\"Fold: \" + str(self.foldNUM+1) + \n",
    "                \", Epoch: \" + str(self.epoch+1)+ \n",
    "                \", Validation Accuracy= \" + \"{:.5f}\".format(vacc))\n",
    "        \n",
    "        return vpred, vacc \n",
    "        \n",
    "        \n",
    "    def execute(self):\n",
    "        meanValidAcc = 0\n",
    "        \n",
    "        for foldNUM, (trainDataIN, trainLabelsIN, validDataIN, validLabelsIN, labelDict) in enumerate(genTrainValidFolds(self.featureDIR, oneHot=True)):   \n",
    "            print ('')\n",
    "            print ('##########################################################################################')\n",
    "            trainDataIN, _ = reshape_data(trainDataIN, imageSize=self.imageSize, numChannels=self.numChannels)                                       \n",
    "            validDataIN, _ = reshape_data(validDataIN, imageSize=self.imageSize, numChannels=self.numChannels)\n",
    "            \n",
    "            print ('')\n",
    "            print ('Validation Data and Labels shape: ', validDataIN.shape, validLabelsIN.shape)\n",
    "            print ('Training Data and Labels shape: ', trainDataIN.shape, trainLabelsIN.shape)\n",
    "            print ('The Label Dictionary is given as: ', labelDict)\n",
    "            print ('')\n",
    "            \n",
    "            self.foldNUM = foldNUM\n",
    "\n",
    "            reset_graph()\n",
    "\n",
    "            # Create a object encapsulating the graph lineage\n",
    "            objCNN = BuildConvNet(params)\n",
    "            self.trainGraphDict = objCNN.trainGraph()\n",
    "            self.validGraphDict = objCNN.validGraph()\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.initialize_all_variables())\n",
    "\n",
    "                for epoch in range(self.epochs): \n",
    "                    self.epoch = epoch\n",
    "                    \n",
    "                    # Train The model for Epochs\n",
    "                    loss, tacc = self.trainModel(trainDataIN, trainLabelsIN, sess)\n",
    "                    print ('')\n",
    "                    \n",
    "                    # Validate the model for Epochs\n",
    "                    vpred, vacc = self.validModel(validDataIN, validLabelsIN, sess)\n",
    "                    print ('')\n",
    "                    \n",
    "                    self.loss_PerEpoch_PerFold[foldNUM+1].append(loss)\n",
    "                    self.trainacc_PerEpoch_PerFold[foldNUM+1].append(tacc)\n",
    "                    self.validacc_PerEpoch_PerFold[foldNUM+1].append(vacc)\n",
    "                    \n",
    "                    if (epoch+1)%10 ==0 or ((epoch+1) == self.epochs):\n",
    "                        validCM = confusionMatrix(validLabelsIN,vpred)\n",
    "                        print ('Confusion Matrix CrossValid Set')\n",
    "                        print (validCM)\n",
    "                        print ('')\n",
    "            \n",
    "            self.meanValidAcc += vpred\n",
    "            \n",
    "            if foldNUM == self.numFolds-1:\n",
    "                break\n",
    "                \n",
    "        return (self.wghtChngDict, \n",
    "                self.meanValidAcc/self.numFolds, \n",
    "                self.loss_PerEpoch_PerFold, \n",
    "                self.trainacc_PerEpoch_PerFold, \n",
    "                self.validacc_PerEpoch_PerFold)\n",
    "                \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MODEL 1: Standarized Feature Set (ADAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ZCAbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/ZCA/batchData/\"\n",
    "STDbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/STD/batchData/\"\n",
    "EDGbatch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/EDG/batchData/\"\n",
    "HOGp1batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp1/batchData/\"   # dim =162\n",
    "HOGp2batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp2/batchData/\"   # dim =576\n",
    "HOGp3batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp3/batchData/\"\n",
    "HOGp4batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/HOGp4/batchData/\"\n",
    "\n",
    "ZCAbatchAug_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/augmented/ZCA/batchData/\"\n",
    "STDbatchAug_dir= \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/augmented/STD/batchData/\"\n",
    "EDGbatchAug_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/augmented/EDG/batchData/\"\n",
    "HOGp1batchAug_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/augmented/HOGp1/batchData/\"\n",
    "HOGp2batchAug_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/augmented/HOGp2/batchData/\"\n",
    "HOGp3batchAug_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/augmented/HOGp3/batchData/\"\n",
    "HOGp4batchAug_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/Model-Sardhendu/augmented/HOGp4/batchData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Conv: Adam optimizer | Non-Augmented | Conv1 = [5x5x16, 3x3x32],  Conv2 = [5x5x16, 3x3x32], Hidden: 1024x1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################################################################\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 32, 32, 1) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 32, 32, 1) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "\n",
      "Fold: 1, Epoch: 1, Mini Batch: 10, Loss= 4192990.000000, Training Accuracy= 56.25000\n",
      "Fold: 1, Epoch: 1, Mini Batch: 20, Loss= 2341833.500000, Training Accuracy= 59.76562\n",
      "Fold: 1, Epoch: 1, Mini Batch: 30, Loss= 2619121.500000, Training Accuracy= 58.20312\n",
      "Fold: 1, Epoch: 1, Mini Batch: 35, Loss= 2277147.000000, Training Accuracy= 61.32812\n",
      "\n",
      "Fold: 1, Epoch: 1, Validation Accuracy= 69.80000\n",
      "\n",
      "Fold: 1, Epoch: 2, Mini Batch: 10, Loss= 1670977.250000, Training Accuracy= 62.89062\n",
      "Fold: 1, Epoch: 2, Mini Batch: 20, Loss= 1338647.250000, Training Accuracy= 67.18750\n",
      "Fold: 1, Epoch: 2, Mini Batch: 30, Loss= 1104146.750000, Training Accuracy= 65.62500\n",
      "Fold: 1, Epoch: 2, Mini Batch: 35, Loss= 1162913.250000, Training Accuracy= 64.84375\n",
      "\n",
      "Fold: 1, Epoch: 2, Validation Accuracy= 70.80000\n",
      "\n",
      "Fold: 1, Epoch: 3, Mini Batch: 10, Loss= 1075500.750000, Training Accuracy= 59.37500\n",
      "Fold: 1, Epoch: 3, Mini Batch: 20, Loss= 822401.750000, Training Accuracy= 67.18750\n",
      "Fold: 1, Epoch: 3, Mini Batch: 30, Loss= 920556.875000, Training Accuracy= 62.50000\n",
      "Fold: 1, Epoch: 3, Mini Batch: 35, Loss= 919047.750000, Training Accuracy= 60.93750\n",
      "\n",
      "Fold: 1, Epoch: 3, Validation Accuracy= 72.00000\n",
      "\n",
      "Fold: 1, Epoch: 4, Mini Batch: 10, Loss= 564961.625000, Training Accuracy= 66.40625\n",
      "Fold: 1, Epoch: 4, Mini Batch: 20, Loss= 644012.500000, Training Accuracy= 67.96875\n",
      "Fold: 1, Epoch: 4, Mini Batch: 30, Loss= 644334.750000, Training Accuracy= 59.76562\n",
      "Fold: 1, Epoch: 4, Mini Batch: 35, Loss= 579486.500000, Training Accuracy= 60.15625\n",
      "\n",
      "Fold: 1, Epoch: 4, Validation Accuracy= 71.00000\n",
      "\n",
      "Fold: 1, Epoch: 5, Mini Batch: 10, Loss= 496796.000000, Training Accuracy= 62.10938\n",
      "Fold: 1, Epoch: 5, Mini Batch: 20, Loss= 393152.093750, Training Accuracy= 68.35938\n",
      "Fold: 1, Epoch: 5, Mini Batch: 30, Loss= 517238.250000, Training Accuracy= 58.98438\n",
      "Fold: 1, Epoch: 5, Mini Batch: 35, Loss= 412501.531250, Training Accuracy= 62.50000\n",
      "\n",
      "Fold: 1, Epoch: 5, Validation Accuracy= 72.20000\n",
      "\n",
      "Fold: 1, Epoch: 6, Mini Batch: 10, Loss= 375932.750000, Training Accuracy= 62.50000\n",
      "Fold: 1, Epoch: 6, Mini Batch: 20, Loss= 313466.750000, Training Accuracy= 66.40625\n",
      "Fold: 1, Epoch: 6, Mini Batch: 30, Loss= 277754.593750, Training Accuracy= 62.89062\n",
      "Fold: 1, Epoch: 6, Mini Batch: 35, Loss= 300550.687500, Training Accuracy= 61.32812\n",
      "\n",
      "Fold: 1, Epoch: 6, Validation Accuracy= 71.80000\n",
      "\n",
      "Fold: 1, Epoch: 7, Mini Batch: 10, Loss= 247272.906250, Training Accuracy= 64.06250\n",
      "Fold: 1, Epoch: 7, Mini Batch: 20, Loss= 185714.078125, Training Accuracy= 68.35938\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a0fc4cd92c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# print (params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanValidAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossPerEpochPerFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaccPerEpochPerFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaccPerEpochPerFold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSessionExec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'The mean Valid Accuracy is : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanValidAcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3661ea84e533>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0;31m# Train The model for Epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabelsIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3661ea84e533>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(self, trainDataIN, trainLabelsIN, sess)\u001b[0m\n\u001b[1;32m     44\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainGraphDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lossCE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainGraphDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainPred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                                         self.trainGraphDict['wghtNew']], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevWghtDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "featureDIR = STDbatch_dir\n",
    "\n",
    "params = dict(imageSize = 32,\n",
    "              seed = 2316,                 # Set the seeds for the random weights generator\n",
    "              numFolds = 1,\n",
    "              \n",
    "              # Network Parameters\n",
    "              numLabels = 2,\n",
    "              numChannels = 1,             # numChannels -> For grayscale =1, for RGB =3\n",
    "              \n",
    "              # Convolution filter params\n",
    "              conv11_Kernel = 5,             # Size of kernel for the first convolution layer\n",
    "              conv11_Stride = 2,             # Strides for the first convolution layer filter \n",
    "              conv11_Depth = 16,             # Number of kernels for the first convolution layer\n",
    "              conv12_Kernel = 3,             # Size of kernel for the first convolution layer\n",
    "              conv12_Stride = 1,             # Strides for the first convolution layer filter \n",
    "              conv12_Depth = 32,             # Number of kernels for the first convolution layer\n",
    "              pool1_Kernel = 2,              # Size of kernel for the first Pooling layer\n",
    "              pool1_Stride = 2,              # Strides for the first Pooling layer filter\n",
    "              \n",
    "              conv21_Kernel = 5,             # Size of kernel for the first convolution layer\n",
    "              conv21_Stride = 2,             # Strides for the first convolution layer filter \n",
    "              conv21_Depth = 16,             # Number of kernels for the first convolution layer\n",
    "              conv22_Kernel = 3,             # Size of kernel for the first convolution layer\n",
    "              conv22_Stride = 2,             # Strides for the first convolution layer filter \n",
    "              conv22_Depth = 32,             # Number of kernels for the first convolution layer\n",
    "              pool2_Kernel = 2,              # Size of kernel for the first Pooling layer\n",
    "              pool2_Stride = 2,              # Strides for the second Pooling layer filter\n",
    "\n",
    "              \n",
    "              numHidden1 = 1024,             # numHiddenUnits for the fully connected layerr\n",
    "              numHidden2 = 1024,             # numHiddenUnits for the fully connected layer\n",
    "              \n",
    "              # Learning Variables     \n",
    "              epochs = 20,\n",
    "              batchSize = 256,\n",
    "        \n",
    "              keepProb = dict(fc1=0.7, fc2=0.5),\n",
    "#               optimizerParam = dict(optimizer='RMSPROP', learning_rate=0.0008, momentum=0.8)\n",
    "              optimizerParam = dict(optimizer='ADAM', learning_rate=0.0008)  # at 0.003 descents slowely, \n",
    "        )\n",
    "\n",
    "# print (params)\n",
    "\n",
    "(out, meanValidAcc, lossPerEpochPerFold, taccPerEpochPerFold, vaccPerEpochPerFold) = SessionExec(featureDIR, params).execute() \n",
    "\n",
    "print ('The mean Valid Accuracy is : ', meanValidAcc)\n",
    "# print ('The mean Valid Accuracy is : ', )\n",
    "# print ('The mean Valid Accuracy is : ', )\n",
    "# print ('The mean Valid Accuracy is : ', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
