{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import os, glob, sys\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "mydir = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "sys.path.append(mydir)\n",
    "from DataGenerator import genTrainValidFolds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Linear SVC with rbf and different gamma values\n",
    "class SVM_model():\n",
    "    def __init__(self, kernel, c_arr, gamma_arr):\n",
    "        self.c_arr = c_arr#[0.1, 1.0, 10.0]#, 1000.0]            \n",
    "        self.gamma_arr = gamma_arr#[0.1, 1, 10.0]\n",
    "        self.kernel=kernel\n",
    "\n",
    "    def classify(self, trainData, trainLabels, validData):\n",
    "        pred_dict = {}\n",
    "        for (c,gamma) in itertools.product(self.c_arr, self.gamma_arr):\n",
    "            string = \"c\" + str(c) + \"_\" + \"gamma\" + str(gamma)  \n",
    "#             print ('Running For: ', string)\n",
    "            clf = svm.SVC(kernel=self.kernel, C=c, gamma=gamma)\n",
    "            classifier = clf.fit(trainData,trainLabels)\n",
    "            pred_dict[string] = clf.predict(validData)\n",
    "        return pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Provide the directory of the batches so that we can generate the sequence one after one.\n",
    "\n",
    "def buildModel(c_arr, gamma_arr, FeatureDir):\n",
    "    objSVM = SVM_model(kernel='rbf', c_arr=c_arr, gamma_arr=gamma_arr)\n",
    "    estimatEach_c_gamma_Dict = {}\n",
    "    validLabelDict = {}\n",
    "    \n",
    "    for foldNUM, (trainData, trainLabels, validData, validLabels, labelDict) in enumerate(genTrainValidFolds(FeatureDir, oneHot=False)):\n",
    "        if foldNUM==0:\n",
    "            print ('Validation Data and Labels shape: ', validData.shape, validLabels.shape)\n",
    "            print ('Training Data and Labels shape: ', trainData.shape, trainLabels.shape)\n",
    "            print ('The Label Dictionary is given as: ', labelDict)\n",
    "            \n",
    "        print ('Cross-Vaidation Fold: ', foldNUM)\n",
    "        \n",
    "        estimatEach_c_gamma_Dict[foldNUM] = objSVM.classify(trainData=trainData, \n",
    "                                                        trainLabels=trainLabels, \n",
    "                                                        validData=validData)\n",
    "        \n",
    "        validLabelDict[foldNUM] = validLabels\n",
    "#         break\n",
    "    return estimatEach_c_gamma_Dict, validLabelDict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metric\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def performanceMetric(c_arr, gamma_arr, estimatEach_c_gamma_Dict, validLabelDict):\n",
    "    performanceDF = pd.DataFrame(np.NaN, index=[\"c\" + str(c) + \"_\" + \"gamma\" + str(gamma) for c, gamma in itertools.product(c_range, gamma_range)],\n",
    "                                            columns=['avg-numAirplaneClssified','avg-numCatClassified', 'avg-airplaneAccuracy', 'avg-catAccuracy','avg-totAccuracy'])\n",
    "\n",
    "    for foldNUM, c_gamma_prediction in  estimatEach_c_gamma_Dict.items():\n",
    "    #     print ('Running for cross validation fold : ', numFold)\n",
    "    #     print (c_gamma_prediction)\n",
    "        for c_gamma, estimates in c_gamma_prediction.items():\n",
    "#             print (c_gamma)\n",
    "            confusionMatrix = pd.crosstab(validLabelDict[foldNUM], estimates)\n",
    "#             print (confusionMatrix)\n",
    "            total = (sum(sum(np.array(confusionMatrix))))\n",
    "\n",
    "            if pd.isnull(performanceDF.ix[c_gamma, 'avg-numAirplaneClssified']):\n",
    "                performanceDF.ix[c_gamma, 'avg-numAirplaneClssified'] = confusionMatrix.ix[0,0]\n",
    "            else:\n",
    "                performanceDF.ix[c_gamma, 'avg-numAirplaneClssified'] = (performanceDF.ix[c_gamma, 'avg-numAirplaneClssified'] + \n",
    "                                                                      confusionMatrix.ix[0,0])\n",
    "\n",
    "            if pd.isnull(performanceDF.ix[c_gamma, 'avg-numCatClassified']):\n",
    "                performanceDF.ix[c_gamma, 'avg-numCatClassified'] = confusionMatrix.ix[1,1]\n",
    "            else:\n",
    "                performanceDF.ix[c_gamma, 'avg-numCatClassified'] = (performanceDF.ix[c_gamma, 'avg-numCatClassified'] + \n",
    "                                                                      confusionMatrix.ix[1,1])\n",
    "\n",
    "\n",
    "            if pd.isnull(performanceDF.ix[c_gamma, 'avg-airplaneAccuracy']):\n",
    "                performanceDF.ix[c_gamma, 'avg-airplaneAccuracy'] = confusionMatrix.ix[0,0]/(confusionMatrix.ix[0,0] + confusionMatrix.ix[0,1]) \n",
    "            else:\n",
    "                performanceDF.ix[c_gamma, 'avg-airplaneAccuracy'] = (performanceDF.ix[c_gamma, 'avg-airplaneAccuracy'] + \n",
    "                                                                      confusionMatrix.ix[0,0]/(confusionMatrix.ix[0,0] + confusionMatrix.ix[0,1]))\n",
    "\n",
    "            if pd.isnull(performanceDF.ix[c_gamma, 'avg-catAccuracy']):\n",
    "                performanceDF.ix[c_gamma, 'avg-catAccuracy'] = confusionMatrix.ix[1,1]/(confusionMatrix.ix[1,0] + confusionMatrix.ix[1,1]) \n",
    "            else:\n",
    "                performanceDF.ix[c_gamma, 'avg-catAccuracy'] = (performanceDF.ix[c_gamma, 'avg-catAccuracy'] + \n",
    "                                                                      confusionMatrix.ix[1,1]/(confusionMatrix.ix[1,0] + confusionMatrix.ix[1,1]))\n",
    "\n",
    "\n",
    "            if pd.isnull(performanceDF.ix[c_gamma, 'avg-totAccuracy']):\n",
    "                performanceDF.ix[c_gamma, 'avg-totAccuracy'] = (confusionMatrix.ix[0,0] + confusionMatrix.ix[1,1])/total\n",
    "            else:\n",
    "                performanceDF.ix[c_gamma, 'avg-totAccuracy'] = (performanceDF.ix[c_gamma, 'avg-totAccuracy'] + \n",
    "                                                                      ((confusionMatrix.ix[0,0] + confusionMatrix.ix[1,1])/total))\n",
    "\n",
    "    return performanceDF/(foldNUM+1)\n",
    "\n",
    "# performanceDF\n",
    "\n",
    "\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models:\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HOGp1batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/featureModels/HOGp1/batchData/\"\n",
    "HOGp2batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/featureModels/HOGp2/batchData/\"\n",
    "HOGp3batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/featureModels/HOGp3/batchData/\"\n",
    "HOGp4batch_dir = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/featureModels/HOGp4/batchData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG | Orientation=18 | kernel: (9,9) | c_arr = [0.1, 1.0, 10.0] |  gamma_arr = [0.1, 1.0, 10.0]\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Validation Data and Labels shape:  (1000, 162) (1000,)\n",
      "Training Data and Labels shape:  (9000, 162) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "--- 1565.5211040973663 seconds --- 26.09201853275299 minutes--- 0.4348669766717487 hours\n"
     ]
    }
   ],
   "source": [
    "c_arr = [0.1, 1.0, 10.0]#, 1000.0]            \n",
    "gamma_arr = [0.1, 1, 10.0]\n",
    "\n",
    "FeatureDir = HOGp1batch_dir\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "estimatEach_c_gamma_Dict, validLabelDict = buildModel(c_arr=c_arr, gamma_arr=gamma_arr, FeatureDir=FeatureDir)\n",
    "\n",
    "print(\"--- %s seconds \" % (time.time() - start_time) + \n",
    "      '--- %s minutes' %str((time.time() - start_time)/60) + \n",
    "      '--- %s hours' %str((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-numAirplaneClssified</th>\n",
       "      <th>avg-numCatClassified</th>\n",
       "      <th>avg-airplaneAccuracy</th>\n",
       "      <th>avg-catAccuracy</th>\n",
       "      <th>avg-totAccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.1</th>\n",
       "      <td>396.7</td>\n",
       "      <td>445.1</td>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma1</th>\n",
       "      <td>430.0</td>\n",
       "      <td>434.9</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma10.0</th>\n",
       "      <td>499.5</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.1</th>\n",
       "      <td>419.4</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma1</th>\n",
       "      <td>433.6</td>\n",
       "      <td>444.6</td>\n",
       "      <td>0.8672</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma10.0</th>\n",
       "      <td>472.9</td>\n",
       "      <td>252.6</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.5052</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.1</th>\n",
       "      <td>427.2</td>\n",
       "      <td>442.4</td>\n",
       "      <td>0.8544</td>\n",
       "      <td>0.8848</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma1</th>\n",
       "      <td>434.2</td>\n",
       "      <td>440.8</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma10.0</th>\n",
       "      <td>470.5</td>\n",
       "      <td>272.8</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.5456</td>\n",
       "      <td>0.7433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 avg-numAirplaneClssified  avg-numCatClassified  \\\n",
       "c0.1_gamma0.1                       396.7                 445.1   \n",
       "c0.1_gamma1                         430.0                 434.9   \n",
       "c0.1_gamma10.0                      499.5                  27.1   \n",
       "c1.0_gamma0.1                       419.4                 439.6   \n",
       "c1.0_gamma1                         433.6                 444.6   \n",
       "c1.0_gamma10.0                      472.9                 252.6   \n",
       "c10.0_gamma0.1                      427.2                 442.4   \n",
       "c10.0_gamma1                        434.2                 440.8   \n",
       "c10.0_gamma10.0                     470.5                 272.8   \n",
       "\n",
       "                 avg-airplaneAccuracy  avg-catAccuracy  avg-totAccuracy  \n",
       "c0.1_gamma0.1                  0.7934           0.8902           0.8418  \n",
       "c0.1_gamma1                    0.8600           0.8698           0.8649  \n",
       "c0.1_gamma10.0                 0.9990           0.0542           0.5266  \n",
       "c1.0_gamma0.1                  0.8388           0.8792           0.8590  \n",
       "c1.0_gamma1                    0.8672           0.8892           0.8782  \n",
       "c1.0_gamma10.0                 0.9458           0.5052           0.7255  \n",
       "c10.0_gamma0.1                 0.8544           0.8848           0.8696  \n",
       "c10.0_gamma1                   0.8684           0.8816           0.8750  \n",
       "c10.0_gamma10.0                0.9410           0.5456           0.7433  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performanceDF = performanceMetric(c_arr=c_arr, \n",
    "                                  gamma_arr=gamma_arr,\n",
    "                                  estimatEach_c_gamma_Dict=estimatEach_c_gamma_Dict, \n",
    "                                  validLabelDict=validLabelDict)\n",
    "performanceDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG | Orientation=18 | kernel: (6,6) | c_arr = [0.1, 1.0, 10.0] |  gamma_arr = [0.1, 1.0, 10.0]\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/featureModels/HOGp1/batchData/\n",
      "Validation Data and Labels shape:  (1000, 1152) (1000,)\n",
      "Training Data and Labels shape:  (9000, 1152) (9000,)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "Cross-Vaidation Fold:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f3bdfe03d8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mestimatEach_c_gamma_Dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidLabelDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_arr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_arr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureDir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFeatureDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m print(\"--- %s seconds \" % (time.time() - start_time) + \n",
      "\u001b[0;32m<ipython-input-4-3fcaf09c91dc>\u001b[0m in \u001b[0;36mbuildModel\u001b[0;34m(c_arr, gamma_arr, FeatureDir)\u001b[0m\n\u001b[1;32m     16\u001b[0m         estimatEach_c_gamma_Dict[foldNUM] = objSVM.classify(trainData=trainData, \n\u001b[1;32m     17\u001b[0m                                                         \u001b[0mtrainLabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                                         validData=validData)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mvalidLabelDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfoldNUM\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidLabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2147b1fe1c70>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, trainData, trainLabels, validData)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#             print ('Running For: ', string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mpred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c_arr = [0.1, 1.0, 10.0]#, 1000.0]            \n",
    "gamma_arr = [0.1, 1, 10.0]\n",
    "\n",
    "FeatureDir = HOGp1batch_dir\n",
    "print (FeatureDir)\n",
    "start_time = time.time()\n",
    "\n",
    "estimatEach_c_gamma_Dict, validLabelDict = buildModel(c_arr=c_arr, gamma_arr=gamma_arr, FeatureDir=FeatureDir)\n",
    "\n",
    "print(\"--- %s seconds \" % (time.time() - start_time) + \n",
    "      '--- %s minutes' %str((time.time() - start_time)/60) + \n",
    "      '--- %s hours' %str((time.time() - start_time)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
