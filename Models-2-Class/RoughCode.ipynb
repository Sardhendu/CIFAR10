{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let us start a interactive session\n",
    "####################################\n",
    "# An interactive session. Ones Interactive session is called \n",
    "# then it means that the session we used to intiate the interactice \n",
    "# console would be the default session used to perform all the tensor operation\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BATCH NORM:\n",
    "\n",
    "Batch norm is a technique to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.5  3.5  4.5]\n",
      "[[-1.5 -1.5 -1.5]\n",
      " [ 1.5  1.5  1.5]]\n",
      "[[ 2.25  2.25  2.25]\n",
      " [ 2.25  2.25  2.25]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "N, D = x.shape\n",
    "\n",
    "mu = 1./N * np.sum(x, axis = 0)\n",
    "\n",
    "print (mu)\n",
    "\n",
    "xmu = x - mu\n",
    "\n",
    "print (xmu)\n",
    "\n",
    "sq = xmu ** 2\n",
    "\n",
    "print (sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) [[1 2 3]\n",
      " [4 5 6]]\n",
      "(3,) [ 2.5  3.5  4.5]\n",
      "(2, 3) [[-1.5 -1.5 -1.5]\n",
      " [ 1.5  1.5  1.5]]\n",
      "(2, 3) [[ 2.25  2.25  2.25]\n",
      " [ 2.25  2.25  2.25]]\n",
      "(3,) [ 2.25  2.25  2.25]\n",
      "(3,) [ 1.50332964  1.50332964  1.50332964]\n",
      "(3,) [ 0.66519011  0.66519011  0.66519011]\n",
      "(2, 3) [[-0.99778516 -0.99778516 -0.99778516]\n",
      " [ 0.99778516  0.99778516  0.99778516]]\n",
      "(2, 3) [[ -9.97785158e-03  -9.97785158e-04  -9.97785158e-05]\n",
      " [  9.97785158e-03   9.97785158e-04   9.97785158e-05]]\n",
      "(2, 3) [[ 0.99002215  1.99900221  2.99990022]\n",
      " [ 1.00997785  2.00099779  3.00009978]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "def batchnorm_forward(x, gamma=None, beta=None, eps=None):\n",
    "    N, D = x.shape\n",
    "    print (x.shape, x)\n",
    "    #step1: calculate mean\n",
    "    mu = 1./N * np.sum(x, axis = 0)\n",
    "    print (mu.shape, mu)\n",
    "    \n",
    "    #step2: subtract mean vector of every trainings example\n",
    "    xmu = x - mu\n",
    "    print (xmu.shape, xmu)\n",
    "    \n",
    "    #step3: following the lower branch - calculation denominator\n",
    "    sq = xmu ** 2\n",
    "    print (sq.shape, sq)\n",
    "    \n",
    "    #step4: calculate variance\n",
    "    var = 1./N * np.sum(sq, axis = 0)\n",
    "    print (var.shape, var)\n",
    "    \n",
    "    #step5: add eps for numerical stability, then sqrt\n",
    "    sqrtvar = np.sqrt(var + eps)\n",
    "    print (sqrtvar.shape, sqrtvar)\n",
    "    \n",
    "    #step6: invert sqrtwar\n",
    "    ivar = 1./sqrtvar\n",
    "    print (ivar.shape, ivar)\n",
    "    \n",
    "    #step7: execute normalization\n",
    "    xhat = xmu * ivar\n",
    "    print (xhat.shape, xhat)\n",
    "    \n",
    "    #step8: Nor the two transformation steps\n",
    "    gammax = gamma * xhat\n",
    "    print (gammax.shape, gammax)\n",
    "    \n",
    "    #step9\n",
    "    out = gammax + beta\n",
    "    print (out.shape, out)\n",
    "#     #store intermediate\n",
    "#     cache = (xhat,gamma,xmu,ivar,sqrtvar,var,eps)\n",
    "    \n",
    "#     return out, cache\n",
    "\n",
    "\n",
    "batchnorm_forward(x, gamma = np.array([0.01, 0.001, 0.0001]), beta=np.array([1,2,3]), eps = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of a is  (2, 3, 3)\n",
      "sum along 0 axis \n",
      " [[ 5.  5.  5.]\n",
      " [ 4.  6.  5.]\n",
      " [ 5.  6.  7.]]\n",
      "sum along 1 axis \n",
      " [[  7.  10.  13.]\n",
      " [  7.   7.   4.]]\n",
      "sum along 2 axis \n",
      " [[  6.   9.  15.]\n",
      " [  9.   6.   3.]]\n",
      "2.52631578947\n",
      "(2, 3, 3)\n",
      "[[[ 1.  2.  3.]\n",
      "  [ 2.  3.  4.]\n",
      "  [ 4.  5.  6.]]\n",
      "\n",
      " [[ 4.  3.  2.]\n",
      "  [ 2.  3.  1.]\n",
      "  [ 1.  1.  1.]]]\n",
      "(2, 3, 3)\n",
      "2.66666666667 2.11111111111\n",
      "<tensorflow.python.training.moving_averages.ExponentialMovingAverage object at 0x11bc94128>\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[[1,2,3],\n",
    "               [2,3,4],\n",
    "               [4,5,6]],\n",
    "              [[4,3,2],\n",
    "               [2,3,1],\n",
    "               [1,1,1]]\n",
    "             ], dtype=\"float64\")\n",
    "print ('The shape of a is ', a.shape)\n",
    "print ('sum along 0 axis \\n', np.sum(a, axis=0))\n",
    "print ('sum along 1 axis \\n', np.sum(a, axis=1))\n",
    "print ('sum along 2 axis \\n', np.sum(a, axis=2))\n",
    "sum_a1 = sum(sum(sum(a)))\n",
    "print (sum_a1/19)\n",
    "# print (sum(sum_a1))\n",
    "# print ('')\n",
    "# prin \n",
    "print (a.shape)\n",
    "tf_a = tf.stack(a)\n",
    "\n",
    "# tf_a = tf.Variable(a, shape=tf.get_shape())\n",
    "print (tf_a.eval())\n",
    "print (tf_a.get_shape())\n",
    "\n",
    "# get the moment \n",
    "batchMean, batchVar = tf.nn.moments(tf_a, [0,1,2], name='moments')\n",
    "print (batchMean.eval(), batchVar.eval())\n",
    "ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "print (ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "m = {}\n",
    "n = {} \n",
    "newDict = defaultdict(list)\n",
    "m['a'] = np.array([[1,2,3],[-1,3,-4]], dtype=float)\n",
    "n['a'] = np.array([[3,4,3],[-1,3,-4]], dtype=float)\n",
    "\n",
    "\n",
    "# print (np.abs(a-b))\n",
    "# print (np.sum(np.abs(a-b)))\n",
    "\n",
    "m['b'] = np.array([[5,4,1],[7,8,9]], dtype=float)\n",
    "n['b'] = np.array([[9,9,5],[-2,1,2]], dtype=float)\n",
    "\n",
    "for layer,val in n.items():\n",
    "    print (layer)\n",
    "    print (np.abs(val-m[layer]))\n",
    "    print (np.sum(np.abs(val-m[layer])))\n",
    "    print ('')\n",
    "    newDict[layer].append(np.sum(np.abs(val-m[layer])))\n",
    "    \n",
    "print (newDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HOG:\n",
    "    def __init__(self, featureParams): \n",
    "        self.orienations = featureParams['orientations']\n",
    "        self.pixelsPerCell = featureParams['pixelsPerCell']\n",
    "        self.cellsPerBlock = featureParams['cellsPerBlock']\n",
    "        self.block_norm = featureParams['block_norm']\n",
    "        self.visualise = featureParams['visualise']\n",
    "        self.transform_sqrt = featureParams['transform_sqrt']\n",
    "\n",
    "    def describe(self, image):\n",
    "        # Use transform_sqrt for Power law Compression before processing the image to increase the accuracy\n",
    "        # Use visualise to return the image of the histogram\n",
    "        if self.visualise:\n",
    "            hist, hog_image = hog(image,\n",
    "                                orientations = self.orienations,\n",
    "                                pixels_per_cell = self.pixelsPerCell,\n",
    "                                cells_per_block = self.cellsPerBlock,\n",
    "                                visualise= self.visualise,\n",
    "                                transform_sqrt = self.transform_sqrt)\n",
    "            return hist, hog_image\n",
    "        else:\n",
    "            hog_image = hog(image,\n",
    "                                orientations = self.orienations,\n",
    "                                pixels_per_cell = self.pixelsPerCell,\n",
    "                                cells_per_block = self.cellsPerBlock,\n",
    "                                transform_sqrt = self.transform_sqrt)\n",
    "            return hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataAirplane/10009.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-4b666d669c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m         (imgHOGp1,imgHOGp2,imgHOGp3,imgHOGp4,imgHOGp5,\n\u001b[1;32m     88\u001b[0m          \u001b[0mimgHOGp6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHOGp7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHOGp8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHOGp9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgHOGp10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m          imgHOGp11,imgHOGp12,imgHOGp13,imgHOGp14) = obj_Preprocess.featureExtractor(imagePath)\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgHOGp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgHOGp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-4b666d669c0c>\u001b[0m in \u001b[0;36mfeatureExtractor\u001b[0;34m(self, imagePath)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mimgHOGp6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_HOG_p6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGS_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mimgHOGp7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_HOG_p7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGS_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mimgHOGp8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_HOG_p8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGS_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mimgHOGp9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_HOG_p9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGS_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mimgHOGp10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_HOG_p10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgGS_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-db64af0596b2>\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                 \u001b[0mpixels_per_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixelsPerCell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                 \u001b[0mcells_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcellsPerBlock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                 transform_sqrt = self.transform_sqrt)\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhog_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/skimage/feature/_hog.py\u001b[0m in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, visualise, transform_sqrt, feature_vector, normalise)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mn_blocksy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_cellsy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     normalised_blocks = np.zeros((n_blocksy, n_blocksx,\n\u001b[0;32m--> 181\u001b[0;31m                                   by, bx, orientations))\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_blocksx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: negative dimensions are not allowed"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "class Preprocess(): \n",
    "    \n",
    "    def __init__(self):        \n",
    "        featureParams1 = dict(orientations = 9, pixelsPerCell = (6, 6), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams2 = dict(orientations = 9, pixelsPerCell = (5, 10), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams3 = dict(orientations = 9, pixelsPerCell = (10, 5), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        \n",
    "        featureParams4 = dict(orientations = 18, pixelsPerCell = (6, 6), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams5 = dict(orientations = 18, pixelsPerCell = (5, 10), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams6 = dict(orientations = 18, pixelsPerCell = (10, 5), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        \n",
    "        \n",
    "        featureParams7 = dict(orientations = 9, pixelsPerCell = (6, 6), cellsPerBlock = (3, 3), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams8 = dict(orientations = 9, pixelsPerCell = (5, 10), cellsPerBlock = (1, 4), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams9 = dict(orientations = 9, pixelsPerCell = (10, 5), cellsPerBlock = (5, 2), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        \n",
    "        featureParams10 = dict(orientations = 18, pixelsPerCell = (6, 6), cellsPerBlock = (3, 3), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams11 = dict(orientations = 18, pixelsPerCell = (5, 10), cellsPerBlock = (2, 5), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams12 = dict(orientations = 18, pixelsPerCell = (10, 5), cellsPerBlock = (5, 2), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        \n",
    "        featureParams13 = dict(orientations = 18, pixelsPerCell = (5, 10), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        featureParams14 = dict(orientations = 18, pixelsPerCell = (10, 5), cellsPerBlock = (1, 1), block_norm = 'L1', visualise = False, transform_sqrt = True)\n",
    "        \n",
    "\n",
    "        self.obj_HOG_p1 = HOG(featureParams1)\n",
    "        self.obj_HOG_p2 = HOG(featureParams2)\n",
    "        self.obj_HOG_p3 = HOG(featureParams3)\n",
    "        self.obj_HOG_p4 = HOG(featureParams4)\n",
    "        self.obj_HOG_p5 = HOG(featureParams5)\n",
    "        self.obj_HOG_p6 = HOG(featureParams6)\n",
    "        self.obj_HOG_p7 = HOG(featureParams7)\n",
    "        self.obj_HOG_p8 = HOG(featureParams8)\n",
    "        self.obj_HOG_p9 = HOG(featureParams9)\n",
    "        self.obj_HOG_p10 = HOG(featureParams10)\n",
    "        self.obj_HOG_p11 = HOG(featureParams11)\n",
    "        self.obj_HOG_p12 = HOG(featureParams12)\n",
    "        self.obj_HOG_p13 = HOG(featureParams13)\n",
    "        self.obj_HOG_p14 = HOG(featureParams14)\n",
    "#         self.obj_HOG_p15 = HOG(featureParams15)\n",
    "#         self.obj_HOG_p3_3 = HOG(featureParams3_3)\n",
    "#         self.obj_HOG_p3_4 = HOG(featureParams3_4)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def featureExtractor (self, imagePath):\n",
    "        # Fetch the image into matrix form\n",
    "        img = cv2.imread(imagePath)\n",
    "\n",
    "        # Note tensor flow Fetches image in BGR format, hence converting it into RGB\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert the Image into Gray Scale\n",
    "        imgGS = cv2.cvtColor(imgRGB, cv2.COLOR_RGB2GRAY) \n",
    "        \n",
    "        imgGS_crop = imgGS[1:31, 1:31]\n",
    "\n",
    "        # Find the HOG features corresponding the parameter setting 1\n",
    "        imgHOGp1 = self.obj_HOG_p1.describe(imgGS_crop)\n",
    "        imgHOGp2 = self.obj_HOG_p2.describe(imgGS_crop)\n",
    "        imgHOGp3 = self.obj_HOG_p3.describe(imgGS_crop)\n",
    "        imgHOGp4 = self.obj_HOG_p4.describe(imgGS_crop)\n",
    "        imgHOGp5 = self.obj_HOG_p5.describe(imgGS_crop)\n",
    "        imgHOGp6 = self.obj_HOG_p6.describe(imgGS_crop)\n",
    "        imgHOGp7 = self.obj_HOG_p7.describe(imgGS_crop)\n",
    "        imgHOGp8 = self.obj_HOG_p8.describe(imgGS_crop)\n",
    "        imgHOGp9 = self.obj_HOG_p9.describe(imgGS_crop)\n",
    "        imgHOGp10 = self.obj_HOG_p10.describe(imgGS_crop)\n",
    "        imgHOGp11 = self.obj_HOG_p11.describe(imgGS_crop)\n",
    "        imgHOGp12 = self.obj_HOG_p12.describe(imgGS_crop)\n",
    "        imgHOGp13 = self.obj_HOG_p13.describe(imgGS_crop)\n",
    "        imgHOGp14 = self.obj_HOG_p14.describe(imgGS_crop)\n",
    "#         imgHOGp15 = self.obj_HOG_p11.describe(imgGS_crop)\n",
    "\n",
    "        return (imgHOGp1,imgHOGp2,imgHOGp3,imgHOGp4,imgHOGp5,imgHOGp6,imgHOGp7,imgHOGp8,imgHOGp9,imgHOGp10,imgHOGp11,imgHOGp12,imgHOGp13,imgHOGp14)\n",
    "\n",
    "airplane_datapath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataAirplane/\"\n",
    "cat_datapath = \"/Users/sam/All-Program/App-DataSet/Kaggle-Challenges/CIFAR-10/trainDataCat/\"\n",
    "ImageDir = [airplane_datapath, cat_datapath]\n",
    "\n",
    "for image_dir in ImageDir:\n",
    "    objectName = os.path.basename(os.path.normpath(image_dir))\n",
    "    filenameArr =  os.listdir(image_dir)\n",
    "    for numImage, image in enumerate(filenameArr):\n",
    "        imagePath = os.path.join(image_dir, image)\n",
    "        print (imagePath)\n",
    "        obj_Preprocess = Preprocess()\n",
    "        (imgHOGp1,imgHOGp2,imgHOGp3,imgHOGp4,imgHOGp5,\n",
    "         imgHOGp6,imgHOGp7,imgHOGp8,imgHOGp9,imgHOGp10, \n",
    "         imgHOGp11,imgHOGp12,imgHOGp13,imgHOGp14) = obj_Preprocess.featureExtractor(imagePath)\n",
    "        print (imgHOGp1.shape)\n",
    "        print (imgHOGp2.shape)\n",
    "        print (imgHOGp3.shape)\n",
    "        print ('##################')\n",
    "        print (imgHOGp4.shape)\n",
    "        print (imgHOGp5.shape)\n",
    "        print (imgHOGp6.shape)\n",
    "        print ('##################')\n",
    "        print (imgHOGp7.shape)\n",
    "        print (imgHOGp8.shape)\n",
    "        print (imgHOGp9.shape)\n",
    "        print ('##################')\n",
    "        print (imgHOGp10.shape)\n",
    "        print (imgHOGp11.shape)\n",
    "        print (imgHOGp12.shape)\n",
    "        print ('##################')\n",
    "        print (imgHOGp13.shape)\n",
    "        print (imgHOGp14.shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
