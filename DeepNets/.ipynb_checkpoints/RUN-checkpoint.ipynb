{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "from tensorflow.python.framework import ops\n",
    "import logging\n",
    "\n",
    "\n",
    "from DataGenerator import genTrainValidFolds\n",
    "from Operations.GraphInterface import convGraphBuilder, nnGraphBuilder, outputToSoftmax\n",
    "from Operations.Tools import reshape_data, accuracy\n",
    "from Operations.Preprocessing import Preprocessing\n",
    "from Operations.CMNFunctions import lossOptimization\n",
    "from Operations.NetworkDebugger import SanityCheck\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reset the Graph every time we initiate a new process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():  # Reset the graph\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the Network Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class GraphComputer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def computationGraph(myNet):\n",
    "        trainTestData = tf.placeholder(dtype=tf.float32,shape=[None, myNet[\"imageSize\"][0], myNet[\"imageSize\"][1], \n",
    "                                                               myNet[\"numChannels\"]], name='xInputs')\n",
    "        trainLabels = tf.placeholder(dtype=tf.float32, shape=[None, myNet[\"numLabels\"]], name='yInputs')\n",
    "        isTraining = tf.placeholder(dtype=tf.bool, name=\"isTraining\")\n",
    "        \n",
    "        runningCount = 1\n",
    "        \n",
    "        # Convolutions Layers\n",
    "        layerOutput = trainTestData\n",
    "        for i in np.arange(myNet[\"convLayerParams\"][\"numLayers\"]):\n",
    "            # define what layer you need for one stacked convolution Layer\n",
    "            layers = myNet[\"convLayerParams\"][\"layers\"]\n",
    "            \n",
    "            convParams = dict(shape = myNet[\"convLayerParams\"][\"convLinear\"][\"shape\"][i],\n",
    "                              stride = myNet[\"convLayerParams\"][\"convLinear\"][\"stride\"][i],\n",
    "                              wghtMean = myNet[\"convLayerParams\"][\"convLinear\"][\"wghtMean\"][i],\n",
    "                              wghtStddev = myNet[\"convLayerParams\"][\"convLinear\"][\"wghtStddev\"][i],\n",
    "                              bias = myNet[\"convLayerParams\"][\"convLinear\"][\"bias\"][i],\n",
    "                              seed = myNet[\"convLayerParams\"][\"convLinear\"][\"seed\"][i])\n",
    "            \n",
    "            poolParams = dict(shape = myNet[\"convLayerParams\"][\"pool\"][\"shape\"][i],\n",
    "                              stride = myNet[\"convLayerParams\"][\"pool\"][\"stride\"][i])\n",
    "            \n",
    "            dropoutParams = dict(keepProb = myNet[\"convLayerParams\"][\"dropout\"][\"keepProb\"][i], \n",
    "                                 seed = myNet[\"convLayerParams\"][\"dropout\"][\"seed\"][i])\n",
    "\n",
    "            print ('')\n",
    "            print ('00000000000000000', dropoutParams)\n",
    "            print ('')\n",
    "            print ('00000000000000000', convParams)\n",
    "            print ('')\n",
    "            print ('00000000000000000', poolParams)\n",
    "            layerOutput, _ = convGraphBuilder(xTF=layerOutput,\n",
    "                                             convParams = convParams, \n",
    "                                             poolParams = poolParams, \n",
    "                                             dropoutParams = dropoutParams,\n",
    "                                             isTraining=isTraining, \n",
    "                                             layers=layers,\n",
    "                                             layerNum=runningCount,\n",
    "                                             axis=[0, 1, 2])\n",
    "\n",
    "            runningCount += 1\n",
    "            \n",
    "        print ('The shape after convolution layer is : ', layerOutput.get_shape())\n",
    "        \n",
    "        # We have to flatten the shape to pass it to the fully connected layer\n",
    "        # Get the features in flattened fashion\n",
    "        shapeY, shapeX, depth = layerOutput.get_shape().as_list()[1:4]\n",
    "        flattenedShape = shapeY * shapeX * depth\n",
    "        convFeaturesFlattened = tf.reshape(layerOutput, [-1, flattenedShape])\n",
    "        \n",
    "        print ('The flattened features of convolutions is: ', convFeaturesFlattened.get_shape())\n",
    "\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        myNet[\"fcLayerParams\"][\"linear\"][\"shape\"][0][0] = flattenedShape      \n",
    "        layerOutput = convFeaturesFlattened\n",
    "        for j in np.arange(myNet[\"fcLayerParams\"][\"numLayers\"]):\n",
    "            k = i+1+j\n",
    "            # print (self.myNet[\"fcLayers\"][j])\n",
    "            layers = myNet[\"fcLayerParams\"][\"layers\"]\n",
    "            dropoutParams = dict(keepProb = myNet[\"fcLayerParams\"][\"dropout\"][\"keepProb\"][j], \n",
    "                                 seed = myNet[\"fcLayerParams\"][\"dropout\"][\"seed\"][j])\n",
    "            \n",
    "            linearParams = dict(shape = myNet[\"fcLayerParams\"][\"linear\"][\"shape\"][j],\n",
    "                                wghtMean = myNet[\"fcLayerParams\"][\"linear\"][\"wghtMean\"][j],\n",
    "                                wghtStddev = myNet[\"fcLayerParams\"][\"linear\"][\"wghtStddev\"][j],\n",
    "                                bias = myNet[\"fcLayerParams\"][\"linear\"][\"bias\"][j],\n",
    "                                seed = myNet[\"fcLayerParams\"][\"linear\"][\"seed\"][j])\n",
    "            print ('')\n",
    "            print ('11111111111111111', dropoutParams)\n",
    "            print ('')\n",
    "            print ('11111111111111111', linearParams)\n",
    "            layerOutput, _ = nnGraphBuilder(xTF=layerOutput,\n",
    "                                            linearParams = linearParams,\n",
    "                                            dropoutParams = dropoutParams,\n",
    "                                            isTraining=isTraining,\n",
    "                                            layers= layers,\n",
    "                                            layerNum = runningCount, \n",
    "                                            axis=[0])\n",
    "            runningCount += 1\n",
    "\n",
    "        print('The shape after the Fully connected Layer is : ', layerOutput.get_shape())\n",
    "\n",
    "        # Fully connected to Softmax layer\n",
    "        outState, probLabel = outputToSoftmax(xTF=layerOutput,\n",
    "                                              numInp=layerOutput.get_shape().as_list()[1],\n",
    "                                              numOut = myNet[\"numLabels\"],\n",
    "                                              layerNum=runningCount)\n",
    "\n",
    "        print('The shape of the Tensor after Out to Softmax is : ', probLabel.get_shape())\n",
    "        \n",
    "        # Loss Function and Optimization\n",
    "        lossCE, optimizer = lossOptimization(xIN=outState, yIN=trainLabels, \n",
    "                                             optimizerParam = myNet[\"optimizerParams\"])\n",
    "        \n",
    "        return dict(\n",
    "                inputData=trainTestData,\n",
    "                inputLabels=trainLabels,\n",
    "                isTraining=isTraining,\n",
    "                optimizer=optimizer,\n",
    "                lossCE=lossCE,\n",
    "                pred=probLabel,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Execute the Session : Train Test the Model:\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "globalSession = 0\n",
    "\n",
    "class SesssionExec():\n",
    "    \n",
    "    def __init__(self, myNet):\n",
    "        self.featureDIR = \"/Users/sam/All-Program/App-DataSet/CIFAR-10/featureModels/2-Class/regularFeatures/RGB/batch_data/\"\n",
    "        self.myNet = myNet\n",
    "\n",
    "\n",
    "    def runPreprocessor(self, dataIN, sess):\n",
    "        preprocessedData = np.ndarray(shape=(dataIN.shape), dtype='float32')\n",
    "        for numImage in np.arange(dataIN.shape[0]):\n",
    "            feed_dict = {\n",
    "                self.preprocessGraphDict['imageIN']:dataIN[numImage,:]\n",
    "            }\n",
    "            preprocessedData[numImage,:] = sess.run(self.preprocessGraphDict['imageOUT'],\n",
    "                                                      feed_dict=feed_dict)\n",
    "        return preprocessedData\n",
    "\n",
    "\n",
    "    def trainModel(self, dataIN, labelIN, sess):\n",
    "        '''\n",
    "        :param dataIN:      The input data for CIFAR 2 (10000 : 5000 each class)\n",
    "        :param labelIN:     The input labels to optimize\n",
    "        :param sess:        Instance for running session\n",
    "        :return:            Nothing\n",
    "        \n",
    "        Here we feed in both the batchData and the baatchLabels and we also run the session\n",
    "        for loss and optimization because we would want to find gradient and update the\n",
    "        weights for the training Dataset\n",
    "        '''\n",
    "        \n",
    "        batchSize = myNet[\"batchSize\"]\n",
    "        numBatches = int(np.ceil(dataIN.shape[0] / batchSize))\n",
    "        \n",
    "\n",
    "        for numBatch in np.arange(numBatches):\n",
    "            batchData = dataIN[numBatch * batchSize: (numBatch + 1) * batchSize]\n",
    "            batchLabels = labelIN[numBatch * batchSize: (numBatch + 1) * batchSize]\n",
    "            # print('The shape for Batch Data, Batch Labels is: ', batchData.shape, batchLabels.shape)\n",
    "            # print('The shape for Batch L is: ', batchData.shape)\n",
    "            feed_dict = {\n",
    "                self.compGraphDict['inputData']: batchData,\n",
    "                self.compGraphDict['inputLabels']: batchLabels,\n",
    "                self.compGraphDict['isTraining']: True\n",
    "            }\n",
    "\n",
    "            _, loss, trainPred = sess.run([self.compGraphDict['optimizer'],\n",
    "                                       self.compGraphDict['lossCE'],\n",
    "                                       self.compGraphDict['pred']],\n",
    "                                      feed_dict=feed_dict)\n",
    "            \n",
    "            if (numBatch+1 == 1) and (self.epoch+1 == 1):\n",
    "                SanityCheck.checkStartingLoss(lossIN = loss, numLabels=self.myNet[\"numLabels\"])\n",
    "\n",
    "            if ((numBatch + 1) % 20 == 0) or ((numBatch + 1) == numBatches):\n",
    "                trainAcc = accuracy(trainPred, batchLabels)\n",
    "                print(\"Fold: \" + str(self.foldNUM + 1) +\n",
    "                      \", Epoch: \" + str(self.epoch + 1) +\n",
    "                      \", Mini Batch: \" + str(numBatch + 1) +\n",
    "                      \", Loss= \" + \"{:.6f}\".format(loss) +\n",
    "                      \", Training Accuracy= \" + \"{:.5f}\".format(trainAcc))\n",
    "\n",
    "        return loss, trainPred\n",
    "    \n",
    "    \n",
    "    def testModel(self, dataIN, labelIN, sess):\n",
    "        '''\n",
    "        :param dataIN:      The input test or validation data\n",
    "        :param labelIN:     The input labels, (just to compute the accuracy)\n",
    "        :param sess:        The opened session\n",
    "        :return:            Nothing\n",
    "        \n",
    "        We only run the session for processes resulting only till the \"pred\" because if we\n",
    "        call optimization then their would computation for gradients resulting in weight\n",
    "        change. This would be unwise because we don't want our model to adjust the weight\n",
    "        for the test data. In other words we dont want out model to learn the test data.\n",
    "        \n",
    "        \n",
    "        TO DO : Here we need to do a sanity check if the weight before testModel and after testModel are\n",
    "        same because if they only if they are same, we can be sure that the test data is not influencing\n",
    "        optimization and weight change.\n",
    "        '''\n",
    "        \n",
    "        feed_dict = {\n",
    "            self.compGraphDict['inputData']: dataIN,\n",
    "            self.compGraphDict['isTraining']: False\n",
    "        }\n",
    "    \n",
    "        testPred = sess.run(self.compGraphDict['pred'], feed_dict=feed_dict)\n",
    "        testAcc = accuracy(testPred, np.array(labelIN))\n",
    "        print(\"Fold: \" + str(self.foldNUM + 1) +\n",
    "              \", Epoch: \" + str(self.epoch + 1) +\n",
    "              \", Test Accuracy= \" + \"{:.5f}\".format(testAcc))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def execute(self):\n",
    "        meanValidAcc = 0\n",
    "        for foldNUM, (trainDataIN, trainLabelsIN,\n",
    "                      validDataIN, validLabelsIN, labelDict\n",
    "                      ) in enumerate(\n",
    "                genTrainValidFolds(self.featureDIR, oneHot=True)):\n",
    "            \n",
    "            self.foldNUM = foldNUM\n",
    "            print('')\n",
    "            print('#################################################################################')\n",
    "            trainDataIN, _ = reshape_data(trainDataIN,\n",
    "                                          imageSize=self.myNet[\"imageSize\"][0],\n",
    "                                          numChannels=self.myNet[\"numChannels\"])\n",
    "            \n",
    "            validDataIN, _ = reshape_data(validDataIN,\n",
    "                                          imageSize=self.myNet[\"imageSize\"][0],\n",
    "                                          numChannels=self.myNet[\"numChannels\"])\n",
    "            \n",
    "            print('')\n",
    "            print('Validation Data and Labels shape: ', validDataIN.shape, validLabelsIN.shape)\n",
    "            print('Training Data and Labels shape: ', trainDataIN.shape, trainLabelsIN.shape)\n",
    "            print('The Label Dictionary is given as: ', labelDict)\n",
    "            print('')\n",
    "            \n",
    "            \n",
    "            # First we reset the graph, so that all the existing graph are erased form memory\n",
    "            reset_graph()\n",
    "            \n",
    "            # Step 1: First we create the Pre-processing Graph:\n",
    "            self.preprocessGraphDict = Preprocessing().preprocessImageGraph(\n",
    "                                                            imageSize=self.myNet[\"imageSize\"],\n",
    "                                                            numChannels=self.myNet[\"numChannels\"])\n",
    "            \n",
    "            # Now we create the Training Graph\n",
    "            self.compGraphDict = GraphComputer.computationGraph(self.myNet)\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                print (sess)\n",
    "                for epoch in range(self.myNet[\"epochs\"]):\n",
    "                    self.epoch = epoch\n",
    "                    # print([op for op in tf.get_default_graph().get_operations()])\n",
    "                    preprocessedTrainData = self.runPreprocessor(dataIN=trainDataIN, sess=sess)\n",
    "                    \n",
    "                    print ('################## ', preprocessedTrainData.shape)\n",
    "    \n",
    "                    loss, trainPred = self.trainModel(dataIN=trainDataIN,\n",
    "                                                      labelIN=trainLabelsIN,\n",
    "                                                      sess=sess)\n",
    "                    self.testModel(dataIN=validDataIN, labelIN=validLabelsIN, sess=sess)\n",
    "                    \n",
    "#                     convWeightL1 = [v for v in tf.trainable_variables() if v.name == 'Layer1/convWeight:0'][0]\n",
    "#                     print (\"The shape of Conv layer 1 filter is : \", convWeightL1.get_shape().as_list())\n",
    "#                     print (sess.run(convWeightL1))\n",
    "#                     print ('1111111111111111111111111111111111111111111111111111111111111111111111')\n",
    "                    if epoch == 10:\n",
    "                        break\n",
    "            break\n",
    "            \n",
    "#         convWeightL1 = [v for v in tf.trainable_variables() if v.name == 'Layer1/convWeight:0'][0]\n",
    "#         sess.run(convWeightL1)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define your Network Condiguration and Execute the Computation Graph:\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#################################################################################\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 32, 32, 3) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 32, 32, 3) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "\n",
      "\n",
      "00000000000000000 {'seed': 19823, 'keepProb': 0.5}\n",
      "\n",
      "00000000000000000 {'wghtMean': 0, 'seed': 231, 'bias': 1.0, 'wghtStddev': 0.05, 'stride': 1, 'shape': [5, 5, 3, 64]}\n",
      "\n",
      "00000000000000000 {'stride': 1, 'shape': [1, 2, 2, 1]}\n",
      "\n",
      "00000000000000000 {'seed': 234, 'keepProb': 0.5}\n",
      "\n",
      "00000000000000000 {'wghtMean': 0, 'seed': 879, 'bias': 1.0, 'wghtStddev': 0.05, 'stride': 1, 'shape': [5, 5, 64, 64]}\n",
      "\n",
      "00000000000000000 {'stride': 1, 'shape': [1, 2, 2, 1]}\n",
      "The shape after convolution layer is :  (?, 32, 32, 64)\n",
      "The flattened features of convolutions is:  (?, 65536)\n",
      "\n",
      "11111111111111111 {'seed': 5556, 'keepProb': 0.5}\n",
      "\n",
      "11111111111111111 {'wghtMean': 0, 'seed': 7952, 'bias': 1.0, 'wghtStddev': 0.05, 'shape': [65536, 1024]}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dropoutParam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-696478183c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mSesssionExec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-264627a2fb57>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# Now we create the Training Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompGraphDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphComputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputationGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-36e3a4c3a31c>\u001b[0m in \u001b[0;36mcomputationGraph\u001b[0;34m(myNet)\u001b[0m\n\u001b[1;32m     80\u001b[0m             layerOutput, _ = nnGraphBuilder(xTF=layerOutput,\n\u001b[1;32m     81\u001b[0m                                             \u001b[0mlinearParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearParams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                             \u001b[0mdropoutParam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropoutParam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                                             \u001b[0misTraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misTraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                                             \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dropoutParam' is not defined"
     ]
    }
   ],
   "source": [
    "myNet = dict(imageSize=(32,32),\n",
    "             numLabels=2,\n",
    "             numChannels=3,\n",
    "             convLayerParams = dict(layers = [\"linear\", \"batchNorm\", \"nonLinear\", \"pool\", \"dropout\"], \n",
    "                                    numLayers=2,\n",
    "                                    convLinear = dict(shape=[[5,5,3,64], [5,5,64,64]],  # [kernelY, kernelX, inpDepth, outDepth]\n",
    "                                                      stride=[1,1],\n",
    "                                                      wghtMean = [0,0],\n",
    "                                                      wghtStddev = [0.05,0.05],\n",
    "                                                      bias = [1.0,1.0],\n",
    "                                                      seed = [231,879]),\n",
    "                                    batchNorm =  dict(mAvg_decay=0.5,\n",
    "                                                      epsilon=1e-4),\n",
    "                                    nonLinear =  dict(activation=[\"RELU\",\"RELU\"]),\n",
    "                                    pool      =  dict(shape=[[1,2,2,1],[1,2,2,1]],\n",
    "                                                      stride=[1,1]),\n",
    "                                    dropout =    dict(keepProb=[0.5,0.5], seed=[19823,234])\n",
    "                                ),\n",
    "             fcLayerParams =   dict(layers = [\"linear\", \"batchNorm\", \"nonLinear\", \"dropout\"], \n",
    "                                    numLayers=2,\n",
    "                                    linear    =  dict(shape = [[0, 1024], [1024,1024]],   # [numHid1, numHid2]\n",
    "                                                      wghtMean = [0,0],\n",
    "                                                      wghtStddev = [0.05,0.05],\n",
    "                                                      bias = [1.0,1.0],\n",
    "                                                      seed = [7952, 8702]), \n",
    "                                    batchNorm =  dict(mAvg_decay=0.5,\n",
    "                                                        epsilon=1e-4),\n",
    "                                    nonLinear =  dict(activation=[\"RELU\",\"RELU\"]),\n",
    "                                    dropout =    dict(keepProb=[0.5,0.5], seed=[5556,497])\n",
    "                                ),\n",
    "             optimizerParams = dict(optimizer='RMSPROP', learning_rate=0.0001, momentum=0.9),\n",
    "             batchSize=128,\n",
    "             epochs = 30\n",
    "        )\n",
    "          \n",
    "\n",
    "SesssionExec(myNet).execute()                               \n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#################################################################################\n",
      "\n",
      "Validation Data and Labels shape:  (1000, 32, 32, 3) (1000, 2)\n",
      "Training Data and Labels shape:  (9000, 32, 32, 3) (9000, 2)\n",
      "The Label Dictionary is given as:  {0: 'trainDataAirplane.pickle', 1: 'trainDataCat.pickle'}\n",
      "\n",
      "(5, 5, 3, 64)\n",
      "(64,)\n",
      "(?, 32, 32, 3)\n",
      "(5, 5, 64, 128)\n",
      "(128,)\n",
      "(?, 32, 32, 64)\n",
      "The shape after convolution layer is :  (?, 32, 32, 128)\n",
      "The flattened features of convolutions is:  (?, 131072)\n",
      "The shape after the Fully connected Layer is :  (?, 1024)\n",
      "The shape of the Tensor after Out to Softmax is :  (?, 2)\n",
      "<tensorflow.python.client.session.Session object at 0x118994eb8>\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 1, Mini Batch: 20, Loss= 1.994374, Training Accuracy= 47.65625\n",
      "Fold: 1, Epoch: 1, Mini Batch: 40, Loss= 1.633837, Training Accuracy= 47.65625\n",
      "Fold: 1, Epoch: 1, Mini Batch: 60, Loss= 1.485618, Training Accuracy= 55.46875\n",
      "Fold: 1, Epoch: 1, Mini Batch: 71, Loss= 1.443670, Training Accuracy= 52.50000\n",
      "Fold: 1, Epoch: 1, Test Accuracy= 51.50000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 2, Mini Batch: 20, Loss= 1.259019, Training Accuracy= 65.62500\n",
      "Fold: 1, Epoch: 2, Mini Batch: 40, Loss= 1.096931, Training Accuracy= 64.84375\n",
      "Fold: 1, Epoch: 2, Mini Batch: 60, Loss= 1.006319, Training Accuracy= 72.65625\n",
      "Fold: 1, Epoch: 2, Mini Batch: 71, Loss= 0.614475, Training Accuracy= 85.00000\n",
      "Fold: 1, Epoch: 2, Test Accuracy= 75.40000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 3, Mini Batch: 20, Loss= 0.740725, Training Accuracy= 77.34375\n",
      "Fold: 1, Epoch: 3, Mini Batch: 40, Loss= 0.564702, Training Accuracy= 83.59375\n",
      "Fold: 1, Epoch: 3, Mini Batch: 60, Loss= 0.738977, Training Accuracy= 77.34375\n",
      "Fold: 1, Epoch: 3, Mini Batch: 71, Loss= 0.452828, Training Accuracy= 85.00000\n",
      "Fold: 1, Epoch: 3, Test Accuracy= 81.20000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 4, Mini Batch: 20, Loss= 0.397558, Training Accuracy= 81.25000\n",
      "Fold: 1, Epoch: 4, Mini Batch: 40, Loss= 0.394088, Training Accuracy= 85.93750\n",
      "Fold: 1, Epoch: 4, Mini Batch: 60, Loss= 0.597027, Training Accuracy= 80.46875\n",
      "Fold: 1, Epoch: 4, Mini Batch: 71, Loss= 0.116639, Training Accuracy= 95.00000\n",
      "Fold: 1, Epoch: 4, Test Accuracy= 87.10000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 5, Mini Batch: 20, Loss= 0.351657, Training Accuracy= 87.50000\n",
      "Fold: 1, Epoch: 5, Mini Batch: 40, Loss= 0.269765, Training Accuracy= 86.71875\n",
      "Fold: 1, Epoch: 5, Mini Batch: 60, Loss= 0.552343, Training Accuracy= 85.15625\n",
      "Fold: 1, Epoch: 5, Mini Batch: 71, Loss= 0.145315, Training Accuracy= 95.00000\n",
      "Fold: 1, Epoch: 5, Test Accuracy= 89.20000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 6, Mini Batch: 20, Loss= 0.300738, Training Accuracy= 90.62500\n",
      "Fold: 1, Epoch: 6, Mini Batch: 40, Loss= 0.232396, Training Accuracy= 92.18750\n",
      "Fold: 1, Epoch: 6, Mini Batch: 60, Loss= 0.408086, Training Accuracy= 84.37500\n",
      "Fold: 1, Epoch: 6, Mini Batch: 71, Loss= 0.158310, Training Accuracy= 95.00000\n",
      "Fold: 1, Epoch: 6, Test Accuracy= 89.50000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 7, Mini Batch: 20, Loss= 0.286686, Training Accuracy= 89.06250\n",
      "Fold: 1, Epoch: 7, Mini Batch: 40, Loss= 0.137807, Training Accuracy= 93.75000\n",
      "Fold: 1, Epoch: 7, Mini Batch: 60, Loss= 0.382102, Training Accuracy= 87.50000\n",
      "Fold: 1, Epoch: 7, Mini Batch: 71, Loss= 0.096862, Training Accuracy= 97.50000\n",
      "Fold: 1, Epoch: 7, Test Accuracy= 87.40000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 8, Mini Batch: 20, Loss= 0.336998, Training Accuracy= 89.06250\n",
      "Fold: 1, Epoch: 8, Mini Batch: 40, Loss= 0.204268, Training Accuracy= 92.18750\n",
      "Fold: 1, Epoch: 8, Mini Batch: 60, Loss= 0.374430, Training Accuracy= 85.93750\n",
      "Fold: 1, Epoch: 8, Mini Batch: 71, Loss= 0.078505, Training Accuracy= 100.00000\n",
      "Fold: 1, Epoch: 8, Test Accuracy= 86.80000\n",
      "##################  (9000, 32, 32, 3)\n",
      "Fold: 1, Epoch: 9, Mini Batch: 20, Loss= 0.221034, Training Accuracy= 90.62500\n",
      "Fold: 1, Epoch: 9, Mini Batch: 40, Loss= 0.142045, Training Accuracy= 95.31250\n",
      "Fold: 1, Epoch: 9, Mini Batch: 60, Loss= 0.392868, Training Accuracy= 87.50000\n",
      "Fold: 1, Epoch: 9, Mini Batch: 71, Loss= 0.091007, Training Accuracy= 95.00000\n",
      "Fold: 1, Epoch: 9, Test Accuracy= 91.90000\n",
      "##################  (9000, 32, 32, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0c3e19bbcf0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mSesssionExec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-972ac49a2774>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m                     loss, trainPred = self.trainModel(dataIN=trainDataIN,\n\u001b[1;32m    143\u001b[0m                                                       \u001b[0mlabelIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainLabelsIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                                                       sess=sess)\n\u001b[0m\u001b[1;32m    145\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidDataIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelIN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidLabelsIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-972ac49a2774>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(self, dataIN, labelIN, sess)\u001b[0m\n\u001b[1;32m     49\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompGraphDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lossCE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                                        self.compGraphDict['pred']],\n\u001b[0;32m---> 51\u001b[0;31m                                       feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sam/App-Setup/CondaENV/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myNet = dict(imageSize=(32,32),\n",
    "             numLabels=2,\n",
    "             numChannels=3,\n",
    "             convLayerParams = dict(layers = [\"linear\", \"batchNorm\", \"nonLinear\", \"pool\", \"dropout\"], \n",
    "                                  numLayers=2,\n",
    "                                  linear = dict(convKernel=[(5,5), (5,5)],\n",
    "                                                convDepth=[3,64,64],          # The first value of the array should equal to the numChannels\n",
    "                                                convStride=[1,1], \n",
    "                                                convPadding=[\"SAME\", \"SAME\"]),\n",
    "                                  batchNorm = dict(mAvg_decay=0.5,\n",
    "                                                   epsilon=1e-4),\n",
    "                                  nonLinear = dict(activation=[\"RELU\",\"RELU\"]),\n",
    "                                  pool = dict(activation=[\"MAX\",\"MAX\"],\n",
    "                                              poolKernel=[(2,2), (2,2)], \n",
    "                                              poolStride=[1,1],\n",
    "                                              poolPadding=[\"SAME\",\"SAME\"]),\n",
    "                                  dropout = dict(keepProb=[0.5,0.5], seed=[19823,234])\n",
    "                            ),\n",
    "             fcLayerParams = dict(layers = [\"linear\", \"batchNorm\", \"nonLinear\", \"dropout\"], \n",
    "                                numLayers=3,\n",
    "                                linear = dict(numHidden = [0, 1024, 1024, 1024]), # The first value of the array should always be zero because it is updated in\n",
    "                             #  run time\n",
    "                                batchNorm = dict(mAvg_decay=0.5,\n",
    "                                                 epsilon=1e-4),\n",
    "                                nonLinear = dict(activation=[\"RELU\",\"RELU\",\"RELU\"]),\n",
    "                                dropout = dict(keepProb=[0.75,0.5,0.5], seed=[5556,497,2286])\n",
    "                            ),\n",
    "             optimizerParams = dict(optimizer='RMSPROP', learning_rate=0.0001, momentum=0.9),\n",
    "             batchSize=128,\n",
    "             epochs = 30\n",
    "        )\n",
    "          \n",
    "\n",
    "SesssionExec(myNet).execute()                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Important Discussion: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Layer1/convWeight:0',\n",
       " 'Layer1/convBias:0',\n",
       " 'Layer1/beta:0',\n",
       " 'Layer1/gamma:0',\n",
       " 'Layer2/convWeight:0',\n",
       " 'Layer2/convBias:0',\n",
       " 'Layer2/beta:0',\n",
       " 'Layer2/gamma:0',\n",
       " 'Layer3/weight:0',\n",
       " 'Layer3/bias:0',\n",
       " 'Layer3/beta:0',\n",
       " 'Layer3/gamma:0',\n",
       " 'Layer4/weight:0',\n",
       " 'Layer4/bias:0',\n",
       " 'Layer4/beta:0',\n",
       " 'Layer4/gamma:0',\n",
       " 'Layer5/weight:0',\n",
       " 'Layer5/bias:0']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the names of all the trained variable taking part in the process by doing the below.\n",
    "var = [v.name for v in tf.trainable_variables()]\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 3, 64]\n",
      "[[[[ -2.58764178e-02   3.68417874e-02  -2.20113825e-02 ...,\n",
      "     -1.01264648e-01   4.23011743e-02  -1.15798414e-01]\n",
      "   [ -5.56089245e-02  -3.05920672e-02   1.15085237e-01 ...,\n",
      "     -5.03812805e-02   2.23189108e-02   6.28041029e-02]\n",
      "   [  6.76066354e-02   3.38082202e-02   2.55782204e-03 ...,\n",
      "     -5.41199036e-02  -6.91338331e-02   2.44802367e-02]]\n",
      "\n",
      "  [[  2.34650761e-01  -2.26471182e-02   1.27404332e-01 ...,\n",
      "      3.84634919e-02  -6.07750714e-02   9.02874693e-02]\n",
      "   [  1.18034676e-01   8.27012062e-02   1.28456101e-01 ...,\n",
      "      8.34089331e-03  -1.41746387e-01   2.87150275e-02]\n",
      "   [  6.03144430e-02  -7.77993500e-02   1.92963928e-02 ...,\n",
      "     -2.81373002e-02   3.97584438e-02   2.18043067e-02]]\n",
      "\n",
      "  [[  7.11000487e-02   2.14320302e-01   1.72619876e-02 ...,\n",
      "      5.06132245e-02  -1.19313799e-01  -1.43738342e-02]\n",
      "   [ -1.29597425e-01  -6.56865016e-02   1.50291443e-01 ...,\n",
      "     -2.00602338e-01   3.73691204e-03  -2.28491098e-01]\n",
      "   [  1.00871108e-01   1.46426558e-01   9.06365290e-02 ...,\n",
      "     -6.44590557e-02   7.45691434e-02  -3.35411131e-02]]\n",
      "\n",
      "  [[ -1.15495659e-01  -4.49672081e-02   1.19989095e-02 ...,\n",
      "     -1.16278045e-01   3.82919721e-02  -7.60577694e-02]\n",
      "   [  4.01016138e-02  -2.62752753e-02  -1.15945235e-01 ...,\n",
      "     -7.18600815e-04   1.48539320e-01  -5.96087985e-02]\n",
      "   [ -5.17041087e-02   2.74251606e-02  -1.23761468e-01 ...,\n",
      "     -2.12772802e-01  -1.78820059e-01  -1.36470338e-02]]\n",
      "\n",
      "  [[ -3.85971069e-02  -1.84520446e-02   1.18552797e-01 ...,\n",
      "     -4.87386808e-03  -1.04641663e-02   5.11490367e-02]\n",
      "   [  2.82339510e-02   2.53091510e-02   1.81193218e-01 ...,\n",
      "      8.03942755e-02  -1.88021407e-01  -2.69058794e-02]\n",
      "   [ -1.79041490e-01   5.62722795e-02  -7.22297654e-02 ...,\n",
      "      8.57672617e-02  -3.28003503e-02   7.38482624e-02]]]\n",
      "\n",
      "\n",
      " [[[ -2.13116538e-02   1.40402928e-01  -2.13173255e-01 ...,\n",
      "      1.28455505e-01  -1.45528195e-02  -4.93258573e-02]\n",
      "   [  3.29766087e-02  -3.40266130e-03   5.99770360e-02 ...,\n",
      "      1.03871182e-01  -1.06280841e-01   1.95291862e-02]\n",
      "   [  7.72479326e-02   5.28448410e-02  -1.88821126e-02 ...,\n",
      "     -2.12382004e-02  -2.29829893e-01   2.34588981e-02]]\n",
      "\n",
      "  [[ -7.48444721e-03  -8.25298578e-02  -9.93280038e-02 ...,\n",
      "      2.73869392e-02   1.50518358e-01  -1.32859752e-01]\n",
      "   [  1.08187608e-01   1.10800982e-01  -2.13588178e-02 ...,\n",
      "     -6.23863414e-02  -5.41277044e-03   7.45363533e-02]\n",
      "   [  1.03763305e-01  -1.68926511e-02  -3.48031111e-02 ...,\n",
      "     -7.58686811e-02   1.19990908e-01   2.31310911e-02]]\n",
      "\n",
      "  [[  6.37462735e-03  -1.68989655e-02  -4.46268776e-03 ...,\n",
      "     -6.95060119e-02   8.17694589e-02  -1.13665640e-01]\n",
      "   [  8.90764222e-02   4.46601622e-02  -2.01118197e-02 ...,\n",
      "     -1.79954514e-01   7.20906183e-02  -2.78347265e-02]\n",
      "   [  6.84039816e-02   2.47177724e-02  -5.18645607e-02 ...,\n",
      "      1.24498405e-01   2.09283293e-03  -1.08770810e-01]]\n",
      "\n",
      "  [[  3.32613438e-02  -4.43079881e-02   3.47839743e-02 ...,\n",
      "     -5.00320271e-02   4.91589531e-02   3.85543220e-02]\n",
      "   [  8.68490189e-02  -3.40938419e-02   6.17051125e-02 ...,\n",
      "     -3.14040966e-02   5.77462278e-02   1.38507532e-02]\n",
      "   [ -6.62095472e-02  -2.26374436e-03  -1.16672469e-02 ...,\n",
      "      3.05678546e-02  -1.80686772e-01  -9.63895172e-02]]\n",
      "\n",
      "  [[ -2.21360996e-01  -7.36526474e-02   2.93139610e-02 ...,\n",
      "     -6.57916591e-02   7.22820386e-02  -1.67531386e-01]\n",
      "   [  8.46542697e-03   4.26540710e-02  -1.10215485e-01 ...,\n",
      "      5.92251793e-02  -1.97752520e-01  -1.68973371e-01]\n",
      "   [  1.68319210e-01  -1.06074713e-01  -8.15333426e-02 ...,\n",
      "      7.15061948e-02   1.40707090e-01  -8.98340866e-02]]]\n",
      "\n",
      "\n",
      " [[[ -3.66916284e-02   8.48478377e-02   6.92168251e-02 ...,\n",
      "     -1.37397006e-01  -4.10844944e-02   8.72867331e-02]\n",
      "   [  5.94354831e-02   1.09518014e-01   8.00427198e-02 ...,\n",
      "     -2.21245951e-04   8.94531384e-02  -2.04359796e-02]\n",
      "   [  1.07243814e-01   7.69856200e-02  -9.14934278e-02 ...,\n",
      "      3.30735706e-02   1.20431423e-01  -1.40185282e-01]]\n",
      "\n",
      "  [[ -7.10190535e-02   1.29439801e-01  -3.00250556e-02 ...,\n",
      "      5.55627756e-02   7.75865803e-04  -6.52514026e-02]\n",
      "   [ -2.76486158e-01   1.04791678e-01  -1.05600795e-02 ...,\n",
      "      1.67727955e-02   1.37917653e-01   6.28411695e-02]\n",
      "   [ -1.09250359e-01  -1.34922609e-01  -7.13825375e-02 ...,\n",
      "      1.64727811e-02   9.23870429e-02   7.21693859e-02]]\n",
      "\n",
      "  [[ -1.42618818e-02  -5.87347746e-02  -1.26514047e-01 ...,\n",
      "      4.08718027e-02  -1.58126596e-02   4.40508835e-02]\n",
      "   [  1.45121917e-01   9.35609415e-02  -1.37340128e-01 ...,\n",
      "     -3.86351696e-03   4.34736572e-02  -8.72142613e-02]\n",
      "   [ -8.56770016e-03   7.60597587e-02  -5.67172170e-02 ...,\n",
      "     -1.99772827e-02   3.21379900e-02  -1.61154702e-01]]\n",
      "\n",
      "  [[ -1.02114521e-01  -5.27157597e-02  -7.15421066e-02 ...,\n",
      "      8.12953338e-02   1.27201080e-01   6.81691095e-02]\n",
      "   [ -6.31583109e-03  -1.09370463e-01  -2.05216572e-01 ...,\n",
      "      6.50566518e-02   4.41019051e-02   7.07023069e-02]\n",
      "   [  7.80574307e-02   6.87100440e-02   1.68500561e-02 ...,\n",
      "      1.38090819e-01  -8.67633149e-02   4.82526645e-02]]\n",
      "\n",
      "  [[  1.30156800e-01   1.40852198e-01  -5.70831485e-02 ...,\n",
      "     -6.50296435e-02   3.15382443e-02  -1.22767009e-01]\n",
      "   [ -5.31092472e-02  -4.29698341e-02   5.29531315e-02 ...,\n",
      "     -7.35886917e-02  -8.23151171e-02   5.22685312e-02]\n",
      "   [  3.50632146e-02  -5.66566475e-02   1.90809295e-01 ...,\n",
      "     -1.54315785e-01  -5.95718585e-02  -1.28237978e-01]]]\n",
      "\n",
      "\n",
      " [[[  1.35199890e-01  -7.35893622e-02  -9.05706808e-02 ...,\n",
      "      1.28818108e-02   4.62180562e-02   1.07312791e-01]\n",
      "   [  3.21903229e-02  -4.25982289e-02   1.92939058e-01 ...,\n",
      "     -1.60016250e-02  -8.21110532e-02   7.64978752e-02]\n",
      "   [ -2.46980810e-03   5.98962419e-02  -1.03160944e-02 ...,\n",
      "     -6.74324408e-02  -4.36142832e-03   1.23521648e-01]]\n",
      "\n",
      "  [[ -4.46190611e-02  -1.17441230e-01   1.34352028e-01 ...,\n",
      "      1.04124501e-01  -4.35703583e-02   1.00570142e-01]\n",
      "   [ -1.74549326e-01   2.44719293e-02  -1.34817377e-01 ...,\n",
      "      3.23304050e-02  -3.51083986e-02   9.30356309e-02]\n",
      "   [ -1.19260348e-01   1.42053068e-02  -8.75061154e-02 ...,\n",
      "      5.96950017e-02  -1.15102828e-01   3.17060165e-02]]\n",
      "\n",
      "  [[ -6.76482320e-02  -1.65725559e-01   3.58087420e-02 ...,\n",
      "     -6.40280619e-02   4.41366695e-02   1.59742162e-01]\n",
      "   [  1.63601324e-01   4.68889922e-02  -9.28216130e-02 ...,\n",
      "     -1.32019684e-01   1.58532616e-02  -5.70641346e-02]\n",
      "   [ -9.20965225e-02   1.68619081e-01  -5.60649037e-02 ...,\n",
      "     -9.38682407e-02   1.03031956e-01  -1.95390865e-01]]\n",
      "\n",
      "  [[ -8.18978399e-02  -1.52508259e-01  -1.11031486e-02 ...,\n",
      "      1.30922943e-01  -4.01531123e-02  -1.90197691e-01]\n",
      "   [  2.62320340e-02  -1.25239015e-01  -2.72860024e-02 ...,\n",
      "     -1.17548458e-01  -2.32840329e-01   6.04611076e-03]\n",
      "   [ -1.55117452e-01   1.43951640e-01   1.24546602e-01 ...,\n",
      "     -5.48981912e-02  -1.64925024e-01   2.35003214e-02]]\n",
      "\n",
      "  [[ -8.53598025e-03   2.02326402e-01   4.32066470e-02 ...,\n",
      "     -1.27037451e-01   1.32999226e-01   4.08797152e-02]\n",
      "   [ -1.16919756e-01  -1.51782125e-01  -5.13342805e-02 ...,\n",
      "     -1.23940386e-01   6.05026148e-02   3.37882452e-02]\n",
      "   [  1.05093695e-01   2.17119977e-02  -8.41627046e-02 ...,\n",
      "     -4.07574140e-02  -2.66892314e-01  -9.85944197e-02]]]\n",
      "\n",
      "\n",
      " [[[  5.56701198e-02   7.70319626e-02  -1.01995312e-01 ...,\n",
      "      3.49025964e-03  -7.62843117e-02  -1.02726392e-01]\n",
      "   [  1.00242794e-01  -1.69762835e-01   9.26557034e-02 ...,\n",
      "     -3.79233919e-02   4.02652137e-02  -1.88844040e-01]\n",
      "   [  4.52743657e-02  -9.94580835e-02   1.01522900e-01 ...,\n",
      "     -2.16769725e-02   4.48441468e-02   3.89367864e-02]]\n",
      "\n",
      "  [[  9.62153915e-03  -2.29229685e-02   3.04807760e-02 ...,\n",
      "      5.15877195e-02  -1.30231842e-01  -1.00561678e-02]\n",
      "   [  4.24061297e-03  -4.67352904e-02  -4.13221009e-02 ...,\n",
      "     -1.56718977e-02   1.52749410e-02  -4.20253305e-03]\n",
      "   [ -3.63108329e-02   9.15298387e-02  -9.02802031e-03 ...,\n",
      "     -6.80107996e-02   2.24269539e-01   7.61420429e-02]]\n",
      "\n",
      "  [[  9.92963016e-02   2.16423318e-01  -6.91235065e-02 ...,\n",
      "      1.11337177e-01  -1.40475482e-01   1.34454250e-01]\n",
      "   [  4.40809689e-02   6.17079735e-02  -1.38404384e-01 ...,\n",
      "     -1.46149574e-02  -1.88099608e-01   6.39020056e-02]\n",
      "   [  9.10687894e-02   3.02054025e-02  -9.31800976e-02 ...,\n",
      "      4.07125466e-02   1.47271845e-02   1.70511454e-01]]\n",
      "\n",
      "  [[  5.09790555e-02   2.14293525e-01  -7.81280175e-03 ...,\n",
      "     -5.63526861e-02   5.56308888e-02  -1.10549510e-01]\n",
      "   [ -1.23156801e-01  -2.38318831e-01  -1.49361580e-03 ...,\n",
      "     -5.69490902e-02   1.02816463e-01  -4.67325747e-02]\n",
      "   [ -2.17191935e-01   2.04989955e-01  -1.15745544e-01 ...,\n",
      "     -1.32500753e-01  -1.13506392e-01  -2.67014857e-02]]\n",
      "\n",
      "  [[  1.73381314e-01  -7.14583695e-03   1.30986750e-01 ...,\n",
      "      7.69249126e-02   1.37000367e-01   1.47049233e-01]\n",
      "   [ -5.33221066e-02   1.07916214e-01   7.24848062e-02 ...,\n",
      "      7.52573982e-02  -3.20519134e-02  -8.40705931e-02]\n",
      "   [ -1.26192644e-01   6.45920709e-02   8.05093646e-02 ...,\n",
      "     -1.26609191e-01   1.38908148e-01  -1.87394805e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "# The most recent variable at a particular layer can be fetched as.\n",
    "with tf.Session() as globalSession:\n",
    "    globalSession.run(tf.global_variables_initializer())\n",
    "    convWeightL1 = [v for v in tf.trainable_variables() if v.name == 'Layer1/convWeight:0'][0]\n",
    "    print (convWeightL1.get_shape().as_list())\n",
    "    print (globalSession.run(convWeightL1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 3, 64]\n",
      "[[[[ -2.58764178e-02   3.68417874e-02  -2.20113825e-02 ...,\n",
      "     -1.01264648e-01   4.23011743e-02  -1.15798414e-01]\n",
      "   [ -5.56089245e-02  -3.05920672e-02   1.15085237e-01 ...,\n",
      "     -5.03812805e-02   2.23189108e-02   6.28041029e-02]\n",
      "   [  6.76066354e-02   3.38082202e-02   2.55782204e-03 ...,\n",
      "     -5.41199036e-02  -6.91338331e-02   2.44802367e-02]]\n",
      "\n",
      "  [[  2.34650761e-01  -2.26471182e-02   1.27404332e-01 ...,\n",
      "      3.84634919e-02  -6.07750714e-02   9.02874693e-02]\n",
      "   [  1.18034676e-01   8.27012062e-02   1.28456101e-01 ...,\n",
      "      8.34089331e-03  -1.41746387e-01   2.87150275e-02]\n",
      "   [  6.03144430e-02  -7.77993500e-02   1.92963928e-02 ...,\n",
      "     -2.81373002e-02   3.97584438e-02   2.18043067e-02]]\n",
      "\n",
      "  [[  7.11000487e-02   2.14320302e-01   1.72619876e-02 ...,\n",
      "      5.06132245e-02  -1.19313799e-01  -1.43738342e-02]\n",
      "   [ -1.29597425e-01  -6.56865016e-02   1.50291443e-01 ...,\n",
      "     -2.00602338e-01   3.73691204e-03  -2.28491098e-01]\n",
      "   [  1.00871108e-01   1.46426558e-01   9.06365290e-02 ...,\n",
      "     -6.44590557e-02   7.45691434e-02  -3.35411131e-02]]\n",
      "\n",
      "  [[ -1.15495659e-01  -4.49672081e-02   1.19989095e-02 ...,\n",
      "     -1.16278045e-01   3.82919721e-02  -7.60577694e-02]\n",
      "   [  4.01016138e-02  -2.62752753e-02  -1.15945235e-01 ...,\n",
      "     -7.18600815e-04   1.48539320e-01  -5.96087985e-02]\n",
      "   [ -5.17041087e-02   2.74251606e-02  -1.23761468e-01 ...,\n",
      "     -2.12772802e-01  -1.78820059e-01  -1.36470338e-02]]\n",
      "\n",
      "  [[ -3.85971069e-02  -1.84520446e-02   1.18552797e-01 ...,\n",
      "     -4.87386808e-03  -1.04641663e-02   5.11490367e-02]\n",
      "   [  2.82339510e-02   2.53091510e-02   1.81193218e-01 ...,\n",
      "      8.03942755e-02  -1.88021407e-01  -2.69058794e-02]\n",
      "   [ -1.79041490e-01   5.62722795e-02  -7.22297654e-02 ...,\n",
      "      8.57672617e-02  -3.28003503e-02   7.38482624e-02]]]\n",
      "\n",
      "\n",
      " [[[ -2.13116538e-02   1.40402928e-01  -2.13173255e-01 ...,\n",
      "      1.28455505e-01  -1.45528195e-02  -4.93258573e-02]\n",
      "   [  3.29766087e-02  -3.40266130e-03   5.99770360e-02 ...,\n",
      "      1.03871182e-01  -1.06280841e-01   1.95291862e-02]\n",
      "   [  7.72479326e-02   5.28448410e-02  -1.88821126e-02 ...,\n",
      "     -2.12382004e-02  -2.29829893e-01   2.34588981e-02]]\n",
      "\n",
      "  [[ -7.48444721e-03  -8.25298578e-02  -9.93280038e-02 ...,\n",
      "      2.73869392e-02   1.50518358e-01  -1.32859752e-01]\n",
      "   [  1.08187608e-01   1.10800982e-01  -2.13588178e-02 ...,\n",
      "     -6.23863414e-02  -5.41277044e-03   7.45363533e-02]\n",
      "   [  1.03763305e-01  -1.68926511e-02  -3.48031111e-02 ...,\n",
      "     -7.58686811e-02   1.19990908e-01   2.31310911e-02]]\n",
      "\n",
      "  [[  6.37462735e-03  -1.68989655e-02  -4.46268776e-03 ...,\n",
      "     -6.95060119e-02   8.17694589e-02  -1.13665640e-01]\n",
      "   [  8.90764222e-02   4.46601622e-02  -2.01118197e-02 ...,\n",
      "     -1.79954514e-01   7.20906183e-02  -2.78347265e-02]\n",
      "   [  6.84039816e-02   2.47177724e-02  -5.18645607e-02 ...,\n",
      "      1.24498405e-01   2.09283293e-03  -1.08770810e-01]]\n",
      "\n",
      "  [[  3.32613438e-02  -4.43079881e-02   3.47839743e-02 ...,\n",
      "     -5.00320271e-02   4.91589531e-02   3.85543220e-02]\n",
      "   [  8.68490189e-02  -3.40938419e-02   6.17051125e-02 ...,\n",
      "     -3.14040966e-02   5.77462278e-02   1.38507532e-02]\n",
      "   [ -6.62095472e-02  -2.26374436e-03  -1.16672469e-02 ...,\n",
      "      3.05678546e-02  -1.80686772e-01  -9.63895172e-02]]\n",
      "\n",
      "  [[ -2.21360996e-01  -7.36526474e-02   2.93139610e-02 ...,\n",
      "     -6.57916591e-02   7.22820386e-02  -1.67531386e-01]\n",
      "   [  8.46542697e-03   4.26540710e-02  -1.10215485e-01 ...,\n",
      "      5.92251793e-02  -1.97752520e-01  -1.68973371e-01]\n",
      "   [  1.68319210e-01  -1.06074713e-01  -8.15333426e-02 ...,\n",
      "      7.15061948e-02   1.40707090e-01  -8.98340866e-02]]]\n",
      "\n",
      "\n",
      " [[[ -3.66916284e-02   8.48478377e-02   6.92168251e-02 ...,\n",
      "     -1.37397006e-01  -4.10844944e-02   8.72867331e-02]\n",
      "   [  5.94354831e-02   1.09518014e-01   8.00427198e-02 ...,\n",
      "     -2.21245951e-04   8.94531384e-02  -2.04359796e-02]\n",
      "   [  1.07243814e-01   7.69856200e-02  -9.14934278e-02 ...,\n",
      "      3.30735706e-02   1.20431423e-01  -1.40185282e-01]]\n",
      "\n",
      "  [[ -7.10190535e-02   1.29439801e-01  -3.00250556e-02 ...,\n",
      "      5.55627756e-02   7.75865803e-04  -6.52514026e-02]\n",
      "   [ -2.76486158e-01   1.04791678e-01  -1.05600795e-02 ...,\n",
      "      1.67727955e-02   1.37917653e-01   6.28411695e-02]\n",
      "   [ -1.09250359e-01  -1.34922609e-01  -7.13825375e-02 ...,\n",
      "      1.64727811e-02   9.23870429e-02   7.21693859e-02]]\n",
      "\n",
      "  [[ -1.42618818e-02  -5.87347746e-02  -1.26514047e-01 ...,\n",
      "      4.08718027e-02  -1.58126596e-02   4.40508835e-02]\n",
      "   [  1.45121917e-01   9.35609415e-02  -1.37340128e-01 ...,\n",
      "     -3.86351696e-03   4.34736572e-02  -8.72142613e-02]\n",
      "   [ -8.56770016e-03   7.60597587e-02  -5.67172170e-02 ...,\n",
      "     -1.99772827e-02   3.21379900e-02  -1.61154702e-01]]\n",
      "\n",
      "  [[ -1.02114521e-01  -5.27157597e-02  -7.15421066e-02 ...,\n",
      "      8.12953338e-02   1.27201080e-01   6.81691095e-02]\n",
      "   [ -6.31583109e-03  -1.09370463e-01  -2.05216572e-01 ...,\n",
      "      6.50566518e-02   4.41019051e-02   7.07023069e-02]\n",
      "   [  7.80574307e-02   6.87100440e-02   1.68500561e-02 ...,\n",
      "      1.38090819e-01  -8.67633149e-02   4.82526645e-02]]\n",
      "\n",
      "  [[  1.30156800e-01   1.40852198e-01  -5.70831485e-02 ...,\n",
      "     -6.50296435e-02   3.15382443e-02  -1.22767009e-01]\n",
      "   [ -5.31092472e-02  -4.29698341e-02   5.29531315e-02 ...,\n",
      "     -7.35886917e-02  -8.23151171e-02   5.22685312e-02]\n",
      "   [  3.50632146e-02  -5.66566475e-02   1.90809295e-01 ...,\n",
      "     -1.54315785e-01  -5.95718585e-02  -1.28237978e-01]]]\n",
      "\n",
      "\n",
      " [[[  1.35199890e-01  -7.35893622e-02  -9.05706808e-02 ...,\n",
      "      1.28818108e-02   4.62180562e-02   1.07312791e-01]\n",
      "   [  3.21903229e-02  -4.25982289e-02   1.92939058e-01 ...,\n",
      "     -1.60016250e-02  -8.21110532e-02   7.64978752e-02]\n",
      "   [ -2.46980810e-03   5.98962419e-02  -1.03160944e-02 ...,\n",
      "     -6.74324408e-02  -4.36142832e-03   1.23521648e-01]]\n",
      "\n",
      "  [[ -4.46190611e-02  -1.17441230e-01   1.34352028e-01 ...,\n",
      "      1.04124501e-01  -4.35703583e-02   1.00570142e-01]\n",
      "   [ -1.74549326e-01   2.44719293e-02  -1.34817377e-01 ...,\n",
      "      3.23304050e-02  -3.51083986e-02   9.30356309e-02]\n",
      "   [ -1.19260348e-01   1.42053068e-02  -8.75061154e-02 ...,\n",
      "      5.96950017e-02  -1.15102828e-01   3.17060165e-02]]\n",
      "\n",
      "  [[ -6.76482320e-02  -1.65725559e-01   3.58087420e-02 ...,\n",
      "     -6.40280619e-02   4.41366695e-02   1.59742162e-01]\n",
      "   [  1.63601324e-01   4.68889922e-02  -9.28216130e-02 ...,\n",
      "     -1.32019684e-01   1.58532616e-02  -5.70641346e-02]\n",
      "   [ -9.20965225e-02   1.68619081e-01  -5.60649037e-02 ...,\n",
      "     -9.38682407e-02   1.03031956e-01  -1.95390865e-01]]\n",
      "\n",
      "  [[ -8.18978399e-02  -1.52508259e-01  -1.11031486e-02 ...,\n",
      "      1.30922943e-01  -4.01531123e-02  -1.90197691e-01]\n",
      "   [  2.62320340e-02  -1.25239015e-01  -2.72860024e-02 ...,\n",
      "     -1.17548458e-01  -2.32840329e-01   6.04611076e-03]\n",
      "   [ -1.55117452e-01   1.43951640e-01   1.24546602e-01 ...,\n",
      "     -5.48981912e-02  -1.64925024e-01   2.35003214e-02]]\n",
      "\n",
      "  [[ -8.53598025e-03   2.02326402e-01   4.32066470e-02 ...,\n",
      "     -1.27037451e-01   1.32999226e-01   4.08797152e-02]\n",
      "   [ -1.16919756e-01  -1.51782125e-01  -5.13342805e-02 ...,\n",
      "     -1.23940386e-01   6.05026148e-02   3.37882452e-02]\n",
      "   [  1.05093695e-01   2.17119977e-02  -8.41627046e-02 ...,\n",
      "     -4.07574140e-02  -2.66892314e-01  -9.85944197e-02]]]\n",
      "\n",
      "\n",
      " [[[  5.56701198e-02   7.70319626e-02  -1.01995312e-01 ...,\n",
      "      3.49025964e-03  -7.62843117e-02  -1.02726392e-01]\n",
      "   [  1.00242794e-01  -1.69762835e-01   9.26557034e-02 ...,\n",
      "     -3.79233919e-02   4.02652137e-02  -1.88844040e-01]\n",
      "   [  4.52743657e-02  -9.94580835e-02   1.01522900e-01 ...,\n",
      "     -2.16769725e-02   4.48441468e-02   3.89367864e-02]]\n",
      "\n",
      "  [[  9.62153915e-03  -2.29229685e-02   3.04807760e-02 ...,\n",
      "      5.15877195e-02  -1.30231842e-01  -1.00561678e-02]\n",
      "   [  4.24061297e-03  -4.67352904e-02  -4.13221009e-02 ...,\n",
      "     -1.56718977e-02   1.52749410e-02  -4.20253305e-03]\n",
      "   [ -3.63108329e-02   9.15298387e-02  -9.02802031e-03 ...,\n",
      "     -6.80107996e-02   2.24269539e-01   7.61420429e-02]]\n",
      "\n",
      "  [[  9.92963016e-02   2.16423318e-01  -6.91235065e-02 ...,\n",
      "      1.11337177e-01  -1.40475482e-01   1.34454250e-01]\n",
      "   [  4.40809689e-02   6.17079735e-02  -1.38404384e-01 ...,\n",
      "     -1.46149574e-02  -1.88099608e-01   6.39020056e-02]\n",
      "   [  9.10687894e-02   3.02054025e-02  -9.31800976e-02 ...,\n",
      "      4.07125466e-02   1.47271845e-02   1.70511454e-01]]\n",
      "\n",
      "  [[  5.09790555e-02   2.14293525e-01  -7.81280175e-03 ...,\n",
      "     -5.63526861e-02   5.56308888e-02  -1.10549510e-01]\n",
      "   [ -1.23156801e-01  -2.38318831e-01  -1.49361580e-03 ...,\n",
      "     -5.69490902e-02   1.02816463e-01  -4.67325747e-02]\n",
      "   [ -2.17191935e-01   2.04989955e-01  -1.15745544e-01 ...,\n",
      "     -1.32500753e-01  -1.13506392e-01  -2.67014857e-02]]\n",
      "\n",
      "  [[  1.73381314e-01  -7.14583695e-03   1.30986750e-01 ...,\n",
      "      7.69249126e-02   1.37000367e-01   1.47049233e-01]\n",
      "   [ -5.33221066e-02   1.07916214e-01   7.24848062e-02 ...,\n",
      "      7.52573982e-02  -3.20519134e-02  -8.40705931e-02]\n",
      "   [ -1.26192644e-01   6.45920709e-02   8.05093646e-02 ...,\n",
      "     -1.26609191e-01   1.38908148e-01  -1.87394805e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as globalSession1:\n",
    "    globalSession1.run(tf.global_variables_initializer())\n",
    "    convWeightL1 = [v for v in tf.trainable_variables() if v.name == 'Layer1/convWeight:0'][0]\n",
    "    print (convWeightL1.get_shape().as_list())\n",
    "    print (globalSession1.run(convWeightL1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f0b1e4aeebd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mABC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-f0b1e4aeebd9>\u001b[0m in \u001b[0;36mprintVal\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprintVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mABC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "class ABC():\n",
    "    def __init__(self):\n",
    "        print (\"abcdef\")\n",
    "        self.a = 11\n",
    "    \n",
    "    @staticmethod\n",
    "    def printVal(x):\n",
    "        print (x)\n",
    "        \n",
    "ABC.printVal(x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
