{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import xrange\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageSize = 2\n",
    "numChannels = 3\n",
    "numLabels = 2\n",
    "batchSize = 2\n",
    "numEpochs = 3\n",
    "trainSize = 11\n",
    "\n",
    "\n",
    "# declare graph operations\n",
    "reset_graph()\n",
    "# Inplementing Convolution layer\n",
    "def convActivation(inputData, inpOutShape=[5,5,3,12], name=\"convLayer\"):\n",
    "    kernelY, kernelX, numImp, numOut = inpOutShape\n",
    "    with tf.name_scope(name):\n",
    "        with tf.variable_scope(name):\n",
    "            w = tf.get_variable(dtype=tf.float32, \n",
    "                                shape=inpOutShape, \n",
    "                                initializer=tf.random_normal_initializer(\n",
    "                                    mean=0, stddev=0.1, seed = 9743),\n",
    "                                name=\"convWghts\")\n",
    "            b = tf.get_variable(dtype=tf.float32,\n",
    "                               shape=[numOut],\n",
    "                               initializer=tf.constant_initializer(1.0),\n",
    "                               name=\"convBias\")\n",
    "\n",
    "            conv = tf.nn.conv2d(inputData, w, strides=[1,1,1,1], padding=\"SAME\")\n",
    "            act = tf.nn.relu(conv + b)\n",
    "            pool = tf.nn.max_pool(act, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "        \n",
    "            return pool\n",
    "    \n",
    "# Implement fully connected layer\n",
    "def fcLayer(inputData, inpOutShape, name=\"fcLayer\"):\n",
    "    numInp, numOut = inpOutShape\n",
    "    with tf.name_scope(name):\n",
    "        with tf.variable_scope(name):\n",
    "            w = tf.get_variable(dtype=tf.float32,\n",
    "                               shape=inpOutShape,\n",
    "                               initializer=tf.random_normal_initializer(\n",
    "                                   mean=0, stddev=0.1, seed=2349),\n",
    "                               name=\"fcWghts\")\n",
    "            b = tf.get_variable(dtype=tf.float32,\n",
    "                               shape=[numOut],\n",
    "                               initializer=tf.constant_initializer(1.0),\n",
    "                               name=\"fcBias\")\n",
    "            convToFc1 = tf.matmul(inputData, w) + b\n",
    "\n",
    "            return tf.nn.relu(convToFc1)\n",
    "    \n",
    "# Build the forward feed network\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, imageSize, imageSize, numChannels], name='xInp')\n",
    "y = tf.placeholder(tf.float32, shape=[None, numLabels], name=\"xLabels\")\n",
    "conv1 = convActivation(inputData=x,\n",
    "                      inpOutShape=[5,5,3,12],\n",
    "                      name = \"conv1\")\n",
    "conv2 = convActivation(inputData=conv1,\n",
    "                      inpOutShape=[5,5,12,12],\n",
    "                      name = \"conv2\")\n",
    "\n",
    "shapeY, shapeX, depth = conv2.get_shape().as_list()[1:4]\n",
    "flattenedShape = shapeY * shapeX * depth\n",
    "conv2Flattened = tf.reshape(conv2, [-1, flattenedShape])\n",
    "fcOut1 = fcLayer(inputData=conv2Flattened,\n",
    "                inpOutShape=[flattenedShape, 28],\n",
    "                name=\"fcLayer1\")\n",
    "fcOut2 = fcLayer(inputData=fcOut1,\n",
    "                inpOutShape=[28,28],\n",
    "                name=\"fcLayer2\")\n",
    "\n",
    "# Now we send our input to the softmax function to calculate the cross entropy loss\n",
    "with tf.name_scope(\"trainLoss\"):\n",
    "    loss = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(logits=fcOut2, labels=y)\n",
    "    )\n",
    "\n",
    "# Implement the optimizer\n",
    "with tf.name_scope(\"trainOpt\"):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# finally we calculate the accuracy\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(fcOut2,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 2, 2, 3) (11, 2)\n",
      "[[[[ 0.35707943  0.12833894  0.15295916]\n",
      "   [ 0.20223427  0.79861436  0.49992973]]\n",
      "\n",
      "  [[ 0.38051615  0.96961017  0.41956738]\n",
      "   [ 0.02243423  0.869846    0.2410229 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.43471575  0.82617992  0.35728117]\n",
      "   [ 0.969553    0.49855262  0.28457198]]\n",
      "\n",
      "  [[ 0.76952965  0.11132122  0.12703334]\n",
      "   [ 0.48154849  0.15632511  0.04167751]]]\n",
      "\n",
      "\n",
      " [[[ 0.4486092   0.66541078  0.2939314 ]\n",
      "   [ 0.7710301   0.64557448  0.8494144 ]]\n",
      "\n",
      "  [[ 0.83201776  0.73499182  0.20471862]\n",
      "   [ 0.58215064  0.26835345  0.86058613]]]\n",
      "\n",
      "\n",
      " [[[ 0.56757519  0.19689462  0.84849181]\n",
      "   [ 0.89588444  0.29359123  0.88640224]]\n",
      "\n",
      "  [[ 0.77661107  0.51537682  0.44087248]\n",
      "   [ 0.02521708  0.90090549  0.2411479 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.65174954  0.8199548   0.90816593]\n",
      "   [ 0.77792883  0.84562629  0.63650318]]\n",
      "\n",
      "  [[ 0.33933048  0.3411692   0.82594148]\n",
      "   [ 0.04943311  0.00404568  0.33157768]]]\n",
      "\n",
      "\n",
      " [[[ 0.88913496  0.79979871  0.17578018]\n",
      "   [ 0.19353671  0.78572631  0.12799973]]\n",
      "\n",
      "  [[ 0.2657621   0.73152201  0.24815633]\n",
      "   [ 0.0657471   0.68899893  0.12826133]]]\n",
      "\n",
      "\n",
      " [[[ 0.78267875  0.39839841  0.21918507]\n",
      "   [ 0.96968283  0.14480076  0.69311649]]\n",
      "\n",
      "  [[ 0.8521256   0.44422481  0.34674195]\n",
      "   [ 0.84443671  0.46268522  0.95028168]]]\n",
      "\n",
      "\n",
      " [[[ 0.52537557  0.74235824  0.75813841]\n",
      "   [ 0.07808035  0.05937075  0.59149949]]\n",
      "\n",
      "  [[ 0.24747418  0.49371527  0.88731349]\n",
      "   [ 0.09236007  0.9189767   0.72183327]]]\n",
      "\n",
      "\n",
      " [[[ 0.33541981  0.43299035  0.95331852]\n",
      "   [ 0.39917801  0.92184256  0.18556985]]\n",
      "\n",
      "  [[ 0.46672497  0.49467124  0.33627543]\n",
      "   [ 0.41353224  0.30039347  0.97074253]]]\n",
      "\n",
      "\n",
      " [[[ 0.51783602  0.37420783  0.53867105]\n",
      "   [ 0.87031263  0.63982202  0.80525479]]\n",
      "\n",
      "  [[ 0.33119061  0.71705293  0.24688925]\n",
      "   [ 0.84671751  0.28068061  0.75194263]]]\n",
      "\n",
      "\n",
      " [[[ 0.02854892  0.46269865  0.43097682]\n",
      "   [ 0.3684336   0.13481755  0.95859279]]\n",
      "\n",
      "  [[ 0.69670221  0.50270012  0.04886604]\n",
      "   [ 0.50731563  0.61474419  0.16368915]]]]\n",
      "\n",
      "\n",
      "Total number of Steps are:  16\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (0 * 2) modulus (11 - 1) = 0 : \n",
      "[[[[ 0.35707943  0.12833894  0.15295916]\n",
      "   [ 0.20223427  0.79861436  0.49992973]]\n",
      "\n",
      "  [[ 0.38051615  0.96961017  0.41956738]\n",
      "   [ 0.02243423  0.869846    0.2410229 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.43471575  0.82617992  0.35728117]\n",
      "   [ 0.969553    0.49855262  0.28457198]]\n",
      "\n",
      "  [[ 0.76952965  0.11132122  0.12703334]\n",
      "   [ 0.48154849  0.15632511  0.04167751]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (1 * 2) modulus (11 - 1) = 2 : \n",
      "[[[[ 0.4486092   0.66541078  0.2939314 ]\n",
      "   [ 0.7710301   0.64557448  0.8494144 ]]\n",
      "\n",
      "  [[ 0.83201776  0.73499182  0.20471862]\n",
      "   [ 0.58215064  0.26835345  0.86058613]]]\n",
      "\n",
      "\n",
      " [[[ 0.56757519  0.19689462  0.84849181]\n",
      "   [ 0.89588444  0.29359123  0.88640224]]\n",
      "\n",
      "  [[ 0.77661107  0.51537682  0.44087248]\n",
      "   [ 0.02521708  0.90090549  0.2411479 ]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (2 * 2) modulus (11 - 1) = 4 : \n",
      "[[[[ 0.65174954  0.8199548   0.90816593]\n",
      "   [ 0.77792883  0.84562629  0.63650318]]\n",
      "\n",
      "  [[ 0.33933048  0.3411692   0.82594148]\n",
      "   [ 0.04943311  0.00404568  0.33157768]]]\n",
      "\n",
      "\n",
      " [[[ 0.88913496  0.79979871  0.17578018]\n",
      "   [ 0.19353671  0.78572631  0.12799973]]\n",
      "\n",
      "  [[ 0.2657621   0.73152201  0.24815633]\n",
      "   [ 0.0657471   0.68899893  0.12826133]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (3 * 2) modulus (11 - 1) = 6 : \n",
      "[[[[ 0.78267875  0.39839841  0.21918507]\n",
      "   [ 0.96968283  0.14480076  0.69311649]]\n",
      "\n",
      "  [[ 0.8521256   0.44422481  0.34674195]\n",
      "   [ 0.84443671  0.46268522  0.95028168]]]\n",
      "\n",
      "\n",
      " [[[ 0.52537557  0.74235824  0.75813841]\n",
      "   [ 0.07808035  0.05937075  0.59149949]]\n",
      "\n",
      "  [[ 0.24747418  0.49371527  0.88731349]\n",
      "   [ 0.09236007  0.9189767   0.72183327]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (4 * 2) modulus (11 - 1) = 8 : \n",
      "[[[[ 0.33541981  0.43299035  0.95331852]\n",
      "   [ 0.39917801  0.92184256  0.18556985]]\n",
      "\n",
      "  [[ 0.46672497  0.49467124  0.33627543]\n",
      "   [ 0.41353224  0.30039347  0.97074253]]]\n",
      "\n",
      "\n",
      " [[[ 0.51783602  0.37420783  0.53867105]\n",
      "   [ 0.87031263  0.63982202  0.80525479]]\n",
      "\n",
      "  [[ 0.33119061  0.71705293  0.24688925]\n",
      "   [ 0.84671751  0.28068061  0.75194263]]]\n",
      "\n",
      "\n",
      " [[[ 0.02854892  0.46269865  0.43097682]\n",
      "   [ 0.3684336   0.13481755  0.95859279]]\n",
      "\n",
      "  [[ 0.69670221  0.50270012  0.04886604]\n",
      "   [ 0.50731563  0.61474419  0.16368915]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (5 * 2) modulus (11 - 1) = 0 : \n",
      "[[[[ 0.35707943  0.12833894  0.15295916]\n",
      "   [ 0.20223427  0.79861436  0.49992973]]\n",
      "\n",
      "  [[ 0.38051615  0.96961017  0.41956738]\n",
      "   [ 0.02243423  0.869846    0.2410229 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.43471575  0.82617992  0.35728117]\n",
      "   [ 0.969553    0.49855262  0.28457198]]\n",
      "\n",
      "  [[ 0.76952965  0.11132122  0.12703334]\n",
      "   [ 0.48154849  0.15632511  0.04167751]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (6 * 2) modulus (11 - 1) = 2 : \n",
      "[[[[ 0.4486092   0.66541078  0.2939314 ]\n",
      "   [ 0.7710301   0.64557448  0.8494144 ]]\n",
      "\n",
      "  [[ 0.83201776  0.73499182  0.20471862]\n",
      "   [ 0.58215064  0.26835345  0.86058613]]]\n",
      "\n",
      "\n",
      " [[[ 0.56757519  0.19689462  0.84849181]\n",
      "   [ 0.89588444  0.29359123  0.88640224]]\n",
      "\n",
      "  [[ 0.77661107  0.51537682  0.44087248]\n",
      "   [ 0.02521708  0.90090549  0.2411479 ]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (7 * 2) modulus (11 - 1) = 4 : \n",
      "[[[[ 0.65174954  0.8199548   0.90816593]\n",
      "   [ 0.77792883  0.84562629  0.63650318]]\n",
      "\n",
      "  [[ 0.33933048  0.3411692   0.82594148]\n",
      "   [ 0.04943311  0.00404568  0.33157768]]]\n",
      "\n",
      "\n",
      " [[[ 0.88913496  0.79979871  0.17578018]\n",
      "   [ 0.19353671  0.78572631  0.12799973]]\n",
      "\n",
      "  [[ 0.2657621   0.73152201  0.24815633]\n",
      "   [ 0.0657471   0.68899893  0.12826133]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (8 * 2) modulus (11 - 1) = 6 : \n",
      "[[[[ 0.78267875  0.39839841  0.21918507]\n",
      "   [ 0.96968283  0.14480076  0.69311649]]\n",
      "\n",
      "  [[ 0.8521256   0.44422481  0.34674195]\n",
      "   [ 0.84443671  0.46268522  0.95028168]]]\n",
      "\n",
      "\n",
      " [[[ 0.52537557  0.74235824  0.75813841]\n",
      "   [ 0.07808035  0.05937075  0.59149949]]\n",
      "\n",
      "  [[ 0.24747418  0.49371527  0.88731349]\n",
      "   [ 0.09236007  0.9189767   0.72183327]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (9 * 2) modulus (11 - 1) = 8 : \n",
      "[[[[ 0.33541981  0.43299035  0.95331852]\n",
      "   [ 0.39917801  0.92184256  0.18556985]]\n",
      "\n",
      "  [[ 0.46672497  0.49467124  0.33627543]\n",
      "   [ 0.41353224  0.30039347  0.97074253]]]\n",
      "\n",
      "\n",
      " [[[ 0.51783602  0.37420783  0.53867105]\n",
      "   [ 0.87031263  0.63982202  0.80525479]]\n",
      "\n",
      "  [[ 0.33119061  0.71705293  0.24688925]\n",
      "   [ 0.84671751  0.28068061  0.75194263]]]\n",
      "\n",
      "\n",
      " [[[ 0.02854892  0.46269865  0.43097682]\n",
      "   [ 0.3684336   0.13481755  0.95859279]]\n",
      "\n",
      "  [[ 0.69670221  0.50270012  0.04886604]\n",
      "   [ 0.50731563  0.61474419  0.16368915]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (10 * 2) modulus (11 - 1) = 0 : \n",
      "[[[[ 0.35707943  0.12833894  0.15295916]\n",
      "   [ 0.20223427  0.79861436  0.49992973]]\n",
      "\n",
      "  [[ 0.38051615  0.96961017  0.41956738]\n",
      "   [ 0.02243423  0.869846    0.2410229 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.43471575  0.82617992  0.35728117]\n",
      "   [ 0.969553    0.49855262  0.28457198]]\n",
      "\n",
      "  [[ 0.76952965  0.11132122  0.12703334]\n",
      "   [ 0.48154849  0.15632511  0.04167751]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (11 * 2) modulus (11 - 1) = 2 : \n",
      "[[[[ 0.4486092   0.66541078  0.2939314 ]\n",
      "   [ 0.7710301   0.64557448  0.8494144 ]]\n",
      "\n",
      "  [[ 0.83201776  0.73499182  0.20471862]\n",
      "   [ 0.58215064  0.26835345  0.86058613]]]\n",
      "\n",
      "\n",
      " [[[ 0.56757519  0.19689462  0.84849181]\n",
      "   [ 0.89588444  0.29359123  0.88640224]]\n",
      "\n",
      "  [[ 0.77661107  0.51537682  0.44087248]\n",
      "   [ 0.02521708  0.90090549  0.2411479 ]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (12 * 2) modulus (11 - 1) = 4 : \n",
      "[[[[ 0.65174954  0.8199548   0.90816593]\n",
      "   [ 0.77792883  0.84562629  0.63650318]]\n",
      "\n",
      "  [[ 0.33933048  0.3411692   0.82594148]\n",
      "   [ 0.04943311  0.00404568  0.33157768]]]\n",
      "\n",
      "\n",
      " [[[ 0.88913496  0.79979871  0.17578018]\n",
      "   [ 0.19353671  0.78572631  0.12799973]]\n",
      "\n",
      "  [[ 0.2657621   0.73152201  0.24815633]\n",
      "   [ 0.0657471   0.68899893  0.12826133]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (13 * 2) modulus (11 - 1) = 6 : \n",
      "[[[[ 0.78267875  0.39839841  0.21918507]\n",
      "   [ 0.96968283  0.14480076  0.69311649]]\n",
      "\n",
      "  [[ 0.8521256   0.44422481  0.34674195]\n",
      "   [ 0.84443671  0.46268522  0.95028168]]]\n",
      "\n",
      "\n",
      " [[[ 0.52537557  0.74235824  0.75813841]\n",
      "   [ 0.07808035  0.05937075  0.59149949]]\n",
      "\n",
      "  [[ 0.24747418  0.49371527  0.88731349]\n",
      "   [ 0.09236007  0.9189767   0.72183327]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (14 * 2) modulus (11 - 1) = 8 : \n",
      "[[[[ 0.33541981  0.43299035  0.95331852]\n",
      "   [ 0.39917801  0.92184256  0.18556985]]\n",
      "\n",
      "  [[ 0.46672497  0.49467124  0.33627543]\n",
      "   [ 0.41353224  0.30039347  0.97074253]]]\n",
      "\n",
      "\n",
      " [[[ 0.51783602  0.37420783  0.53867105]\n",
      "   [ 0.87031263  0.63982202  0.80525479]]\n",
      "\n",
      "  [[ 0.33119061  0.71705293  0.24688925]\n",
      "   [ 0.84671751  0.28068061  0.75194263]]]\n",
      "\n",
      "\n",
      " [[[ 0.02854892  0.46269865  0.43097682]\n",
      "   [ 0.3684336   0.13481755  0.95859279]]\n",
      "\n",
      "  [[ 0.69670221  0.50270012  0.04886604]\n",
      "   [ 0.50731563  0.61474419  0.16368915]]]]\n",
      "\n",
      "(Step * batchSize) modulus (trainSize - remainder) = offset (15 * 2) modulus (11 - 1) = 0 : \n",
      "[[[[ 0.35707943  0.12833894  0.15295916]\n",
      "   [ 0.20223427  0.79861436  0.49992973]]\n",
      "\n",
      "  [[ 0.38051615  0.96961017  0.41956738]\n",
      "   [ 0.02243423  0.869846    0.2410229 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.43471575  0.82617992  0.35728117]\n",
      "   [ 0.969553    0.49855262  0.28457198]]\n",
      "\n",
      "  [[ 0.76952965  0.11132122  0.12703334]\n",
      "   [ 0.48154849  0.15632511  0.04167751]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we build fake mnist data\n",
    "def fake_data(trainSize, numFeatures):\n",
    "    \"\"\"Generate a fake dataset that matches the dimensions of MNIST.\"\"\"\n",
    "    data = np.random.rand(\n",
    "        trainSize, imageSize, imageSize, 3)\n",
    "    labels = np.zeros(shape=(trainSize,), dtype=np.int64)\n",
    "    for image in xrange(trainSize):\n",
    "        label = image % 2\n",
    "#         data[image, 0] = label - 0.5\n",
    "        labels[image] = label\n",
    "    return data, labels\n",
    "\n",
    "trainData, trainLabels = fake_data(trainSize=trainSize, numFeatures=3)\n",
    "\n",
    "trainLabels = np.eye(numLabels)[trainLabels]\n",
    "print (trainData.shape, trainLabels.shape)\n",
    "\n",
    "print (trainData)\n",
    "print ('')\n",
    "print ('')\n",
    "numSteps = int((numEpochs * trainSize)) // batchSize\n",
    "# Capture the remainder if in case the trainSize is not ezactly divisible by batchSize.  If such is the case then we may miss some training set. \n",
    "# For example, if trainingSize = 11 and batchSize=2 them since 10%2 = 0, but 11%2 = 1. So when we itereate over a batch of 2 then for every epoch \n",
    "# we miss one trainig example\n",
    "remainder = trainSize % batchSize  \n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print ('Total number of Steps are: ', numSteps)\n",
    "    for step in np.arange(numSteps):\n",
    "        offset = (step * batchSize) % (trainSize-remainder)\n",
    "        print ('(Step * batchSize) modulus (trainSize - remainder) = offset (%s * %s) modulus (%s - %s) = %s : '%(str(step), str(batchSize), str(trainSize), str(remainder), str(offset)))\n",
    "        if offset == (trainSize - remainder - batchSize):\n",
    "            batchData = trainData[offset:(offset+batchSize+remainder),:]\n",
    "            batchLabels = trainData[offset:(offset+batchSize+remainder),:]\n",
    "        else:\n",
    "            batchData = trainData[offset:(offset+batchSize),:]\n",
    "            batchLabels = trainData[offset:(offset+batchSize),:]\n",
    "\n",
    "        feedDict = {x:batchData, y:batchLabels}\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.ndarray(\n",
    "        shape=(20, 28, 28, 3),\n",
    "        dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 28, 28, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
